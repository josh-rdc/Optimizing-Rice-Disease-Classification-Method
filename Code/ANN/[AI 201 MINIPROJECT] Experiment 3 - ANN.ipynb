{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64653a26-b164-4036-93b5-be0f7358a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxiliaries (Importing Datafile, Checking Time)\n",
    "import os \n",
    "import time\n",
    "\n",
    "# Calculations\n",
    "import numpy as np\n",
    "\n",
    "# For Importing Data Files\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from skimage import color\n",
    "\n",
    "# For Image Pre-Processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979b03d-2172-4465-999b-1e65d282be22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create dataframe\n",
    "\n",
    "3 columns\n",
    "1. Disease Classification\n",
    "2. Image Name\n",
    "3. Image RGB Values (RGB Converted from BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce4c625-de79-4861-b12a-56db5eb4203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def create_dataframe_from_folders(root_folder):\n",
    "    # Initialize empty lists to store data for each column\n",
    "    folder_names = []\n",
    "    photo_names = []\n",
    "    photos = []\n",
    "\n",
    "    # Traverse through the root folder and its subfolders\n",
    "    for folder_name in sorted(os.listdir(root_folder)):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if the entry in the root folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for photo_name in sorted(os.listdir(folder_path), key=natural_sort_key):\n",
    "                # Assuming photos are in common image formats (e.g., jpg, png)\n",
    "                if photo_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    photo_path = os.path.join(folder_path, photo_name)\n",
    "\n",
    "                    # Read image data using cv2\n",
    "                    image_data = cv2.imread(photo_path)\n",
    "\n",
    "                    # Convert BGR to RGB\n",
    "                    image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Append data to the lists\n",
    "                    folder_names.append(folder_name)\n",
    "                    photo_names.append(photo_name)\n",
    "                    photos.append(image_data_rgb)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'class': folder_names,\n",
    "        'img_name': photo_names,\n",
    "        'rgb': photos\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af7bde-ac77-45fa-8c61-7a53363109b4",
   "metadata": {},
   "source": [
    "Get data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f698915-bb74-4ec7-8ff1-606c6471d686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   class            img_name  \\\n",
      "0  bacterial_leaf_blight  BLB_single (1).jpg   \n",
      "1  bacterial_leaf_blight  BLB_single (2).jpg   \n",
      "2  bacterial_leaf_blight  BLB_single (3).jpg   \n",
      "3  bacterial_leaf_blight  BLB_single (4).jpg   \n",
      "4  bacterial_leaf_blight  BLB_single (5).jpg   \n",
      "\n",
      "                                                 rgb  \n",
      "0  [[[161, 125, 67], [163, 128, 70], [166, 132, 7...  \n",
      "1  [[[238, 229, 222], [238, 229, 222], [238, 229,...  \n",
      "2  [[[236, 225, 219], [237, 226, 220], [238, 227,...  \n",
      "3  [[[236, 223, 217], [236, 223, 217], [237, 224,...  \n",
      "4  [[[236, 225, 221], [236, 225, 221], [236, 225,...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "extra_resized_folder_path = r\"C:\\Users\\Josh\\000 Files\\003 Mengg AI\\01a 201 (AI)\\03 Mini-Project\\resized_raw_images (14 Classes - Zoomed)\"\n",
    "extra_resized = create_dataframe_from_folders(extra_resized_folder_path)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(extra_resized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5426b9d-5fe5-470e-95cd-b9bd72e1875a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Class Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be65000-1849-48e3-b646-93efd2758afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "brown_spot               54\n",
      "rice_blast               52\n",
      "rice_false_smut          51\n",
      "bacterial_leaf_streak    50\n",
      "grassy_stunt_virus       50\n",
      "healthy_rice_plant       50\n",
      "narrow_brown_spot        50\n",
      "sheath_blight            50\n",
      "sheath_rot               50\n",
      "stem_rot                 50\n",
      "tungro_virus             50\n",
      "bakanae                  49\n",
      "ragged_stunt_virus       49\n",
      "bacterial_leaf_blight    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = extra_resized['class'].value_counts()\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac8225-3fe7-4259-a715-381055cfb61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d99ab4-0a06-495a-8af2-2d2ca69d19a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Texture Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef73441b-106f-4a76-af4a-30d0192a58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mahotas\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def compute_glcm_features(df):\n",
    "    df['gray'] = df['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2GRAY))\n",
    "    def calculate_glcm(gray_image):\n",
    "        # Compute GLCM using mahotas\n",
    "        glcm = mahotas.features.haralick(gray_image.astype(np.uint8), ignore_zeros=True)\n",
    "        return glcm.mean(axis=0)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gray_image = row['gray']\n",
    "        glcm_features = calculate_glcm(gray_image)\n",
    "        features.append(glcm_features)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Define meaningful column names for GLCM features\n",
    "    glcm_columns = [\n",
    "        'Angular Second Moment',\n",
    "        'Contrast',\n",
    "        'Correlation',\n",
    "        'Sum of Squares: Variance',\n",
    "        'Inverse Difference Moment',\n",
    "        'Sum Average',\n",
    "        'Sum Variance',\n",
    "        'Sum Entropy',\n",
    "        'Entropy',\n",
    "        'Difference Variance',\n",
    "        'Difference Entropy',\n",
    "        'Informational Measure of Correlation 1',\n",
    "        'Informational Measure of Correlation 2'\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with the new GLCM features and meaningful column names\n",
    "    glcm_df = pd.DataFrame(features, columns=[f'GLCM_{col}' for col in glcm_columns])\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, glcm_df], axis=1)\n",
    "\n",
    "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2b059a-fa17-4742-a4e9-61286361606a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 17.18 seconds\n"
     ]
    }
   ],
   "source": [
    "glcm = compute_glcm_features(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564a00a9-a6ed-4d71-b79b-82ded4744d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the first n columns\n",
    "f_glcm = glcm.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3555e8-efe3-4a70-8258-9bf9d11a2d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_Angular Second Moment</th>\n",
       "      <th>GLCM_Contrast</th>\n",
       "      <th>GLCM_Correlation</th>\n",
       "      <th>GLCM_Sum of Squares: Variance</th>\n",
       "      <th>GLCM_Inverse Difference Moment</th>\n",
       "      <th>GLCM_Sum Average</th>\n",
       "      <th>GLCM_Sum Variance</th>\n",
       "      <th>GLCM_Sum Entropy</th>\n",
       "      <th>GLCM_Entropy</th>\n",
       "      <th>GLCM_Difference Variance</th>\n",
       "      <th>GLCM_Difference Entropy</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 1</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000358</td>\n",
       "      <td>266.001841</td>\n",
       "      <td>0.964868</td>\n",
       "      <td>3785.238579</td>\n",
       "      <td>0.239492</td>\n",
       "      <td>180.814209</td>\n",
       "      <td>14874.952473</td>\n",
       "      <td>8.629918</td>\n",
       "      <td>12.466566</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>4.343470</td>\n",
       "      <td>-0.369462</td>\n",
       "      <td>0.997668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018832</td>\n",
       "      <td>29.540256</td>\n",
       "      <td>0.994057</td>\n",
       "      <td>2484.910874</td>\n",
       "      <td>0.515623</td>\n",
       "      <td>370.827844</td>\n",
       "      <td>9910.103241</td>\n",
       "      <td>6.141836</td>\n",
       "      <td>8.088455</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>2.749243</td>\n",
       "      <td>-0.444118</td>\n",
       "      <td>0.993843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012217</td>\n",
       "      <td>47.934937</td>\n",
       "      <td>0.991704</td>\n",
       "      <td>2888.983700</td>\n",
       "      <td>0.439836</td>\n",
       "      <td>355.884272</td>\n",
       "      <td>11507.999864</td>\n",
       "      <td>6.346219</td>\n",
       "      <td>8.658163</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>3.050238</td>\n",
       "      <td>-0.405166</td>\n",
       "      <td>0.991940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019039</td>\n",
       "      <td>56.672401</td>\n",
       "      <td>0.992339</td>\n",
       "      <td>3697.472233</td>\n",
       "      <td>0.519511</td>\n",
       "      <td>348.227408</td>\n",
       "      <td>14733.216531</td>\n",
       "      <td>6.472970</td>\n",
       "      <td>8.465276</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>2.890223</td>\n",
       "      <td>-0.465543</td>\n",
       "      <td>0.996049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025665</td>\n",
       "      <td>45.344059</td>\n",
       "      <td>0.993331</td>\n",
       "      <td>3397.524613</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>379.393294</td>\n",
       "      <td>13544.754392</td>\n",
       "      <td>5.682043</td>\n",
       "      <td>7.201895</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>2.390516</td>\n",
       "      <td>-0.478429</td>\n",
       "      <td>0.993598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_Angular Second Moment  GLCM_Contrast  GLCM_Correlation  \\\n",
       "0                    0.000358     266.001841          0.964868   \n",
       "1                    0.018832      29.540256          0.994057   \n",
       "2                    0.012217      47.934937          0.991704   \n",
       "3                    0.019039      56.672401          0.992339   \n",
       "4                    0.025665      45.344059          0.993331   \n",
       "\n",
       "   GLCM_Sum of Squares: Variance  GLCM_Inverse Difference Moment  \\\n",
       "0                    3785.238579                        0.239492   \n",
       "1                    2484.910874                        0.515623   \n",
       "2                    2888.983700                        0.439836   \n",
       "3                    3697.472233                        0.519511   \n",
       "4                    3397.524613                        0.590942   \n",
       "\n",
       "   GLCM_Sum Average  GLCM_Sum Variance  GLCM_Sum Entropy  GLCM_Entropy  \\\n",
       "0        180.814209       14874.952473          8.629918     12.466566   \n",
       "1        370.827844        9910.103241          6.141836      8.088455   \n",
       "2        355.884272       11507.999864          6.346219      8.658163   \n",
       "3        348.227408       14733.216531          6.472970      8.465276   \n",
       "4        379.393294       13544.754392          5.682043      7.201895   \n",
       "\n",
       "   GLCM_Difference Variance  GLCM_Difference Entropy  \\\n",
       "0                  0.000331                 4.343470   \n",
       "1                  0.000993                 2.749243   \n",
       "2                  0.000813                 3.050238   \n",
       "3                  0.000997                 2.890223   \n",
       "4                  0.001234                 2.390516   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 1  \\\n",
       "0                                    -0.369462   \n",
       "1                                    -0.444118   \n",
       "2                                    -0.405166   \n",
       "3                                    -0.465543   \n",
       "4                                    -0.478429   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 2  \n",
       "0                                     0.997668  \n",
       "1                                     0.993843  \n",
       "2                                     0.991940  \n",
       "3                                     0.996049  \n",
       "4                                     0.993598  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_glcm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ad4b-7eb0-4110-bcb4-6e592e28d837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94ca35f-9437-4b01-8009-1a0eed2ae870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354c8451-629c-447d-beef-076db3311418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def values(dataframe):\n",
    "    # Ensure the 'rgb' column exists in the dataframe\n",
    "    dataframe['hsv'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2HSV))\n",
    "    #dataframe['hsi'] = dataframe['rgb'].apply(lambda x: color.rgb2hsi(np.uint8(x)))\n",
    "    dataframe['lab'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    dataframe['red'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,0])\n",
    "    dataframe['green'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,1])\n",
    "    dataframe['blue'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,2])\n",
    "    \n",
    "    dataframe['hue_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,0])\n",
    "    dataframe['saturation_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,1])\n",
    "    dataframe['value_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,2])\n",
    "    \n",
    "    #dataframe['hue_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,0])\n",
    "    #dataframe['saturation_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,1])\n",
    "    #dataframe['intensity_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,2])\n",
    "    \n",
    "    dataframe['lightness'] = dataframe['lab'].apply(lambda lab: lab[:, :, 0])\n",
    "    dataframe['a'] = dataframe['lab'].apply(lambda lab: lab[:, :, 1])\n",
    "    dataframe['b'] = dataframe['lab'].apply(lambda lab: lab[:, :, 2])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5082c1-48a7-4a77-ae63-d276523f8173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_bins_to_dataframe(dataframe, column_name, num_bins):\n",
    "    # Extract the specified column\n",
    "    original_column = dataframe[column_name]\n",
    "\n",
    "    # Define bin edges based on the min and max values in the matrices\n",
    "    min_value = np.min([np.min(matrix) for matrix in original_column])\n",
    "    max_value = np.max([np.max(matrix) for matrix in original_column])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "    # Create column names for the bins\n",
    "    bin_column_names = [f'{column_name}_{i}' for i in range(num_bins)]\n",
    "\n",
    "    # Iterate through each matrix in the original column\n",
    "    for i, matrix in enumerate(original_column):\n",
    "        # Digitize each element in the matrix into the corresponding bin\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "\n",
    "        # Count the occurrences of each bin index\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        # Add new columns to the DataFrame for each bin\n",
    "        for j, bin_column_name in enumerate(bin_column_names):\n",
    "            dataframe.loc[i, bin_column_name] = bin_counts[j]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb1fba-0704-4f4b-b34a-2e2ef1cbd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = values(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ab83c9-fc0e-4cff-9869-3fa8c12e4469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_bins_dataframe(dataframe, col, num_bins):\n",
    "    bins_dataframe = pd.DataFrame()\n",
    "\n",
    "    #print(col)\n",
    "    min_value = np.min([np.min(matrix) for matrix in dataframe[col]])\n",
    "    max_value = np.max([np.max(matrix) for matrix in dataframe[col]])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "    bin_column_names = [f'{col}_{i}' for i in range(1, num_bins + 1)]\n",
    "\n",
    "    for matrix in dataframe[col]:\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        bins_dataframe = pd.concat([bins_dataframe, pd.DataFrame(bin_counts).transpose()], axis=0, ignore_index=True)\n",
    "\n",
    "    bins_dataframe.columns = bin_column_names\n",
    "        \n",
    "    return bins_dataframe\n",
    "\n",
    "def hist_features(df, cols, bins):\n",
    "    complete_bins = pd.DataFrame()\n",
    "\n",
    "    for col in cols:\n",
    "        col_bins = create_bins_dataframe(df, col, bins)\n",
    "        complete_bins = pd.concat([complete_bins, col_bins], axis=1)\n",
    "\n",
    "    return complete_bins\n",
    "\n",
    "cols = ['red', 'green', 'blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef1f4f2-7b29-4783-80bb-942502c3f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'channels' is your DataFrame\n",
    "f_histogram = hist_features(channels, cols, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200b7499-7dd8-4545-a930-7e28dd715d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>red_10</th>\n",
       "      <th>...</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "      <th>b_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>373</td>\n",
       "      <td>484</td>\n",
       "      <td>879</td>\n",
       "      <td>1088</td>\n",
       "      <td>1006</td>\n",
       "      <td>1012</td>\n",
       "      <td>832</td>\n",
       "      <td>1121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_1  red_2  red_3  red_4  red_5  red_6  red_7  red_8  red_9  red_10  ...  \\\n",
       "0    175    390    373    484    879   1088   1006   1012    832    1121  ...   \n",
       "1      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "2      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "\n",
       "   b_73  b_74  b_75  b_76  b_77  b_78  b_79  b_80  b_81  b_82  \n",
       "0     0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_histogram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58cb8f-65ac-44fc-99e6-58e42abfabfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Color Moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b0823e-3e5b-4f1c-95a6-8b8b4cc97e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "\n",
    "def color_moments(dataframe, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        mean_values = []\n",
    "        variance_values = []\n",
    "        kurtosis_values = []\n",
    "        skewness_values = []\n",
    "\n",
    "        for img in dataframe[col]:\n",
    "            # Assuming 'img' is a 3D numpy array representing an RGB image\n",
    "            # Calculate statistics for each image\n",
    "            mean_channel = np.mean(img, axis=(0, 1))\n",
    "            variance_channel = np.var(img, axis=(0, 1))\n",
    "            kurtosis_channel = kurtosis(img, axis=(0, 1))\n",
    "            skewness_channel = skew(img, axis=(0, 1))\n",
    "\n",
    "            # Append values to respective lists\n",
    "            mean_values.append(mean_channel)\n",
    "            variance_values.append(variance_channel)\n",
    "            kurtosis_values.append(kurtosis_channel)\n",
    "            skewness_values.append(skewness_channel)\n",
    "\n",
    "        # Add the new columns to the DataFrame with channel names\n",
    "        for i in range(img.shape[2]):  # Assuming 'img' has shape (height, width, channels)\n",
    "            dataframe[f'{col}_channel_{i}_mean'] = [x[i] for x in mean_values]\n",
    "            dataframe[f'{col}_channel_{i}_variance'] = [x[i] for x in variance_values]\n",
    "            dataframe[f'{col}_channel_{i}_kurtosis'] = [x[i] for x in kurtosis_values]\n",
    "            dataframe[f'{col}_channel_{i}_skewness'] = [x[i] for x in skewness_values]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cc9e6e-ddcb-41fe-aa4b-72e3f44afc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb\n",
      "hsv\n",
      "lab\n"
     ]
    }
   ],
   "source": [
    "color_df = color_moments(extra_resized, ['rgb','hsv','lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c245d80-93b2-4cc8-82a3-77f40ab9b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_color = color_df.drop(columns=['class','img_name','rgb','gray','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52a436e-88b8-43bc-b1d7-b17b428f0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>rgb_channel_2_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "      <th>lab_channel_2_skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.270089</td>\n",
       "      <td>3990.031165</td>\n",
       "      <td>-0.411904</td>\n",
       "      <td>0.744936</td>\n",
       "      <td>91.700953</td>\n",
       "      <td>3810.139266</td>\n",
       "      <td>-0.052213</td>\n",
       "      <td>0.715675</td>\n",
       "      <td>66.826531</td>\n",
       "      <td>4130.342437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306373</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>125.893136</td>\n",
       "      <td>75.606086</td>\n",
       "      <td>1.887396</td>\n",
       "      <td>0.218237</td>\n",
       "      <td>142.877770</td>\n",
       "      <td>139.253973</td>\n",
       "      <td>-0.707640</td>\n",
       "      <td>0.418429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199.242566</td>\n",
       "      <td>2069.785490</td>\n",
       "      <td>-1.514378</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>187.317861</td>\n",
       "      <td>2008.205226</td>\n",
       "      <td>-1.781474</td>\n",
       "      <td>-0.309983</td>\n",
       "      <td>139.516861</td>\n",
       "      <td>7895.016537</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728330</td>\n",
       "      <td>-0.350443</td>\n",
       "      <td>126.572007</td>\n",
       "      <td>37.250356</td>\n",
       "      <td>-0.824629</td>\n",
       "      <td>-0.589908</td>\n",
       "      <td>153.407805</td>\n",
       "      <td>516.292401</td>\n",
       "      <td>-1.853678</td>\n",
       "      <td>0.254570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186.096600</td>\n",
       "      <td>3007.509502</td>\n",
       "      <td>-1.814930</td>\n",
       "      <td>-0.218978</td>\n",
       "      <td>182.329321</td>\n",
       "      <td>2194.281216</td>\n",
       "      <td>-1.800756</td>\n",
       "      <td>-0.187194</td>\n",
       "      <td>135.049247</td>\n",
       "      <td>7673.218019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.818788</td>\n",
       "      <td>-0.189757</td>\n",
       "      <td>122.807617</td>\n",
       "      <td>76.436941</td>\n",
       "      <td>-1.666075</td>\n",
       "      <td>-0.225414</td>\n",
       "      <td>152.541653</td>\n",
       "      <td>431.494438</td>\n",
       "      <td>-1.912749</td>\n",
       "      <td>0.151626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.299904</td>\n",
       "      <td>3966.247111</td>\n",
       "      <td>-1.576733</td>\n",
       "      <td>-0.496616</td>\n",
       "      <td>176.301718</td>\n",
       "      <td>3005.669150</td>\n",
       "      <td>-1.622519</td>\n",
       "      <td>-0.438570</td>\n",
       "      <td>139.876574</td>\n",
       "      <td>7783.860065</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.594524</td>\n",
       "      <td>-0.460021</td>\n",
       "      <td>125.340880</td>\n",
       "      <td>60.401777</td>\n",
       "      <td>-0.872360</td>\n",
       "      <td>-0.856840</td>\n",
       "      <td>147.570592</td>\n",
       "      <td>328.878308</td>\n",
       "      <td>-1.485259</td>\n",
       "      <td>0.609684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195.866789</td>\n",
       "      <td>3836.636711</td>\n",
       "      <td>-1.119386</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>191.531848</td>\n",
       "      <td>2688.568262</td>\n",
       "      <td>-1.122789</td>\n",
       "      <td>-0.898519</td>\n",
       "      <td>164.997409</td>\n",
       "      <td>6832.874435</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.123964</td>\n",
       "      <td>-0.901373</td>\n",
       "      <td>125.377272</td>\n",
       "      <td>71.134292</td>\n",
       "      <td>-0.437482</td>\n",
       "      <td>-1.166782</td>\n",
       "      <td>142.234515</td>\n",
       "      <td>262.144242</td>\n",
       "      <td>-0.463300</td>\n",
       "      <td>1.184542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgb_channel_0_mean  rgb_channel_0_variance  rgb_channel_0_kurtosis  \\\n",
       "0           96.270089             3990.031165               -0.411904   \n",
       "1          199.242566             2069.785490               -1.514378   \n",
       "2          186.096600             3007.509502               -1.814930   \n",
       "3          183.299904             3966.247111               -1.576733   \n",
       "4          195.866789             3836.636711               -1.119386   \n",
       "\n",
       "   rgb_channel_0_skewness  rgb_channel_1_mean  rgb_channel_1_variance  \\\n",
       "0                0.744936           91.700953             3810.139266   \n",
       "1               -0.515288          187.317861             2008.205226   \n",
       "2               -0.218978          182.329321             2194.281216   \n",
       "3               -0.496616          176.301718             3005.669150   \n",
       "4               -0.906572          191.531848             2688.568262   \n",
       "\n",
       "   rgb_channel_1_kurtosis  rgb_channel_1_skewness  rgb_channel_2_mean  \\\n",
       "0               -0.052213                0.715675           66.826531   \n",
       "1               -1.781474               -0.309983          139.516861   \n",
       "2               -1.800756               -0.187194          135.049247   \n",
       "3               -1.622519               -0.438570          139.876574   \n",
       "4               -1.122789               -0.898519          164.997409   \n",
       "\n",
       "   rgb_channel_2_variance  ...  lab_channel_0_kurtosis  \\\n",
       "0             4130.342437  ...               -0.306373   \n",
       "1             7895.016537  ...               -1.728330   \n",
       "2             7673.218019  ...               -1.818788   \n",
       "3             7783.860065  ...               -1.594524   \n",
       "4             6832.874435  ...               -1.123964   \n",
       "\n",
       "   lab_channel_0_skewness  lab_channel_1_mean  lab_channel_1_variance  \\\n",
       "0                0.581436          125.893136               75.606086   \n",
       "1               -0.350443          126.572007               37.250356   \n",
       "2               -0.189757          122.807617               76.436941   \n",
       "3               -0.460021          125.340880               60.401777   \n",
       "4               -0.901373          125.377272               71.134292   \n",
       "\n",
       "   lab_channel_1_kurtosis  lab_channel_1_skewness  lab_channel_2_mean  \\\n",
       "0                1.887396                0.218237          142.877770   \n",
       "1               -0.824629               -0.589908          153.407805   \n",
       "2               -1.666075               -0.225414          152.541653   \n",
       "3               -0.872360               -0.856840          147.570592   \n",
       "4               -0.437482               -1.166782          142.234515   \n",
       "\n",
       "   lab_channel_2_variance  lab_channel_2_kurtosis  lab_channel_2_skewness  \n",
       "0              139.253973               -0.707640                0.418429  \n",
       "1              516.292401               -1.853678                0.254570  \n",
       "2              431.494438               -1.912749                0.151626  \n",
       "3              328.878308               -1.485259                0.609684  \n",
       "4              262.144242               -0.463300                1.184542  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_color.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374ff69-1bee-49c9-a127-38bf7b2154fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Zernike Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2e3d8b-9bcb-4314-8271-fbda88d99c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas.features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def zernike(df, zernike_order):\n",
    "    features_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        gray_img = row['gray']\n",
    "\n",
    "        # Check if the image is grayscale\n",
    "        if len(gray_img.shape) == 2:\n",
    "            # If grayscale, compute Zernike moments directly\n",
    "            moments = mahotas.features.zernike_moments(gray_img, radius=zernike_order)\n",
    "        else:\n",
    "            raise ValueError(\"Input image must be grayscale.\")\n",
    "\n",
    "        features_list.append(moments)\n",
    "\n",
    "    # Determine the number of features per image\n",
    "    num_features_per_image = len(features_list[0])\n",
    "\n",
    "    # Add features to the DataFrame\n",
    "    feature_columns = [f'feature_{i}' for i in range(num_features_per_image)]\n",
    "    df_features = pd.DataFrame(features_list, columns=feature_columns)\n",
    "    df_result = pd.concat([df, df_features], axis=1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2839e315-3874-4df5-9d76-5f159e11d6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.014889</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.019124</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.013850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.024526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.013213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.063308</td>\n",
       "      <td>0.051655</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.036561</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>0.023167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    0.31831   0.015994   0.005830   0.004560   0.010091   0.015493   \n",
       "1    0.31831   0.001594   0.004247   0.003555   0.011316   0.010798   \n",
       "2    0.31831   0.005007   0.008705   0.006788   0.019123   0.016181   \n",
       "3    0.31831   0.015932   0.063308   0.051655   0.003087   0.017435   \n",
       "4    0.31831   0.003166   0.010777   0.007619   0.004912   0.010917   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0   0.014889   0.002006   0.005715   0.019349  ...    0.002224    0.019971   \n",
       "1   0.020522   0.017677   0.027740   0.014565  ...    0.024135    0.019143   \n",
       "2   0.003956   0.002548   0.003154   0.013875  ...    0.007416    0.025023   \n",
       "3   0.015274   0.036561   0.007757   0.015761  ...    0.001233    0.033839   \n",
       "4   0.014197   0.007375   0.009341   0.004156  ...    0.002502    0.008668   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.032080    0.029382    0.009788    0.019124    0.006777    0.016389   \n",
       "1    0.020336    0.016388    0.015845    0.003558    0.002029    0.007313   \n",
       "2    0.029394    0.028356    0.004316    0.020854    0.006702    0.015855   \n",
       "3    0.026412    0.008598    0.007508    0.004111    0.003043    0.041183   \n",
       "4    0.026115    0.033828    0.006642    0.002440    0.006141    0.001619   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.011934    0.013850  \n",
       "1    0.008196    0.024526  \n",
       "2    0.013115    0.013213  \n",
       "3    0.010187    0.023167  \n",
       "4    0.005364    0.005747  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zernike_df = zernike(extra_resized, 10)\n",
    "f_zernike = zernike_df.iloc[:, 51:]\n",
    "f_zernike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f9f14-f5c1-49e8-bc81-0ff472678dd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Legendre Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c31faf-4303-4c2c-9116-db4207ca5f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extra_resized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11c6966-8fce-4fe6-b283-0ae5a249459b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_input = extra_resized.drop(columns=['class','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])\n",
    "l_input = l_input.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797a48fb-2cbb-4377-a2c7-c851bf96b9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>rgb</th>\n",
       "      <th>gray</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLB_single (1).jpg</td>\n",
       "      <td>[[[161, 125, 67], [163, 128, 70], [166, 132, 7...</td>\n",
       "      <td>[[129, 132, 135, 136, 136, 138, 139, 139, 137,...</td>\n",
       "      <td>96.270089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLB_single (2).jpg</td>\n",
       "      <td>[[[238, 229, 222], [238, 229, 222], [238, 229,...</td>\n",
       "      <td>[[231, 231, 231, 231, 230, 229, 230, 230, 229,...</td>\n",
       "      <td>199.242566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLB_single (3).jpg</td>\n",
       "      <td>[[[236, 225, 219], [237, 226, 220], [238, 227,...</td>\n",
       "      <td>[[228, 229, 230, 231, 231, 231, 230, 229, 230,...</td>\n",
       "      <td>186.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLB_single (4).jpg</td>\n",
       "      <td>[[[236, 223, 217], [236, 223, 217], [237, 224,...</td>\n",
       "      <td>[[226, 226, 227, 227, 227, 227, 227, 227, 227,...</td>\n",
       "      <td>183.299904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLB_single (5).jpg</td>\n",
       "      <td>[[[236, 225, 221], [236, 225, 221], [236, 225,...</td>\n",
       "      <td>[[228, 228, 228, 228, 228, 228, 228, 228, 228,...</td>\n",
       "      <td>195.866789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img_name                                                rgb  \\\n",
       "0  BLB_single (1).jpg  [[[161, 125, 67], [163, 128, 70], [166, 132, 7...   \n",
       "1  BLB_single (2).jpg  [[[238, 229, 222], [238, 229, 222], [238, 229,...   \n",
       "2  BLB_single (3).jpg  [[[236, 225, 219], [237, 226, 220], [238, 227,...   \n",
       "3  BLB_single (4).jpg  [[[236, 223, 217], [236, 223, 217], [237, 224,...   \n",
       "4  BLB_single (5).jpg  [[[236, 225, 221], [236, 225, 221], [236, 225,...   \n",
       "\n",
       "                                                gray  rgb_channel_0_mean  \n",
       "0  [[129, 132, 135, 136, 136, 138, 139, 139, 137,...           96.270089  \n",
       "1  [[231, 231, 231, 231, 230, 229, 230, 230, 229,...          199.242566  \n",
       "2  [[228, 229, 230, 231, 231, 231, 230, 229, 230,...          186.096600  \n",
       "3  [[226, 226, 227, 227, 227, 227, 227, 227, 227,...          183.299904  \n",
       "4  [[228, 228, 228, 228, 228, 228, 228, 228, 228,...          195.866789  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac178d0-3ed3-4c52-a778-5ae124e3d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.special import legendre\n",
    "\n",
    "def compute_legendre_features(rgb_image, degree):\n",
    "    # Get V channel from RGB image\n",
    "    v_channel = rgb_image[:, :, 2]\n",
    "\n",
    "    # Define x and y coordinates\n",
    "    x_size, y_size = v_channel.shape\n",
    "    x = np.linspace(-1, 1, x_size)\n",
    "    y = np.linspace(-1, 1, y_size)\n",
    "\n",
    "    # Compute Legendre features for the V channel\n",
    "    legendre_features = np.zeros((degree + 1, degree + 1))\n",
    "\n",
    "    for j in range(degree + 1):\n",
    "        for k in range(degree + 1):\n",
    "            legendre_features[j, k] = np.sum(v_channel * legendre(j)(x) * legendre(k)(y))\n",
    "\n",
    "    return legendre_features.flatten()\n",
    "\n",
    "def add_legendre(df, degree):\n",
    "    # Create a new DataFrame for Legendre features\n",
    "    legendre_columns = [f'v_legendre_{i}_{j}' for i in range(degree + 1) for j in range(degree + 1)]\n",
    "    legendre_df = pd.DataFrame(df['rgb'].apply(lambda rgb: compute_legendre_features(rgb, degree)).values.tolist(), columns=legendre_columns)\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, legendre_df], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43846dc1-14e3-448d-adc4-a22e38c851ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "legendre_df = add_legendre(l_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74b7ce3-9c49-42a7-95d2-ea2df961247b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_legendre_0_0</th>\n",
       "      <th>v_legendre_0_1</th>\n",
       "      <th>v_legendre_0_2</th>\n",
       "      <th>v_legendre_0_3</th>\n",
       "      <th>v_legendre_0_4</th>\n",
       "      <th>v_legendre_0_5</th>\n",
       "      <th>v_legendre_0_6</th>\n",
       "      <th>v_legendre_0_7</th>\n",
       "      <th>v_legendre_0_8</th>\n",
       "      <th>v_legendre_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>v_legendre_10_1</th>\n",
       "      <th>v_legendre_10_2</th>\n",
       "      <th>v_legendre_10_3</th>\n",
       "      <th>v_legendre_10_4</th>\n",
       "      <th>v_legendre_10_5</th>\n",
       "      <th>v_legendre_10_6</th>\n",
       "      <th>v_legendre_10_7</th>\n",
       "      <th>v_legendre_10_8</th>\n",
       "      <th>v_legendre_10_9</th>\n",
       "      <th>v_legendre_10_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3353088.0</td>\n",
       "      <td>-1.087238e+06</td>\n",
       "      <td>235099.508778</td>\n",
       "      <td>138969.614640</td>\n",
       "      <td>-213880.081800</td>\n",
       "      <td>32868.044026</td>\n",
       "      <td>41100.147021</td>\n",
       "      <td>-22057.604276</td>\n",
       "      <td>4093.363361</td>\n",
       "      <td>4959.005446</td>\n",
       "      <td>...</td>\n",
       "      <td>-6311.718764</td>\n",
       "      <td>17134.386705</td>\n",
       "      <td>-4354.325125</td>\n",
       "      <td>21434.136965</td>\n",
       "      <td>-4999.513654</td>\n",
       "      <td>-16770.059701</td>\n",
       "      <td>9646.856903</td>\n",
       "      <td>18634.297732</td>\n",
       "      <td>-77270.510962</td>\n",
       "      <td>171556.758187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000398.0</td>\n",
       "      <td>-1.647153e+05</td>\n",
       "      <td>16993.528324</td>\n",
       "      <td>1784.367334</td>\n",
       "      <td>35445.715279</td>\n",
       "      <td>-2965.453418</td>\n",
       "      <td>31875.111977</td>\n",
       "      <td>-940.235712</td>\n",
       "      <td>29365.092505</td>\n",
       "      <td>-4259.342104</td>\n",
       "      <td>...</td>\n",
       "      <td>-3207.796386</td>\n",
       "      <td>32476.086937</td>\n",
       "      <td>-2489.962161</td>\n",
       "      <td>33577.290543</td>\n",
       "      <td>-2410.030008</td>\n",
       "      <td>34908.447337</td>\n",
       "      <td>-1957.168143</td>\n",
       "      <td>33858.993532</td>\n",
       "      <td>-14522.080791</td>\n",
       "      <td>367208.435549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6776231.0</td>\n",
       "      <td>-4.040194e+04</td>\n",
       "      <td>94178.452151</td>\n",
       "      <td>-28337.376132</td>\n",
       "      <td>38294.200615</td>\n",
       "      <td>2442.323361</td>\n",
       "      <td>29519.886739</td>\n",
       "      <td>573.809983</td>\n",
       "      <td>32319.438140</td>\n",
       "      <td>-2597.708766</td>\n",
       "      <td>...</td>\n",
       "      <td>-2207.567426</td>\n",
       "      <td>34574.201478</td>\n",
       "      <td>-962.117115</td>\n",
       "      <td>34265.410875</td>\n",
       "      <td>-840.786748</td>\n",
       "      <td>35865.336257</td>\n",
       "      <td>-4235.821516</td>\n",
       "      <td>42533.736921</td>\n",
       "      <td>-5801.509097</td>\n",
       "      <td>361853.335579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7018447.0</td>\n",
       "      <td>9.445593e+04</td>\n",
       "      <td>6862.907016</td>\n",
       "      <td>4972.047285</td>\n",
       "      <td>39488.004341</td>\n",
       "      <td>2049.562175</td>\n",
       "      <td>27225.615815</td>\n",
       "      <td>-3893.297024</td>\n",
       "      <td>36188.794809</td>\n",
       "      <td>4373.071135</td>\n",
       "      <td>...</td>\n",
       "      <td>3169.501812</td>\n",
       "      <td>34547.292349</td>\n",
       "      <td>401.307337</td>\n",
       "      <td>33508.846870</td>\n",
       "      <td>1111.812538</td>\n",
       "      <td>35333.013038</td>\n",
       "      <td>1912.006198</td>\n",
       "      <td>33394.064995</td>\n",
       "      <td>8572.133821</td>\n",
       "      <td>367697.941762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8278910.0</td>\n",
       "      <td>-7.859323e+04</td>\n",
       "      <td>13974.904824</td>\n",
       "      <td>924.369355</td>\n",
       "      <td>43248.444176</td>\n",
       "      <td>-1325.024786</td>\n",
       "      <td>36822.544836</td>\n",
       "      <td>-309.008812</td>\n",
       "      <td>39155.165133</td>\n",
       "      <td>-2002.215996</td>\n",
       "      <td>...</td>\n",
       "      <td>-1352.400608</td>\n",
       "      <td>40153.183075</td>\n",
       "      <td>-1015.441145</td>\n",
       "      <td>40220.085810</td>\n",
       "      <td>-1162.845594</td>\n",
       "      <td>41754.143653</td>\n",
       "      <td>-913.967013</td>\n",
       "      <td>39824.164348</td>\n",
       "      <td>-6934.850970</td>\n",
       "      <td>434175.385973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v_legendre_0_0  v_legendre_0_1  v_legendre_0_2  v_legendre_0_3  \\\n",
       "0       3353088.0   -1.087238e+06   235099.508778   138969.614640   \n",
       "1       7000398.0   -1.647153e+05    16993.528324     1784.367334   \n",
       "2       6776231.0   -4.040194e+04    94178.452151   -28337.376132   \n",
       "3       7018447.0    9.445593e+04     6862.907016     4972.047285   \n",
       "4       8278910.0   -7.859323e+04    13974.904824      924.369355   \n",
       "\n",
       "   v_legendre_0_4  v_legendre_0_5  v_legendre_0_6  v_legendre_0_7  \\\n",
       "0  -213880.081800    32868.044026    41100.147021   -22057.604276   \n",
       "1    35445.715279    -2965.453418    31875.111977     -940.235712   \n",
       "2    38294.200615     2442.323361    29519.886739      573.809983   \n",
       "3    39488.004341     2049.562175    27225.615815    -3893.297024   \n",
       "4    43248.444176    -1325.024786    36822.544836     -309.008812   \n",
       "\n",
       "   v_legendre_0_8  v_legendre_0_9  ...  v_legendre_10_1  v_legendre_10_2  \\\n",
       "0     4093.363361     4959.005446  ...     -6311.718764     17134.386705   \n",
       "1    29365.092505    -4259.342104  ...     -3207.796386     32476.086937   \n",
       "2    32319.438140    -2597.708766  ...     -2207.567426     34574.201478   \n",
       "3    36188.794809     4373.071135  ...      3169.501812     34547.292349   \n",
       "4    39155.165133    -2002.215996  ...     -1352.400608     40153.183075   \n",
       "\n",
       "   v_legendre_10_3  v_legendre_10_4  v_legendre_10_5  v_legendre_10_6  \\\n",
       "0     -4354.325125     21434.136965     -4999.513654    -16770.059701   \n",
       "1     -2489.962161     33577.290543     -2410.030008     34908.447337   \n",
       "2      -962.117115     34265.410875      -840.786748     35865.336257   \n",
       "3       401.307337     33508.846870      1111.812538     35333.013038   \n",
       "4     -1015.441145     40220.085810     -1162.845594     41754.143653   \n",
       "\n",
       "   v_legendre_10_7  v_legendre_10_8  v_legendre_10_9  v_legendre_10_10  \n",
       "0      9646.856903     18634.297732    -77270.510962     171556.758187  \n",
       "1     -1957.168143     33858.993532    -14522.080791     367208.435549  \n",
       "2     -4235.821516     42533.736921     -5801.509097     361853.335579  \n",
       "3      1912.006198     33394.064995      8572.133821     367697.941762  \n",
       "4      -913.967013     39824.164348     -6934.850970     434175.385973  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_legendre = legendre_df.iloc[:, 4:]\n",
    "f_legendre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bb6a4-6f30-4f3c-8b50-0bad0e8b6c75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Complete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5931a6-4d94-44df-8c1a-82076732f0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with just the selected column\n",
    "classes = pd.DataFrame(extra_resized['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5002378-98b0-4b70-ba29-a07ba57764f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#complete_features = pd.concat([classes,f_color,f_histogram, f_glcm], axis=1)\n",
    "complete_features = pd.concat([classes,f_histogram, f_glcm, f_color, f_legendre, f_zernike], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "060e531f-0a6e-455b-8dbf-07ca777d8c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>373</td>\n",
       "      <td>484</td>\n",
       "      <td>879</td>\n",
       "      <td>1088</td>\n",
       "      <td>1006</td>\n",
       "      <td>1012</td>\n",
       "      <td>832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.019124</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.013850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.024526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.013213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>0.023167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  red_1  red_2  red_3  red_4  red_5  red_6  red_7  \\\n",
       "0  bacterial_leaf_blight    175    390    373    484    879   1088   1006   \n",
       "1  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "2  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "3  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "4  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "\n",
       "   red_8  red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0   1012    832  ...    0.002224    0.019971    0.032080    0.029382   \n",
       "1      0      0  ...    0.024135    0.019143    0.020336    0.016388   \n",
       "2      0      0  ...    0.007416    0.025023    0.029394    0.028356   \n",
       "3      0      0  ...    0.001233    0.033839    0.026412    0.008598   \n",
       "4      0      0  ...    0.002502    0.008668    0.026115    0.033828   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.009788    0.019124    0.006777    0.016389    0.011934    0.013850  \n",
       "1    0.015845    0.003558    0.002029    0.007313    0.008196    0.024526  \n",
       "2    0.004316    0.020854    0.006702    0.015855    0.013115    0.013213  \n",
       "3    0.007508    0.004111    0.003043    0.041183    0.010187    0.023167  \n",
       "4    0.006642    0.002440    0.006141    0.001619    0.005364    0.005747  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93653fd4-c7c1-4763-ab89-2102d2f29c4c",
   "metadata": {},
   "source": [
    "# Data Normalization and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80096471-c274-4870-bea1-05b14edc651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe(df):\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Extract numerical columns (assuming only numerical columns need normalization)\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply normalization to each numerical column\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b235b92a-228e-4021-975a-b860cafec988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.032128</td>\n",
       "      <td>0.03783</td>\n",
       "      <td>0.02203</td>\n",
       "      <td>0.135732</td>\n",
       "      <td>0.095615</td>\n",
       "      <td>0.138263</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.283572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>0.144965</td>\n",
       "      <td>0.223467</td>\n",
       "      <td>0.219293</td>\n",
       "      <td>0.061088</td>\n",
       "      <td>0.135918</td>\n",
       "      <td>0.056597</td>\n",
       "      <td>0.158638</td>\n",
       "      <td>0.092182</td>\n",
       "      <td>0.116852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182499</td>\n",
       "      <td>0.138646</td>\n",
       "      <td>0.139402</td>\n",
       "      <td>0.121577</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.066894</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054738</td>\n",
       "      <td>0.183517</td>\n",
       "      <td>0.204241</td>\n",
       "      <td>0.211581</td>\n",
       "      <td>0.026646</td>\n",
       "      <td>0.148234</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.111160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.250792</td>\n",
       "      <td>0.182894</td>\n",
       "      <td>0.062999</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.024150</td>\n",
       "      <td>0.409268</td>\n",
       "      <td>0.078012</td>\n",
       "      <td>0.200142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017186</td>\n",
       "      <td>0.058709</td>\n",
       "      <td>0.180770</td>\n",
       "      <td>0.252727</td>\n",
       "      <td>0.041288</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>0.051073</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>0.044423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class     red_1     red_2    red_3    red_4     red_5  \\\n",
       "0  bacterial_leaf_blight  0.015877  0.032128  0.03783  0.02203  0.135732   \n",
       "1  bacterial_leaf_blight  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "2  bacterial_leaf_blight  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "3  bacterial_leaf_blight  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "4  bacterial_leaf_blight  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "\n",
       "      red_6     red_7     red_8     red_9  ...  feature_15  feature_16  \\\n",
       "0  0.095615  0.138263  0.314286  0.283572  ...    0.015064    0.144965   \n",
       "1  0.000000  0.000000  0.000000  0.000000  ...    0.182499    0.138646   \n",
       "2  0.000000  0.000000  0.000000  0.000000  ...    0.054738    0.183517   \n",
       "3  0.000000  0.000000  0.000000  0.000000  ...    0.007488    0.250792   \n",
       "4  0.000000  0.000000  0.000000  0.000000  ...    0.017186    0.058709   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.223467    0.219293    0.061088    0.135918    0.056597    0.158638   \n",
       "1    0.139402    0.121577    0.099206    0.025037    0.015334    0.066894   \n",
       "2    0.204241    0.211581    0.026646    0.148234    0.055950    0.153247   \n",
       "3    0.182894    0.062999    0.046734    0.028980    0.024150    0.409268   \n",
       "4    0.180770    0.252727    0.041288    0.017076    0.051073    0.009342   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.092182    0.116852  \n",
       "1    0.061873    0.212293  \n",
       "2    0.101754    0.111160  \n",
       "3    0.078012    0.200142  \n",
       "4    0.038911    0.044423  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features = normalize_dataframe(complete_features)\n",
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b339da2-35a0-455d-8db7-266f056dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_features['class'] = label_encoder.fit_transform(normalized_features['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "097defd8-e917-45e2-a877-dfe178bfe066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.032128</td>\n",
       "      <td>0.03783</td>\n",
       "      <td>0.02203</td>\n",
       "      <td>0.135732</td>\n",
       "      <td>0.095615</td>\n",
       "      <td>0.138263</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.283572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>0.144965</td>\n",
       "      <td>0.223467</td>\n",
       "      <td>0.219293</td>\n",
       "      <td>0.061088</td>\n",
       "      <td>0.135918</td>\n",
       "      <td>0.056597</td>\n",
       "      <td>0.158638</td>\n",
       "      <td>0.092182</td>\n",
       "      <td>0.116852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182499</td>\n",
       "      <td>0.138646</td>\n",
       "      <td>0.139402</td>\n",
       "      <td>0.121577</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.066894</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054738</td>\n",
       "      <td>0.183517</td>\n",
       "      <td>0.204241</td>\n",
       "      <td>0.211581</td>\n",
       "      <td>0.026646</td>\n",
       "      <td>0.148234</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.111160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.250792</td>\n",
       "      <td>0.182894</td>\n",
       "      <td>0.062999</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.024150</td>\n",
       "      <td>0.409268</td>\n",
       "      <td>0.078012</td>\n",
       "      <td>0.200142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017186</td>\n",
       "      <td>0.058709</td>\n",
       "      <td>0.180770</td>\n",
       "      <td>0.252727</td>\n",
       "      <td>0.041288</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>0.051073</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>0.044423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class     red_1     red_2    red_3    red_4     red_5     red_6     red_7  \\\n",
       "0      0  0.015877  0.032128  0.03783  0.02203  0.135732  0.095615  0.138263   \n",
       "1      0  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000   \n",
       "2      0  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000   \n",
       "3      0  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000   \n",
       "4      0  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      red_8     red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0  0.314286  0.283572  ...    0.015064    0.144965    0.223467    0.219293   \n",
       "1  0.000000  0.000000  ...    0.182499    0.138646    0.139402    0.121577   \n",
       "2  0.000000  0.000000  ...    0.054738    0.183517    0.204241    0.211581   \n",
       "3  0.000000  0.000000  ...    0.007488    0.250792    0.182894    0.062999   \n",
       "4  0.000000  0.000000  ...    0.017186    0.058709    0.180770    0.252727   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.061088    0.135918    0.056597    0.158638    0.092182    0.116852  \n",
       "1    0.099206    0.025037    0.015334    0.066894    0.061873    0.212293  \n",
       "2    0.026646    0.148234    0.055950    0.153247    0.101754    0.111160  \n",
       "3    0.046734    0.028980    0.024150    0.409268    0.078012    0.200142  \n",
       "4    0.041288    0.017076    0.051073    0.009342    0.038911    0.044423  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0bcdc0-7857-48da-b88e-f8e53d6e2590",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77638c94-04af-43fb-a1db-0548a9c497cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acc8851d-dc36-4634-8d2f-8a3016c14ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def custom_train_test_split(dataframe, target_column, test_size=0.2, random_state=None):\n",
    "    # Separate features and labels\n",
    "    X = dataframe.drop(target_column, axis=1)  # Features\n",
    "    y = dataframe[target_column]  # Labels\n",
    "\n",
    "    # Perform the train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53594f6d-e920-4b66-91d8-7ba1ad60e4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = custom_train_test_split(normalized_features, 'class', test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "165bd148-e43b-401d-94a1-24f08ca4ef46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features (all columns except the first)\n",
    "x_d = normalized_features.iloc[:, 1:].values\n",
    "\n",
    "# Extract target variable (first column)\n",
    "y_d = normalized_features.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4e754-433d-4633-8ed7-21cfb29a579a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**SVM Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d22a348-215f-4374-8a06-aac852e1ba66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_svm_classifier(X_train, y_train, X_test, y_test, kernel='linear', C=1.0):\n",
    "    # Create an SVM classifier\n",
    "    svm_classifier = SVC(kernel=kernel, C=C)\n",
    "\n",
    "    # Train the classifier\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return svm_classifier, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f81072ab-be75-4726-b02f-2e2e0c235415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.98%\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM classifier using the function\n",
    "trained_svm_classifier, accuracy = train_svm_classifier(x_tr, y_tr, x_te, y_te, kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e3ad0-ac62-4b28-93b4-99d1600ec588",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Selection PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ca9bed2-f735-4f13-af9a-a004073cb92f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 0.99\n",
      "(703, 206)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.991\n",
      "(703, 213)\n",
      "Accuracy: 0.9290780141843972\n",
      "var: 0.992\n",
      "(703, 222)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.993\n",
      "(703, 231)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.994\n",
      "(703, 242)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.995\n",
      "(703, 255)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.996\n",
      "(703, 271)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.997\n",
      "(703, 291)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.998\n",
      "(703, 320)\n",
      "Accuracy: 0.9361702127659575\n",
      "var: 0.999\n",
      "(703, 367)\n",
      "Accuracy: 0.9361702127659575\n",
      "Best Accuracy: 0.9361702127659575\n",
      "Trimmed x_d with Best Selected Features:\n",
      "(703, 206)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def apply_pca_for_feature_selection(X, desired_variance_ratio):\n",
    "    pca = PCA(n_components=desired_variance_ratio)\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "    return reduced_features, pca\n",
    "\n",
    "def pca(X, y, test_size=0.2, random_state=42):\n",
    "\n",
    "    variance_ratios = [i / 1000 for i in range(990, 1000)]\n",
    "    max_accuracy = 0.0\n",
    "    best_selected_features = None\n",
    "    best_pca_model = None\n",
    "\n",
    "    for desired_variance_ratio in variance_ratios:\n",
    "        reduced_features, pca_model = apply_pca_for_feature_selection(X, desired_variance_ratio)\n",
    "        print(f\"var: {desired_variance_ratio}\")\n",
    "        print(np.shape(reduced_features))\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduced_features, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # Create an SVM classifier\n",
    "        svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "        # Train the SVM classifier using the selected features\n",
    "        svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "        # Evaluate the performance of the SVM classifier\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "        # Update max accuracy and store corresponding features\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            best_selected_features = reduced_features.copy()\n",
    "            best_pca_model = pca_model\n",
    "\n",
    "    # Apply inverse_transform to the full dataset with the best selected features\n",
    "    trimmed_x_d = best_pca_model.inverse_transform(best_selected_features)\n",
    "\n",
    "    return best_selected_features, max_accuracy\n",
    "\n",
    "# Example usage:\n",
    "reduced_x_d, max_accuracy = pca(x_d, y_d)\n",
    "print(f\"Best Accuracy: {max_accuracy}\")\n",
    "print(\"Trimmed x_d with Best Selected Features:\")\n",
    "print(np.shape(reduced_x_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7077ef71-d0ad-4f60-b848-0589d7b4c39a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming X is your feature matrix and y is the target variable\n",
    "correlation_matrix = np.corrcoef(x_d, rowvar=False)\n",
    "correlation_with_target = np.abs(correlation_matrix[-1, :-1])  # Assuming the last row is the target variable\n",
    "selected_features = np.where(correlation_with_target < .4)[0]\n",
    "np.shape(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f9ac88-d54e-4886-8ee7-35e0801ec9fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def svm_classifier_with_rfe(X_train, X_test, y_train, y_test, num_features_to_select=3):\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    \n",
    "    rfe = RFE(estimator=svm_classifier, n_features_to_select=num_features_to_select)\n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "    svm_classifier.fit(X_train_rfe, y_train)\n",
    "\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    y_pred = svm_classifier.predict(X_test_rfe)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    selected_features = [f'Feature {i + 1}' for i, selected in enumerate(rfe.support_) if selected]\n",
    "\n",
    "    return accuracy, selected_features\n",
    "\n",
    "def run_experiment(num_features):\n",
    "    result_accuracy, selected_features = svm_classifier_with_rfe(X_train, X_test, y_train, y_test, num_features)\n",
    "    return num_features, result_accuracy, selected_features\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_d, y_d, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parallelize the loop\n",
    "num_features_range = range(1, 140)\n",
    "results = Parallel(n_jobs=-1)(delayed(run_experiment)(i) for i in num_features_range)\n",
    "\n",
    "# Print the results after the loop\n",
    "for num_features, accuracy, selected_features in results:\n",
    "    print(f'Number of features: {num_features}, Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801fac45-a849-4eec-b324-b9a534fbadcc",
   "metadata": {},
   "source": [
    "## SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "566ab918-9f84-4926-ac7a-bc73dc22e68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Test Accuracy: 95.04%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = reduced_x_d\n",
    "y = y_d\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 200, 300],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', .001, .01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_accuracy = best_svm_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73765a37-399f-441b-abcf-dd92e0e942a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       1.00      0.88      0.93         8\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       0.89      0.80      0.84        10\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       0.91      1.00      0.95        10\n",
      "           8       0.89      0.89      0.89         9\n",
      "           9       0.86      0.86      0.86         7\n",
      "          10       1.00      0.90      0.95        10\n",
      "          11       0.89      1.00      0.94         8\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.95       141\n",
      "   macro avg       0.95      0.95      0.95       141\n",
      "weighted avg       0.95      0.95      0.95       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are defined earlier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 200, 300],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', .001, .01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d94f218e-dcbf-4c8e-a8f9-d7d3ef41616a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       0.89      0.80      0.84        10\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       0.91      1.00      0.95        10\n",
      "           8       1.00      0.89      0.94         9\n",
      "           9       0.86      0.86      0.86         7\n",
      "          10       1.00      0.90      0.95        10\n",
      "          11       0.89      1.00      0.94         8\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.96       141\n",
      "   macro avg       0.96      0.96      0.96       141\n",
      "weighted avg       0.96      0.96      0.96       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are defined earlier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the best hyperparameters obtained from the grid search\n",
    "best_params = {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "\n",
    "# Build an SVM model with the best hyperparameters\n",
    "best_svm_model = SVC(**best_params)\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# # Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=best_svm_model.classes_, yticklabels=best_svm_model.classes_)\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix[0])):\n",
    "        if i == j:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='white')\n",
    "        else:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='black')\n",
    "            \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9575ccbb-0c05-4c10-b98c-04f55e32abf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       1.00      0.88      0.93         8\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       0.89      0.80      0.84        10\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       0.91      1.00      0.95        10\n",
      "           8       0.89      0.89      0.89         9\n",
      "           9       0.86      0.86      0.86         7\n",
      "          10       1.00      0.90      0.95        10\n",
      "          11       0.89      1.00      0.94         8\n",
      "          12       1.00      1.00      1.00        12\n",
      "          13       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.95       141\n",
      "   macro avg       0.95      0.95      0.95       141\n",
      "weighted avg       0.95      0.95      0.95       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are defined earlier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 200, 300],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', .001, .01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b4890-0ac4-4c6d-b3c1-9acf0c770916",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "705fec05-d73e-470c-9a2b-d71b16d96f36",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "17/17 [==============================] - 2s 26ms/step - loss: 2.2872 - accuracy: 0.3021 - val_loss: 1.5020 - val_accuracy: 0.7586\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.3725 - accuracy: 0.6567 - val_loss: 0.8655 - val_accuracy: 0.8276\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8887 - accuracy: 0.7749 - val_loss: 0.6453 - val_accuracy: 0.8966\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.8612 - val_loss: 0.4983 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.8931 - val_loss: 0.4114 - val_accuracy: 0.8966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.9156 - val_loss: 0.3772 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9493 - val_loss: 0.3327 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9606 - val_loss: 0.3248 - val_accuracy: 0.8621\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9719 - val_loss: 0.2932 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9812 - val_loss: 0.2897 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.9887 - val_loss: 0.2842 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9869 - val_loss: 0.2579 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9925 - val_loss: 0.2652 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.9944 - val_loss: 0.2602 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9962 - val_loss: 0.2589 - val_accuracy: 0.8966\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9655\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.8966\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9655\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.8966\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.9304e-04 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.6427e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.3963e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.1337e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.9194e-04 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6951e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4612e-04 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2394e-04 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0402e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8156e-04 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6349e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4480e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.2448e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.0854e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9329e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.7516e-04 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5977e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.4398e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3075e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.9007\n",
      "\n",
      "Test accuracy: 0.9007092118263245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have your data in x_d and y_d\n",
    "X = x_d\n",
    "y = y_d\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c715fbb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(X_test_scaled)\n",
    "# predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "# np.savetxt('test_predictions.csv', np.hstack((predicted_labels.reshape(-1, 1), y_test.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "# # np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601026b",
   "metadata": {},
   "source": [
    "## Feature Selection PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05c4b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 0.99\n",
      "(703, 206)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 21ms/step - loss: 2.3243 - accuracy: 0.2833 - val_loss: 1.7626 - val_accuracy: 0.5172\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4160 - accuracy: 0.6304 - val_loss: 1.1442 - val_accuracy: 0.7586\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9458 - accuracy: 0.7580 - val_loss: 0.8160 - val_accuracy: 0.7586\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.8274 - val_loss: 0.6118 - val_accuracy: 0.8621\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.8799 - val_loss: 0.4818 - val_accuracy: 0.8276\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.9193 - val_loss: 0.4064 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.9493 - val_loss: 0.3669 - val_accuracy: 0.8621\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9606 - val_loss: 0.3501 - val_accuracy: 0.8966\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.9794 - val_loss: 0.3322 - val_accuracy: 0.9310\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9850 - val_loss: 0.3231 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9812 - val_loss: 0.3082 - val_accuracy: 0.9310\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.9869 - val_loss: 0.3128 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9962 - val_loss: 0.2986 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9981 - val_loss: 0.2987 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9981 - val_loss: 0.2914 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9981 - val_loss: 0.3027 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7654e-04 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.5093e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.2484e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.9947e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.7571e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.5292e-04 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.3451e-04 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1075e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9069e-04 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7087e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.5184e-04 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.3587e-04 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.1550e-04 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9789e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.8312e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.6622e-04 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.5057e-04 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3673e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2076e-04 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.0630e-04 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.8723\n",
      "\n",
      "Test accuracy: 0.8723404407501221\n",
      "var: 0.991\n",
      "(703, 213)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 20ms/step - loss: 2.3395 - accuracy: 0.2364 - val_loss: 1.5812 - val_accuracy: 0.5172\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.4349 - accuracy: 0.5929 - val_loss: 0.9469 - val_accuracy: 0.7931\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9405 - accuracy: 0.7598 - val_loss: 0.6140 - val_accuracy: 0.8621\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6484 - accuracy: 0.8199 - val_loss: 0.4763 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.8724 - val_loss: 0.3835 - val_accuracy: 0.8966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.9118 - val_loss: 0.3538 - val_accuracy: 0.8966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.9400 - val_loss: 0.3255 - val_accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9606 - val_loss: 0.2843 - val_accuracy: 0.8966\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1768 - accuracy: 0.9737 - val_loss: 0.2741 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1424 - accuracy: 0.9756 - val_loss: 0.2592 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9812 - val_loss: 0.2496 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9887 - val_loss: 0.2351 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9981 - val_loss: 0.2435 - val_accuracy: 0.8966\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9906 - val_loss: 0.2121 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9981 - val_loss: 0.2381 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9655\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7697e-04 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.5229e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.2523e-04 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.0116e-04 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.7413e-04 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4993e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2673e-04 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0656e-04 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.8356e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6283e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.4351e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2504e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.0995e-04 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.8912e-04 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.7389e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5696e-04 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.4033e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2672e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.1026e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.9548e-04 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.8192e-04 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.6842e-04 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.5660e-04 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.8936\n",
      "\n",
      "Test accuracy: 0.8936170339584351\n",
      "var: 0.992\n",
      "(703, 222)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 2s 21ms/step - loss: 2.4321 - accuracy: 0.2458 - val_loss: 1.7429 - val_accuracy: 0.3793\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5934 - accuracy: 0.5347 - val_loss: 1.2061 - val_accuracy: 0.6897\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1418 - accuracy: 0.6961 - val_loss: 0.8469 - val_accuracy: 0.8276\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8211 - accuracy: 0.8011 - val_loss: 0.6362 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.8480 - val_loss: 0.5360 - val_accuracy: 0.8621\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.8856 - val_loss: 0.4702 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.9156 - val_loss: 0.4202 - val_accuracy: 0.9655\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.9325 - val_loss: 0.4184 - val_accuracy: 0.9655\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2316 - accuracy: 0.9456 - val_loss: 0.4021 - val_accuracy: 0.9655\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9606 - val_loss: 0.3951 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9644 - val_loss: 0.3903 - val_accuracy: 0.9655\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9719 - val_loss: 0.3795 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9775 - val_loss: 0.3926 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9887 - val_loss: 0.3839 - val_accuracy: 0.9655\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9962 - val_loss: 0.3885 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9655\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9655\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9655\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9655\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9655\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9655\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9655\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9655\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9655\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9655\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9655\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.9042e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.6569e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 9.3586e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 9.0958e-04 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 8.8468e-04 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.6022e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 8.3919e-04 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.1937e-04 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.9473e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7480e-04 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.5462e-04 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.3696e-04 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.1613e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9982e-04 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.8110e-04 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.6368e-04 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.4831e-04 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3252e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.1781e-04 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.0328e-04 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.8810e-04 - accuracy: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.7618e-04 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.8936\n",
      "\n",
      "Test accuracy: 0.8936170339584351\n",
      "var: 0.993\n",
      "(703, 231)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 20ms/step - loss: 2.4368 - accuracy: 0.2495 - val_loss: 1.6858 - val_accuracy: 0.4828\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5291 - accuracy: 0.5460 - val_loss: 1.1815 - val_accuracy: 0.6897\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0201 - accuracy: 0.7561 - val_loss: 0.8027 - val_accuracy: 0.8276\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7093 - accuracy: 0.8293 - val_loss: 0.6000 - val_accuracy: 0.8276\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.8705 - val_loss: 0.4758 - val_accuracy: 0.8966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.9099 - val_loss: 0.4328 - val_accuracy: 0.8966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.9400 - val_loss: 0.3854 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9625 - val_loss: 0.3690 - val_accuracy: 0.9310\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9700 - val_loss: 0.3416 - val_accuracy: 0.9310\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9756 - val_loss: 0.3468 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9794 - val_loss: 0.3331 - val_accuracy: 0.9310\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9906 - val_loss: 0.3354 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9887 - val_loss: 0.3546 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9944 - val_loss: 0.3448 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9962 - val_loss: 0.3504 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9981 - val_loss: 0.3450 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 9.9181e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.6925e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.3673e-04 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.1171e-04 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.9072e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.6545e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.4243e-04 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.1982e-04 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.9949e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.7997e-04 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.5927e-04 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4067e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2476e-04 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.0396e-04 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.8900e-04 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.7070e-04 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5706e-04 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3816e-04 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2647e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.0976e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.9574e-04 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8955 - accuracy: 0.9078\n",
      "\n",
      "Test accuracy: 0.9078013896942139\n",
      "var: 0.994\n",
      "(703, 242)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 21ms/step - loss: 2.3289 - accuracy: 0.3246 - val_loss: 1.6095 - val_accuracy: 0.5862\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.4464 - accuracy: 0.5966 - val_loss: 1.1104 - val_accuracy: 0.6897\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.9901 - accuracy: 0.7073 - val_loss: 0.8714 - val_accuracy: 0.6897\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.7208 - accuracy: 0.8086 - val_loss: 0.6981 - val_accuracy: 0.8276\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.8668 - val_loss: 0.5670 - val_accuracy: 0.8276\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.9043 - val_loss: 0.4601 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.9231 - val_loss: 0.3899 - val_accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2323 - accuracy: 0.9512 - val_loss: 0.3764 - val_accuracy: 0.8966\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9681 - val_loss: 0.3472 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1437 - accuracy: 0.9737 - val_loss: 0.3343 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9887 - val_loss: 0.3338 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9925 - val_loss: 0.3098 - val_accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9944 - val_loss: 0.3049 - val_accuracy: 0.8621\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9962 - val_loss: 0.3168 - val_accuracy: 0.8966\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9981 - val_loss: 0.2956 - val_accuracy: 0.8621\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.8966\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8966\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.8966\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.8966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.8621\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.8966\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.8966\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.8966\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.8966\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.8621\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.8966\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.8966\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8966\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7665e-04 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.4828e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.2128e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.9664e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.7375e-04 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.5029e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2708e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0627e-04 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8781e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7014e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.5160e-04 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.3101e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.1356e-04 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.9471e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.7836e-04 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.6122e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.4757e-04 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3188e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.1718e-04 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.0235e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.9055e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.7610e-04 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.9149\n",
      "\n",
      "Test accuracy: 0.914893627166748\n",
      "var: 0.995\n",
      "(703, 255)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 22ms/step - loss: 2.1876 - accuracy: 0.3246 - val_loss: 1.5171 - val_accuracy: 0.5172\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3174 - accuracy: 0.6585 - val_loss: 1.0257 - val_accuracy: 0.6897\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8776 - accuracy: 0.7580 - val_loss: 0.7075 - val_accuracy: 0.8966\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.8311 - val_loss: 0.5138 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8724 - val_loss: 0.4370 - val_accuracy: 0.8966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.9081 - val_loss: 0.3824 - val_accuracy: 0.8966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.9381 - val_loss: 0.3327 - val_accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2314 - accuracy: 0.9587 - val_loss: 0.2977 - val_accuracy: 0.9310\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1845 - accuracy: 0.9756 - val_loss: 0.2995 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9812 - val_loss: 0.2586 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.9850 - val_loss: 0.2480 - val_accuracy: 0.9655\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9925 - val_loss: 0.2436 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9944 - val_loss: 0.2298 - val_accuracy: 0.9655\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9944 - val_loss: 0.2214 - val_accuracy: 0.9655\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9981 - val_loss: 0.2308 - val_accuracy: 0.9655\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9655\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.9583e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.6846e-04 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.3905e-04 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.1494e-04 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.8958e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6802e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4252e-04 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.2359e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0139e-04 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8081e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6021e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4041e-04 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2328e-04 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.0529e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.8702e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.6980e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5674e-04 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3936e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2355e-04 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.0970e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.9479e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.8175e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.6828e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.5464e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7659 - accuracy: 0.9149\n",
      "\n",
      "Test accuracy: 0.914893627166748\n",
      "var: 0.996\n",
      "(703, 271)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 21ms/step - loss: 2.3133 - accuracy: 0.3002 - val_loss: 1.6268 - val_accuracy: 0.5172\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.3910 - accuracy: 0.5966 - val_loss: 1.1301 - val_accuracy: 0.6207\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.9433 - accuracy: 0.7655 - val_loss: 0.8184 - val_accuracy: 0.7931\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.8405 - val_loss: 0.6331 - val_accuracy: 0.8276\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.8893 - val_loss: 0.5001 - val_accuracy: 0.8621\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.9118 - val_loss: 0.4548 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3096 - accuracy: 0.9250 - val_loss: 0.4005 - val_accuracy: 0.8621\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2469 - accuracy: 0.9512 - val_loss: 0.3808 - val_accuracy: 0.8621\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9568 - val_loss: 0.3575 - val_accuracy: 0.8621\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9719 - val_loss: 0.3347 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1274 - accuracy: 0.9812 - val_loss: 0.3255 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9906 - val_loss: 0.3319 - val_accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9944 - val_loss: 0.3289 - val_accuracy: 0.8966\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9962 - val_loss: 0.3284 - val_accuracy: 0.8966\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9981 - val_loss: 0.3163 - val_accuracy: 0.8966\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9981 - val_loss: 0.3192 - val_accuracy: 0.8966\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.8966\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.8966\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.8966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.8966\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.8966\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.8966\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.8966\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.8966\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.8966\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.8966\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.8966\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.8966\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.8966\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.8966\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.8966\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.8966\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.8966\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.8966\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.8966\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.8966\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.8966\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.8966\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.8966\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.8966\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.8966\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.8966\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8966\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.8966\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.8966\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8966\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.8966\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.8966\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.8966\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8966\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.8966\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8966\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.8966\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.8966\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.8966\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.8966\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.8966\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.8966\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.8966\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.8966\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.8966\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8966\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.8966\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.8966\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.8966\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.8966\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.8966\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8966\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.8966\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.8966\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.8966\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8966\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.8966\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.8966\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.8966\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.8966\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.7934e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8966\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.4869e-04 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.8966\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.2136e-04 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.8966\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.0036e-04 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.8966\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 8.7350e-04 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.8966\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4834e-04 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.8966\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.2622e-04 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.8966\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.0745e-04 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8966\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8531e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.8966\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6538e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8966\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4781e-04 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.8966\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2794e-04 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8966\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.0995e-04 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8966\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9231e-04 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.8966\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.7597e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.8966\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.6137e-04 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.8966\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.4433e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8966\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2821e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.8966\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.1594e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8966\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.0016e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8966\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 5.8741e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8966\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.7330e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8966\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.6032e-04 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8966\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.8723\n",
      "\n",
      "Test accuracy: 0.8723404407501221\n",
      "var: 0.997\n",
      "(703, 291)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 22ms/step - loss: 2.2611 - accuracy: 0.2833 - val_loss: 1.3811 - val_accuracy: 0.6552\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2372 - accuracy: 0.6904 - val_loss: 0.9969 - val_accuracy: 0.7241\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.8168 - accuracy: 0.8049 - val_loss: 0.7258 - val_accuracy: 0.7931\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5784 - accuracy: 0.8743 - val_loss: 0.5443 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.9099 - val_loss: 0.4299 - val_accuracy: 0.8966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.9343 - val_loss: 0.3485 - val_accuracy: 0.8966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2569 - accuracy: 0.9456 - val_loss: 0.3122 - val_accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9700 - val_loss: 0.2983 - val_accuracy: 0.9310\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9756 - val_loss: 0.2860 - val_accuracy: 0.9310\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9812 - val_loss: 0.2767 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9925 - val_loss: 0.2624 - val_accuracy: 0.9310\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9925 - val_loss: 0.2445 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9981 - val_loss: 0.2572 - val_accuracy: 0.8966\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9981 - val_loss: 0.2310 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9981 - val_loss: 0.2361 - val_accuracy: 0.8966\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9981 - val_loss: 0.2291 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9981 - val_loss: 0.2225 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9981 - val_loss: 0.2128 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9981 - val_loss: 0.2141 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.8966\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9310\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8877e-04 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.6195e-04 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.3822e-04 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.1436e-04 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.9012e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6647e-04 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4562e-04 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.2663e-04 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0323e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.8549e-04 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6710e-04 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4962e-04 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.3226e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 7.1390e-04 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9757e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.8029e-04 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.6534e-04 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5189e-04 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3592e-04 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.9149\n",
      "\n",
      "Test accuracy: 0.914893627166748\n",
      "var: 0.998\n",
      "(703, 320)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 20ms/step - loss: 2.2233 - accuracy: 0.3265 - val_loss: 1.3063 - val_accuracy: 0.6897\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.2981 - accuracy: 0.6585 - val_loss: 0.9675 - val_accuracy: 0.7586\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8830 - accuracy: 0.7561 - val_loss: 0.7707 - val_accuracy: 0.7241\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6262 - accuracy: 0.8311 - val_loss: 0.6416 - val_accuracy: 0.7931\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.8818 - val_loss: 0.5528 - val_accuracy: 0.8276\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.9156 - val_loss: 0.4901 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2859 - accuracy: 0.9343 - val_loss: 0.4353 - val_accuracy: 0.8621\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9550 - val_loss: 0.4126 - val_accuracy: 0.8621\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9644 - val_loss: 0.3712 - val_accuracy: 0.8621\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9756 - val_loss: 0.3653 - val_accuracy: 0.8966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9850 - val_loss: 0.3588 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9887 - val_loss: 0.3426 - val_accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9906 - val_loss: 0.3661 - val_accuracy: 0.8966\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9944 - val_loss: 0.3375 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9962 - val_loss: 0.3356 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9981 - val_loss: 0.3438 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9310\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9310\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9310\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9310\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9310\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9310\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9310\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9310\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.9310\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9310\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9310\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9310\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9310\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9310\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9310\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9310\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9310\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9310\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9310\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9310\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9310\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9310\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9310\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9310\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9310\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.8467e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9310\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.5786e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.3163e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9310\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.0743e-04 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9310\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.8449e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9310\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6240e-04 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9310\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4022e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1817e-04 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9310\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.9756e-04 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9310\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7947e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9310\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6109e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9310\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4178e-04 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9310\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2366e-04 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9310\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.0659e-04 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9310\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.8984e-04 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9310\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.7415e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9310\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5815e-04 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9310\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.4445e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9310\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.2982e-04 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.1520e-04 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8742 - accuracy: 0.8582\n",
      "\n",
      "Test accuracy: 0.8581560254096985\n",
      "var: 0.999\n",
      "(703, 367)\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 2s 24ms/step - loss: 2.3964 - accuracy: 0.2064 - val_loss: 1.8954 - val_accuracy: 0.2759\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.6112 - accuracy: 0.5009 - val_loss: 1.2446 - val_accuracy: 0.6552\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 1.1320 - accuracy: 0.7111 - val_loss: 0.8534 - val_accuracy: 0.7931\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.8218 - val_loss: 0.6846 - val_accuracy: 0.8276\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.6057 - accuracy: 0.8705 - val_loss: 0.5875 - val_accuracy: 0.7931\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.9024 - val_loss: 0.4687 - val_accuracy: 0.9310\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.9081 - val_loss: 0.4183 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.9268 - val_loss: 0.3804 - val_accuracy: 0.8966\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2328 - accuracy: 0.9437 - val_loss: 0.3438 - val_accuracy: 0.9310\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.9625 - val_loss: 0.3388 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9794 - val_loss: 0.3128 - val_accuracy: 0.9310\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9794 - val_loss: 0.3162 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0977 - accuracy: 0.9906 - val_loss: 0.3129 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9906 - val_loss: 0.3320 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9925 - val_loss: 0.3255 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9906 - val_loss: 0.3252 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9981 - val_loss: 0.3298 - val_accuracy: 0.9310\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9981 - val_loss: 0.3218 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.8966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.8966\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.8966\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9310\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9310\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9310\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.8966\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9310\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9310\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9310\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9310\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9310\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9310\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9310\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9310\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9310\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9310\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9310\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9310\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9310\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9655\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9310\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9655\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9655\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9655\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9655\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9655\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9655\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9655\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9655\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9655\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9655\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9655\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9655\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9655\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9655\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9655\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9655\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9655\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9655\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9655\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9655\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9655\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.9655\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9655\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9655\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9655\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9655\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9655\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9655\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9655\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.9532e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9655\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.6891e-04 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9655\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.4496e-04 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9655\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 9.2187e-04 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9655\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.9147e-04 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9655\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.7115e-04 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9655\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4965e-04 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9655\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.2720e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9655\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0178e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9655\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.8362e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9655\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.6294e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9655\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4502e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9655\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.2591e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9655\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.0833e-04 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9655\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.9213e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9655\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.7548e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9655\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5899e-04 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9655\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.4572e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9655\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.9149\n",
      "\n",
      "Test accuracy: 0.914893627166748\n",
      "Best Accuracy: 0.914893627166748\n",
      "Trimmed x_d with Best Selected Features:\n",
      "(703, 242)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_pca_for_feature_selection(X, desired_variance_ratio):\n",
    "    pca = PCA(n_components=desired_variance_ratio)\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "    return reduced_features, pca\n",
    "\n",
    "def pca(X, y, test_size=0.2, random_state=42):\n",
    "\n",
    "    variance_ratios = [i / 1000 for i in range(990, 1000)]\n",
    "    max_accuracy = 0.0\n",
    "    best_selected_features = None\n",
    "    best_pca_model = None\n",
    "\n",
    "    for desired_variance_ratio in variance_ratios:\n",
    "        reduced_features, pca_model = apply_pca_for_feature_selection(X, desired_variance_ratio)\n",
    "        print(f\"var: {desired_variance_ratio}\")\n",
    "        print(np.shape(reduced_features))\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Build the ANN model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Update max accuracy and store corresponding features\n",
    "        if test_acc > max_accuracy:\n",
    "            max_accuracy = test_acc\n",
    "            best_selected_features = reduced_features.copy()\n",
    "            best_pca_model = pca_model\n",
    "\n",
    "    # Apply inverse_transform to the full dataset with the best selected features\n",
    "    trimmed_x_d = best_pca_model.inverse_transform(best_selected_features)\n",
    "\n",
    "    return best_selected_features, max_accuracy\n",
    "\n",
    "# Example usage:\n",
    "reduced_x_d, max_accuracy = pca(x_d, y_d)\n",
    "print(f\"Best Accuracy: {max_accuracy}\")\n",
    "print(\"Trimmed x_d with Best Selected Features:\")\n",
    "print(np.shape(reduced_x_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bcf09",
   "metadata": {},
   "source": [
    "## ANN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca19135c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01, 0.1, 0.3, 0.5], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X = reduced_x_d\n",
    "y = y_d\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # Tune the number of layers.\n",
    "        for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "            model.add(\n",
    "                layers.Dense(\n",
    "                    # Tune number of units separately.\n",
    "                    units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model.add(layers.Dense(14, activation=\"softmax\")) # Output Classes\n",
    "\n",
    "        learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.01, 0.1, 0.3, 0.5])\n",
    "#         alpha = hp.Choice(\"alpha\", [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate), #, momentum=alpha\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create an instance of HyperParameters\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "# Build the model with default hyperparameters\n",
    "my_hypermodel = MyHyperModel()\n",
    "my_model = my_hypermodel.build(hp)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=my_hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    factor=2,\n",
    "    directory=\"Parameter Tuning\",\n",
    "    project_name=\"Neural Network-14 zoomed\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23c23c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.13793103396892548\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 11m 41s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.05, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6d24a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Parameter Tuning\\Neural Network-14 zoomed\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0128 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 64\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "units_2: 32\n",
      "activation_2: sigmoid\n",
      "batch_size: 128\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0137 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 64\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "units_2: 32\n",
      "activation_2: sigmoid\n",
      "batch_size: 128\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0128\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0144 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 64\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "units_2: 32\n",
      "activation_2: sigmoid\n",
      "batch_size: 128\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0137\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0148 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 64\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "units_2: 32\n",
      "activation_2: sigmoid\n",
      "batch_size: 128\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0144\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0176 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 320\n",
      "activation_0: tanh\n",
      "learning_rate: 0.5\n",
      "units_1: 288\n",
      "activation_1: relu\n",
      "units_2: 160\n",
      "activation_2: sigmoid\n",
      "batch_size: 16\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0169\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0178 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 320\n",
      "activation_0: tanh\n",
      "learning_rate: 0.01\n",
      "units_1: 448\n",
      "activation_1: tanh\n",
      "units_2: 416\n",
      "activation_2: relu\n",
      "batch_size: 32\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0171\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0008 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 448\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 192\n",
      "activation_1: tanh\n",
      "units_2: 128\n",
      "activation_2: sigmoid\n",
      "batch_size: 16\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 0.9655172228813171\n",
      "\n",
      "Trial 0038 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 448\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 192\n",
      "activation_1: tanh\n",
      "units_2: 128\n",
      "activation_2: sigmoid\n",
      "batch_size: 16\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 5\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0008\n",
      "Score: 0.9655172228813171\n",
      "\n",
      "Trial 0040 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 352\n",
      "activation_0: tanh\n",
      "learning_rate: 0.001\n",
      "units_1: 480\n",
      "activation_1: tanh\n",
      "units_2: 32\n",
      "activation_2: tanh\n",
      "batch_size: 16\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 5\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0003\n",
      "Score: 0.9655172228813171\n",
      "\n",
      "Trial 0041 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 128\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 416\n",
      "activation_1: relu\n",
      "units_2: 288\n",
      "activation_2: tanh\n",
      "batch_size: 64\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 5\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0009\n",
      "Score: 0.9655172228813171\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0fcd0d17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 18ms/step - loss: 1.3469 - accuracy: 0.6173 - val_loss: 0.5222 - val_accuracy: 0.8621\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.9006 - val_loss: 0.2236 - val_accuracy: 0.9310\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9625 - val_loss: 0.6420 - val_accuracy: 0.8621\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1468 - accuracy: 0.9625 - val_loss: 0.1072 - val_accuracy: 0.9655\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.9869 - val_loss: 0.7635 - val_accuracy: 0.8621\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1984 - accuracy: 0.9756 - val_loss: 0.1507 - val_accuracy: 0.9655\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9719 - val_loss: 0.2091 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9775 - val_loss: 0.6986 - val_accuracy: 0.9310\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9850 - val_loss: 0.6957 - val_accuracy: 0.9310\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9775 - val_loss: 1.9109 - val_accuracy: 0.8276\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3032 - accuracy: 0.9531 - val_loss: 1.0632 - val_accuracy: 0.9655\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.9493 - val_loss: 2.5128 - val_accuracy: 0.8276\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.9568 - val_loss: 0.7428 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.9512 - val_loss: 1.2386 - val_accuracy: 0.9310\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.9362\n",
      "[test loss, test accuracy]: [0.5713715553283691, 0.936170220375061]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "# layer is {best_hps.get('units_0')} and the optimal learning rate for the optimizer\n",
    "# is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05, callbacks=[early_stopping])\n",
    "\n",
    "# Check Result\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)\n",
    "\n",
    "# # Find the optimal number of epochs to train the model with the hyperparameters obtained from the search.\n",
    "# val_acc_per_epoch = history.history['val_accuracy']\n",
    "# best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "# print('Best epoch:', best_epoch)\n",
    "\n",
    "# # Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
    "# hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# # Retrain the model\n",
    "# hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.1)\n",
    "\n",
    "# # Check Result\n",
    "# eval_result = hypermodel.evaluate(X_test, y_test)\n",
    "# print(\"[test loss, test accuracy]:\", eval_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191152f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665bbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
