{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64653a26-b164-4036-93b5-be0f7358a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxiliaries (Importing Datafile, Checking Time)\n",
    "import os \n",
    "import time\n",
    "\n",
    "# Calculations\n",
    "import numpy as np\n",
    "\n",
    "# For Importing Data Files\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from skimage import color\n",
    "\n",
    "# For Image Pre-Processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979b03d-2172-4465-999b-1e65d282be22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create dataframe\n",
    "\n",
    "3 columns\n",
    "1. Disease Classification\n",
    "2. Image Name\n",
    "3. Image RGB Values (RGB Converted from BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce4c625-de79-4861-b12a-56db5eb4203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def create_dataframe_from_folders(root_folder):\n",
    "    # Initialize empty lists to store data for each column\n",
    "    folder_names = []\n",
    "    photo_names = []\n",
    "    photos = []\n",
    "\n",
    "    # Traverse through the root folder and its subfolders\n",
    "    for folder_name in sorted(os.listdir(root_folder)):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if the entry in the root folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for photo_name in sorted(os.listdir(folder_path), key=natural_sort_key):\n",
    "                # Photos are in common image formats (e.g., jpg, png)\n",
    "                if photo_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    photo_path = os.path.join(folder_path, photo_name)\n",
    "\n",
    "                    # Read image data using cv2\n",
    "                    image_data = cv2.imread(photo_path)\n",
    "\n",
    "                    # Convert BGR to RGB\n",
    "                    image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Append data to the lists\n",
    "                    folder_names.append(folder_name)\n",
    "                    photo_names.append(photo_name)\n",
    "                    photos.append(image_data_rgb)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'class': folder_names,\n",
    "        'img_name': photo_names,\n",
    "        'rgb': photos\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af7bde-ac77-45fa-8c61-7a53363109b4",
   "metadata": {},
   "source": [
    "Get data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f698915-bb74-4ec7-8ff1-606c6471d686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   class                img_name  \\\n",
      "0  bacterial_leaf_blight  BLB_multi_leaf (1).jpg   \n",
      "1  bacterial_leaf_blight  BLB_multi_leaf (2).jpg   \n",
      "2  bacterial_leaf_blight  BLB_multi_leaf (3).jpg   \n",
      "3  bacterial_leaf_blight  BLB_multi_leaf (4).jpg   \n",
      "4  bacterial_leaf_blight  BLB_multi_leaf (5).jpg   \n",
      "\n",
      "                                                 rgb  \n",
      "0  [[[115, 152, 47], [78, 113, 9], [116, 147, 43]...  \n",
      "1  [[[198, 218, 97], [190, 210, 89], [189, 208, 9...  \n",
      "2  [[[137, 176, 51], [166, 203, 64], [165, 200, 3...  \n",
      "3  [[[192, 212, 143], [201, 222, 157], [187, 206,...  \n",
      "4  [[[132, 176, 27], [135, 180, 27], [161, 206, 4...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "extra_resized_folder_path = r\"C:\\Users\\Josh\\000 Files\\003 Mengg AI\\01a 201 (AI)\\03 Mini-Project\\resized_raw_images (14 Classes)\"\n",
    "extra_resized = create_dataframe_from_folders(extra_resized_folder_path)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(extra_resized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5426b9d-5fe5-470e-95cd-b9bd72e1875a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Class Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be65000-1849-48e3-b646-93efd2758afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "bakanae                  100\n",
      "brown_spot               100\n",
      "grassy_stunt_virus       100\n",
      "healthy_rice_plant       100\n",
      "ragged_stunt_virus       100\n",
      "stem_rot                 100\n",
      "tungro_virus             100\n",
      "bacterial_leaf_streak     99\n",
      "rice_false_smut           99\n",
      "narrow_brown_spot         98\n",
      "rice_blast                98\n",
      "sheath_blight             98\n",
      "bacterial_leaf_blight     97\n",
      "sheath_rot                91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = extra_resized['class'].value_counts()\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac8225-3fe7-4259-a715-381055cfb61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d99ab4-0a06-495a-8af2-2d2ca69d19a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Texture Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef73441b-106f-4a76-af4a-30d0192a58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mahotas\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def compute_glcm_features(df):\n",
    "    df['gray'] = df['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2GRAY))\n",
    "    def calculate_glcm(gray_image):\n",
    "        # Compute GLCM using mahotas\n",
    "        glcm = mahotas.features.haralick(gray_image.astype(np.uint8), ignore_zeros=True)\n",
    "        return glcm.mean(axis=0)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gray_image = row['gray']\n",
    "        glcm_features = calculate_glcm(gray_image)\n",
    "        features.append(glcm_features)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Define meaningful column names for GLCM features\n",
    "    glcm_columns = [\n",
    "        'Angular Second Moment',\n",
    "        'Contrast',\n",
    "        'Correlation',\n",
    "        'Sum of Squares: Variance',\n",
    "        'Inverse Difference Moment',\n",
    "        'Sum Average',\n",
    "        'Sum Variance',\n",
    "        'Sum Entropy',\n",
    "        'Entropy',\n",
    "        'Difference Variance',\n",
    "        'Difference Entropy',\n",
    "        'Informational Measure of Correlation 1',\n",
    "        'Informational Measure of Correlation 2'\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with the new GLCM features and meaningful column names\n",
    "    glcm_df = pd.DataFrame(features, columns=[f'GLCM_{col}' for col in glcm_columns])\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, glcm_df], axis=1)\n",
    "\n",
    "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2b059a-fa17-4742-a4e9-61286361606a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 34.48 seconds\n"
     ]
    }
   ],
   "source": [
    "glcm = compute_glcm_features(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564a00a9-a6ed-4d71-b79b-82ded4744d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the first n columns\n",
    "f_glcm = glcm.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3555e8-efe3-4a70-8258-9bf9d11a2d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_Angular Second Moment</th>\n",
       "      <th>GLCM_Contrast</th>\n",
       "      <th>GLCM_Correlation</th>\n",
       "      <th>GLCM_Sum of Squares: Variance</th>\n",
       "      <th>GLCM_Inverse Difference Moment</th>\n",
       "      <th>GLCM_Sum Average</th>\n",
       "      <th>GLCM_Sum Variance</th>\n",
       "      <th>GLCM_Sum Entropy</th>\n",
       "      <th>GLCM_Entropy</th>\n",
       "      <th>GLCM_Difference Variance</th>\n",
       "      <th>GLCM_Difference Entropy</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 1</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>1876.058313</td>\n",
       "      <td>0.693690</td>\n",
       "      <td>3062.090566</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>281.006018</td>\n",
       "      <td>10372.303952</td>\n",
       "      <td>8.629042</td>\n",
       "      <td>14.243405</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>6.206143</td>\n",
       "      <td>-0.154215</td>\n",
       "      <td>0.950487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>1334.884861</td>\n",
       "      <td>0.797998</td>\n",
       "      <td>3303.508641</td>\n",
       "      <td>0.077155</td>\n",
       "      <td>276.277140</td>\n",
       "      <td>11879.149702</td>\n",
       "      <td>8.601060</td>\n",
       "      <td>14.082083</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>6.006272</td>\n",
       "      <td>-0.160813</td>\n",
       "      <td>0.952879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000140</td>\n",
       "      <td>1340.143870</td>\n",
       "      <td>0.744815</td>\n",
       "      <td>2625.859569</td>\n",
       "      <td>0.091972</td>\n",
       "      <td>293.873154</td>\n",
       "      <td>9163.294405</td>\n",
       "      <td>8.446153</td>\n",
       "      <td>13.764957</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>5.900897</td>\n",
       "      <td>-0.165284</td>\n",
       "      <td>0.954139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>1293.754229</td>\n",
       "      <td>0.776222</td>\n",
       "      <td>2890.458305</td>\n",
       "      <td>0.071097</td>\n",
       "      <td>289.332162</td>\n",
       "      <td>10268.078990</td>\n",
       "      <td>8.648174</td>\n",
       "      <td>14.226573</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>6.040155</td>\n",
       "      <td>-0.157107</td>\n",
       "      <td>0.952233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000101</td>\n",
       "      <td>1076.703851</td>\n",
       "      <td>0.693791</td>\n",
       "      <td>1757.932426</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>284.620945</td>\n",
       "      <td>5955.025853</td>\n",
       "      <td>8.284213</td>\n",
       "      <td>13.795743</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>5.881877</td>\n",
       "      <td>-0.134893</td>\n",
       "      <td>0.923023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_Angular Second Moment  GLCM_Contrast  GLCM_Correlation  \\\n",
       "0                    0.000093    1876.058313          0.693690   \n",
       "1                    0.000090    1334.884861          0.797998   \n",
       "2                    0.000140    1340.143870          0.744815   \n",
       "3                    0.000071    1293.754229          0.776222   \n",
       "4                    0.000101    1076.703851          0.693791   \n",
       "\n",
       "   GLCM_Sum of Squares: Variance  GLCM_Inverse Difference Moment  \\\n",
       "0                    3062.090566                        0.086892   \n",
       "1                    3303.508641                        0.077155   \n",
       "2                    2625.859569                        0.091972   \n",
       "3                    2890.458305                        0.071097   \n",
       "4                    1757.932426                        0.082002   \n",
       "\n",
       "   GLCM_Sum Average  GLCM_Sum Variance  GLCM_Sum Entropy  GLCM_Entropy  \\\n",
       "0        281.006018       10372.303952          8.629042     14.243405   \n",
       "1        276.277140       11879.149702          8.601060     14.082083   \n",
       "2        293.873154        9163.294405          8.446153     13.764957   \n",
       "3        289.332162       10268.078990          8.648174     14.226573   \n",
       "4        284.620945        5955.025853          8.284213     13.795743   \n",
       "\n",
       "   GLCM_Difference Variance  GLCM_Difference Entropy  \\\n",
       "0                  0.000072                 6.206143   \n",
       "1                  0.000079                 6.006272   \n",
       "2                  0.000095                 5.900897   \n",
       "3                  0.000073                 6.040155   \n",
       "4                  0.000086                 5.881877   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 1  \\\n",
       "0                                    -0.154215   \n",
       "1                                    -0.160813   \n",
       "2                                    -0.165284   \n",
       "3                                    -0.157107   \n",
       "4                                    -0.134893   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 2  \n",
       "0                                     0.950487  \n",
       "1                                     0.952879  \n",
       "2                                     0.954139  \n",
       "3                                     0.952233  \n",
       "4                                     0.923023  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_glcm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ad4b-7eb0-4110-bcb4-6e592e28d837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94ca35f-9437-4b01-8009-1a0eed2ae870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354c8451-629c-447d-beef-076db3311418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def values(dataframe):\n",
    "    # Ensure the 'rgb' column exists in the dataframe\n",
    "    dataframe['hsv'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2HSV))\n",
    "    #dataframe['hsi'] = dataframe['rgb'].apply(lambda x: color.rgb2hsi(np.uint8(x)))\n",
    "    dataframe['lab'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    dataframe['red'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,0])\n",
    "    dataframe['green'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,1])\n",
    "    dataframe['blue'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,2])\n",
    "    \n",
    "    dataframe['hue_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,0])\n",
    "    dataframe['saturation_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,1])\n",
    "    dataframe['value_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,2])\n",
    "    \n",
    "    #dataframe['hue_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,0])\n",
    "    #dataframe['saturation_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,1])\n",
    "    #dataframe['intensity_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,2])\n",
    "    \n",
    "    dataframe['lightness'] = dataframe['lab'].apply(lambda lab: lab[:, :, 0])\n",
    "    dataframe['a'] = dataframe['lab'].apply(lambda lab: lab[:, :, 1])\n",
    "    dataframe['b'] = dataframe['lab'].apply(lambda lab: lab[:, :, 2])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5082c1-48a7-4a77-ae63-d276523f8173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_bins_to_dataframe(dataframe, column_name, num_bins):\n",
    "    # Extract the specified column\n",
    "    original_column = dataframe[column_name]\n",
    "\n",
    "    # Define bin edges based on the min and max values in the matrices\n",
    "    min_value = np.min([np.min(matrix) for matrix in original_column])\n",
    "    max_value = np.max([np.max(matrix) for matrix in original_column])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "    # Create column names for the bins\n",
    "    bin_column_names = [f'{column_name}_{i}' for i in range(num_bins)]\n",
    "\n",
    "    # Iterate through each matrix in the original column\n",
    "    for i, matrix in enumerate(original_column):\n",
    "        # Digitize each element in the matrix into the corresponding bin\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "\n",
    "        # Count the occurrences of each bin index\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        # Add new columns to the DataFrame for each bin\n",
    "        for j, bin_column_name in enumerate(bin_column_names):\n",
    "            dataframe.loc[i, bin_column_name] = bin_counts[j]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb1fba-0704-4f4b-b34a-2e2ef1cbd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = values(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ab83c9-fc0e-4cff-9869-3fa8c12e4469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_bins_dataframe(dataframe, col, num_bins):\n",
    "    bins_dataframe = pd.DataFrame()\n",
    "\n",
    "    #print(col)\n",
    "    min_value = np.min([np.min(matrix) for matrix in dataframe[col]])\n",
    "    max_value = np.max([np.max(matrix) for matrix in dataframe[col]])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "    bin_column_names = [f'{col}_{i}' for i in range(1, num_bins + 1)]\n",
    "\n",
    "    for matrix in dataframe[col]:\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        bins_dataframe = pd.concat([bins_dataframe, pd.DataFrame(bin_counts).transpose()], axis=0, ignore_index=True)\n",
    "\n",
    "    bins_dataframe.columns = bin_column_names\n",
    "        \n",
    "    return bins_dataframe\n",
    "\n",
    "def hist_features(df, cols, bins):\n",
    "    complete_bins = pd.DataFrame()\n",
    "\n",
    "    for col in cols:\n",
    "        col_bins = create_bins_dataframe(df, col, bins)\n",
    "        complete_bins = pd.concat([complete_bins, col_bins], axis=1)\n",
    "\n",
    "    return complete_bins\n",
    "\n",
    "cols = ['red', 'green', 'blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef1f4f2-7b29-4783-80bb-942502c3f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_histogram = hist_features(channels, cols, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200b7499-7dd8-4545-a930-7e28dd715d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>red_10</th>\n",
       "      <th>...</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "      <th>b_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>223</td>\n",
       "      <td>231</td>\n",
       "      <td>305</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>210</td>\n",
       "      <td>261</td>\n",
       "      <td>308</td>\n",
       "      <td>349</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>358</td>\n",
       "      <td>383</td>\n",
       "      <td>554</td>\n",
       "      <td>...</td>\n",
       "      <td>541</td>\n",
       "      <td>556</td>\n",
       "      <td>187</td>\n",
       "      <td>98</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>290</td>\n",
       "      <td>337</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>454</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>1417</td>\n",
       "      <td>1133</td>\n",
       "      <td>195</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_1  red_2  red_3  red_4  red_5  red_6  red_7  red_8  red_9  red_10  ...  \\\n",
       "0     19     47     93    143    223    231    305    314    330     432  ...   \n",
       "1    153    210    261    308    349    391    392    358    383     554  ...   \n",
       "2     14     35     62    145    205    290    337    325    338     454  ...   \n",
       "3     14     14     40     53     89    106    194    242    267     436  ...   \n",
       "4      0      1      3      4      1      6      6      9      8      31  ...   \n",
       "\n",
       "   b_73  b_74  b_75  b_76  b_77  b_78  b_79  b_80  b_81  b_82  \n",
       "0    73    27     0     0     0     0     0     0     0     0  \n",
       "1   541   556   187    98    47    33     0     0     0     0  \n",
       "2   157    51     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4  1417  1133   195    42     8     1     0     0     0     0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_histogram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58cb8f-65ac-44fc-99e6-58e42abfabfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Color Moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b0823e-3e5b-4f1c-95a6-8b8b4cc97e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "\n",
    "def color_moments(dataframe, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        mean_values = []\n",
    "        variance_values = []\n",
    "        kurtosis_values = []\n",
    "        skewness_values = []\n",
    "\n",
    "        for img in dataframe[col]:\n",
    "            # 'img' is a 3D numpy array representing an RGB image\n",
    "            # Calculate statistics for each image\n",
    "            mean_channel = np.mean(img, axis=(0, 1))\n",
    "            variance_channel = np.var(img, axis=(0, 1))\n",
    "            kurtosis_channel = kurtosis(img, axis=(0, 1))\n",
    "            skewness_channel = skew(img, axis=(0, 1))\n",
    "\n",
    "            # Append values to respective lists\n",
    "            mean_values.append(mean_channel)\n",
    "            variance_values.append(variance_channel)\n",
    "            kurtosis_values.append(kurtosis_channel)\n",
    "            skewness_values.append(skewness_channel)\n",
    "\n",
    "        # Add the new columns to the DataFrame with channel names\n",
    "        for i in range(img.shape[2]):  # 'img' has shape (height, width, channels)\n",
    "            dataframe[f'{col}_channel_{i}_mean'] = [x[i] for x in mean_values]\n",
    "            dataframe[f'{col}_channel_{i}_variance'] = [x[i] for x in variance_values]\n",
    "            dataframe[f'{col}_channel_{i}_kurtosis'] = [x[i] for x in kurtosis_values]\n",
    "            dataframe[f'{col}_channel_{i}_skewness'] = [x[i] for x in skewness_values]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cc9e6e-ddcb-41fe-aa4b-72e3f44afc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb\n",
      "hsv\n",
      "lab\n"
     ]
    }
   ],
   "source": [
    "color_df = color_moments(extra_resized, ['rgb','hsv','lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c245d80-93b2-4cc8-82a3-77f40ab9b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_color = color_df.drop(columns=['class','img_name','rgb','gray','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52a436e-88b8-43bc-b1d7-b17b428f0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>rgb_channel_2_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "      <th>lab_channel_2_skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.110013</td>\n",
       "      <td>3078.218207</td>\n",
       "      <td>-0.689453</td>\n",
       "      <td>-0.192670</td>\n",
       "      <td>157.315011</td>\n",
       "      <td>3449.301597</td>\n",
       "      <td>-0.484632</td>\n",
       "      <td>-0.518085</td>\n",
       "      <td>67.831274</td>\n",
       "      <td>2087.782836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296129</td>\n",
       "      <td>-0.606758</td>\n",
       "      <td>106.950853</td>\n",
       "      <td>61.335754</td>\n",
       "      <td>0.410354</td>\n",
       "      <td>0.917856</td>\n",
       "      <td>169.947226</td>\n",
       "      <td>203.966363</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>-0.576146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.208227</td>\n",
       "      <td>3961.755789</td>\n",
       "      <td>-1.130258</td>\n",
       "      <td>-0.302681</td>\n",
       "      <td>158.333586</td>\n",
       "      <td>3558.081163</td>\n",
       "      <td>-0.908913</td>\n",
       "      <td>-0.458059</td>\n",
       "      <td>50.368921</td>\n",
       "      <td>1453.704717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781886</td>\n",
       "      <td>-0.534726</td>\n",
       "      <td>103.516083</td>\n",
       "      <td>21.999662</td>\n",
       "      <td>2.755215</td>\n",
       "      <td>1.327478</td>\n",
       "      <td>177.711097</td>\n",
       "      <td>198.029258</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>-0.735196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143.534598</td>\n",
       "      <td>2684.064771</td>\n",
       "      <td>-0.122034</td>\n",
       "      <td>-0.726785</td>\n",
       "      <td>163.988122</td>\n",
       "      <td>3032.684210</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>-0.932985</td>\n",
       "      <td>67.333745</td>\n",
       "      <td>1393.034182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395657</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>106.869300</td>\n",
       "      <td>39.706570</td>\n",
       "      <td>1.180393</td>\n",
       "      <td>1.184484</td>\n",
       "      <td>173.509228</td>\n",
       "      <td>201.620730</td>\n",
       "      <td>0.534828</td>\n",
       "      <td>-0.842716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.806521</td>\n",
       "      <td>3150.853829</td>\n",
       "      <td>-0.752603</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>155.817223</td>\n",
       "      <td>2935.205771</td>\n",
       "      <td>-0.687641</td>\n",
       "      <td>-0.282174</td>\n",
       "      <td>112.783462</td>\n",
       "      <td>2356.163989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573437</td>\n",
       "      <td>-0.355013</td>\n",
       "      <td>112.668666</td>\n",
       "      <td>26.981995</td>\n",
       "      <td>2.443752</td>\n",
       "      <td>0.798156</td>\n",
       "      <td>148.112783</td>\n",
       "      <td>56.290194</td>\n",
       "      <td>1.918221</td>\n",
       "      <td>-0.305414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133.956593</td>\n",
       "      <td>1928.268962</td>\n",
       "      <td>-0.601913</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>165.174087</td>\n",
       "      <td>1995.183999</td>\n",
       "      <td>-0.653920</td>\n",
       "      <td>-0.250057</td>\n",
       "      <td>46.036372</td>\n",
       "      <td>1525.296728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566688</td>\n",
       "      <td>-0.252408</td>\n",
       "      <td>101.051419</td>\n",
       "      <td>77.759832</td>\n",
       "      <td>0.647577</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>180.711256</td>\n",
       "      <td>190.856598</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>-0.751957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgb_channel_0_mean  rgb_channel_0_variance  rgb_channel_0_kurtosis  \\\n",
       "0          135.110013             3078.218207               -0.689453   \n",
       "1          132.208227             3961.755789               -1.130258   \n",
       "2          143.534598             2684.064771               -0.122034   \n",
       "3          134.806521             3150.853829               -0.752603   \n",
       "4          133.956593             1928.268962               -0.601913   \n",
       "\n",
       "   rgb_channel_0_skewness  rgb_channel_1_mean  rgb_channel_1_variance  \\\n",
       "0               -0.192670          157.315011             3449.301597   \n",
       "1               -0.302681          158.333586             3558.081163   \n",
       "2               -0.726785          163.988122             3032.684210   \n",
       "3                0.011988          155.817223             2935.205771   \n",
       "4                0.189324          165.174087             1995.183999   \n",
       "\n",
       "   rgb_channel_1_kurtosis  rgb_channel_1_skewness  rgb_channel_2_mean  \\\n",
       "0               -0.484632               -0.518085           67.831274   \n",
       "1               -0.908913               -0.458059           50.368921   \n",
       "2                0.098623               -0.932985           67.333745   \n",
       "3               -0.687641               -0.282174          112.783462   \n",
       "4               -0.653920               -0.250057           46.036372   \n",
       "\n",
       "   rgb_channel_2_variance  ...  lab_channel_0_kurtosis  \\\n",
       "0             2087.782836  ...               -0.296129   \n",
       "1             1453.704717  ...               -0.781886   \n",
       "2             1393.034182  ...                0.395657   \n",
       "3             2356.163989  ...               -0.573437   \n",
       "4             1525.296728  ...               -0.566688   \n",
       "\n",
       "   lab_channel_0_skewness  lab_channel_1_mean  lab_channel_1_variance  \\\n",
       "0               -0.606758          106.950853               61.335754   \n",
       "1               -0.534726          103.516083               21.999662   \n",
       "2               -1.041771          106.869300               39.706570   \n",
       "3               -0.355013          112.668666               26.981995   \n",
       "4               -0.252408          101.051419               77.759832   \n",
       "\n",
       "   lab_channel_1_kurtosis  lab_channel_1_skewness  lab_channel_2_mean  \\\n",
       "0                0.410354                0.917856          169.947226   \n",
       "1                2.755215                1.327478          177.711097   \n",
       "2                1.180393                1.184484          173.509228   \n",
       "3                2.443752                0.798156          148.112783   \n",
       "4                0.647577                1.165816          180.711256   \n",
       "\n",
       "   lab_channel_2_variance  lab_channel_2_kurtosis  lab_channel_2_skewness  \n",
       "0              203.966363                0.049806               -0.576146  \n",
       "1              198.029258                0.350495               -0.735196  \n",
       "2              201.620730                0.534828               -0.842716  \n",
       "3               56.290194                1.918221               -0.305414  \n",
       "4              190.856598                0.315457               -0.751957  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_color.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374ff69-1bee-49c9-a127-38bf7b2154fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Zernike Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2e3d8b-9bcb-4314-8271-fbda88d99c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas.features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def zernike(df, zernike_order):\n",
    "    features_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        gray_img = row['gray']\n",
    "\n",
    "        # Check if the image is grayscale\n",
    "        if len(gray_img.shape) == 2:\n",
    "            # If grayscale, compute Zernike moments directly\n",
    "            moments = mahotas.features.zernike_moments(gray_img, radius=zernike_order)\n",
    "        else:\n",
    "            raise ValueError(\"Input image must be grayscale.\")\n",
    "\n",
    "        features_list.append(moments)\n",
    "\n",
    "    # Determine the number of features per image\n",
    "    num_features_per_image = len(features_list[0])\n",
    "\n",
    "    # Add features to the DataFrame\n",
    "    feature_columns = [f'feature_{i}' for i in range(num_features_per_image)]\n",
    "    df_features = pd.DataFrame(features_list, columns=feature_columns)\n",
    "    df_result = pd.concat([df, df_features], axis=1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2839e315-3874-4df5-9d76-5f159e11d6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.085352</td>\n",
       "      <td>0.096424</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>0.047294</td>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>0.021023</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.030770</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.047826</td>\n",
       "      <td>0.057547</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.035470</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.037121</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.044010</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>0.050413</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.056392</td>\n",
       "      <td>0.064779</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048771</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    0.31831   0.017224   0.085352   0.096424   0.007132   0.019454   \n",
       "1    0.31831   0.014304   0.028368   0.037181   0.013888   0.019413   \n",
       "2    0.31831   0.079290   0.030770   0.009481   0.047826   0.057547   \n",
       "3    0.31831   0.037962   0.004782   0.037121   0.070988   0.044010   \n",
       "4    0.31831   0.008223   0.041976   0.050413   0.029785   0.035719   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0   0.035195   0.047294   0.034389   0.012664  ...    0.021457    0.009277   \n",
       "1   0.032812   0.021023   0.036471   0.003854  ...    0.019798    0.021939   \n",
       "2   0.014013   0.021884   0.035470   0.021808  ...    0.028761    0.049967   \n",
       "3   0.004336   0.021578   0.015647   0.008096  ...    0.017136    0.012084   \n",
       "4   0.045422   0.056392   0.064779   0.029646  ...    0.025135    0.003060   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.024865    0.004817    0.017575    0.003713    0.003742    0.016868   \n",
       "1    0.024250    0.033492    0.027907    0.000967    0.009835    0.017213   \n",
       "2    0.039179    0.039791    0.023068    0.031944    0.021562    0.009072   \n",
       "3    0.020084    0.021049    0.013913    0.004487    0.017935    0.029116   \n",
       "4    0.024900    0.048771    0.041041    0.005773    0.034733    0.012531   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.031700    0.035992  \n",
       "1    0.006593    0.008411  \n",
       "2    0.019779    0.024128  \n",
       "3    0.023423    0.023256  \n",
       "4    0.014290    0.004188  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zernike_df = zernike(extra_resized, 10)\n",
    "f_zernike = zernike_df.iloc[:, 51:]\n",
    "f_zernike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f9f14-f5c1-49e8-bc81-0ff472678dd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Legendre Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c31faf-4303-4c2c-9116-db4207ca5f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extra_resized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11c6966-8fce-4fe6-b283-0ae5a249459b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_input = extra_resized.drop(columns=['class','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])\n",
    "l_input = l_input.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797a48fb-2cbb-4377-a2c7-c851bf96b9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>rgb</th>\n",
       "      <th>gray</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLB_multi_leaf (1).jpg</td>\n",
       "      <td>[[[115, 152, 47], [78, 113, 9], [116, 147, 43]...</td>\n",
       "      <td>[[129, 91, 126, 196, 208, 157, 175, 128, 114, ...</td>\n",
       "      <td>135.110013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLB_multi_leaf (2).jpg</td>\n",
       "      <td>[[[198, 218, 97], [190, 210, 89], [189, 208, 9...</td>\n",
       "      <td>[[198, 190, 189, 183, 189, 189, 187, 187, 189,...</td>\n",
       "      <td>132.208227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLB_multi_leaf (3).jpg</td>\n",
       "      <td>[[[137, 176, 51], [166, 203, 64], [165, 200, 3...</td>\n",
       "      <td>[[150, 176, 171, 177, 193, 187, 142, 136, 135,...</td>\n",
       "      <td>143.534598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLB_multi_leaf (4).jpg</td>\n",
       "      <td>[[[192, 212, 143], [201, 222, 157], [187, 206,...</td>\n",
       "      <td>[[198, 208, 194, 198, 196, 159, 143, 145, 165,...</td>\n",
       "      <td>134.806521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLB_multi_leaf (5).jpg</td>\n",
       "      <td>[[[132, 176, 27], [135, 180, 27], [161, 206, 4...</td>\n",
       "      <td>[[146, 149, 174, 126, 153, 153, 185, 201, 210,...</td>\n",
       "      <td>133.956593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 img_name                                                rgb  \\\n",
       "0  BLB_multi_leaf (1).jpg  [[[115, 152, 47], [78, 113, 9], [116, 147, 43]...   \n",
       "1  BLB_multi_leaf (2).jpg  [[[198, 218, 97], [190, 210, 89], [189, 208, 9...   \n",
       "2  BLB_multi_leaf (3).jpg  [[[137, 176, 51], [166, 203, 64], [165, 200, 3...   \n",
       "3  BLB_multi_leaf (4).jpg  [[[192, 212, 143], [201, 222, 157], [187, 206,...   \n",
       "4  BLB_multi_leaf (5).jpg  [[[132, 176, 27], [135, 180, 27], [161, 206, 4...   \n",
       "\n",
       "                                                gray  rgb_channel_0_mean  \n",
       "0  [[129, 91, 126, 196, 208, 157, 175, 128, 114, ...          135.110013  \n",
       "1  [[198, 190, 189, 183, 189, 189, 187, 187, 189,...          132.208227  \n",
       "2  [[150, 176, 171, 177, 193, 187, 142, 136, 135,...          143.534598  \n",
       "3  [[198, 208, 194, 198, 196, 159, 143, 145, 165,...          134.806521  \n",
       "4  [[146, 149, 174, 126, 153, 153, 185, 201, 210,...          133.956593  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac178d0-3ed3-4c52-a778-5ae124e3d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.special import legendre\n",
    "\n",
    "def compute_legendre_features(rgb_image, degree):\n",
    "    # Get V channel from RGB image\n",
    "    v_channel = rgb_image[:, :, 2]\n",
    "\n",
    "    # Define x and y coordinates\n",
    "    x_size, y_size = v_channel.shape\n",
    "    x = np.linspace(-1, 1, x_size)\n",
    "    y = np.linspace(-1, 1, y_size)\n",
    "\n",
    "    # Compute Legendre features for the V channel\n",
    "    legendre_features = np.zeros((degree + 1, degree + 1))\n",
    "\n",
    "    for j in range(degree + 1):\n",
    "        for k in range(degree + 1):\n",
    "            legendre_features[j, k] = np.sum(v_channel * legendre(j)(x) * legendre(k)(y))\n",
    "\n",
    "    return legendre_features.flatten()\n",
    "\n",
    "def add_legendre(df, degree):\n",
    "    # Create a new DataFrame for Legendre features\n",
    "    legendre_columns = [f'v_legendre_{i}_{j}' for i in range(degree + 1) for j in range(degree + 1)]\n",
    "    legendre_df = pd.DataFrame(df['rgb'].apply(lambda rgb: compute_legendre_features(rgb, degree)).values.tolist(), columns=legendre_columns)\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, legendre_df], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43846dc1-14e3-448d-adc4-a22e38c851ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "legendre_df = add_legendre(l_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74b7ce3-9c49-42a7-95d2-ea2df961247b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_legendre_0_0</th>\n",
       "      <th>v_legendre_0_1</th>\n",
       "      <th>v_legendre_0_2</th>\n",
       "      <th>v_legendre_0_3</th>\n",
       "      <th>v_legendre_0_4</th>\n",
       "      <th>v_legendre_0_5</th>\n",
       "      <th>v_legendre_0_6</th>\n",
       "      <th>v_legendre_0_7</th>\n",
       "      <th>v_legendre_0_8</th>\n",
       "      <th>v_legendre_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>v_legendre_10_1</th>\n",
       "      <th>v_legendre_10_2</th>\n",
       "      <th>v_legendre_10_3</th>\n",
       "      <th>v_legendre_10_4</th>\n",
       "      <th>v_legendre_10_5</th>\n",
       "      <th>v_legendre_10_6</th>\n",
       "      <th>v_legendre_10_7</th>\n",
       "      <th>v_legendre_10_8</th>\n",
       "      <th>v_legendre_10_9</th>\n",
       "      <th>v_legendre_10_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3403502.0</td>\n",
       "      <td>97362.493274</td>\n",
       "      <td>-48201.759416</td>\n",
       "      <td>-43493.535531</td>\n",
       "      <td>-7187.545250</td>\n",
       "      <td>-13629.967522</td>\n",
       "      <td>26794.954058</td>\n",
       "      <td>-16840.577069</td>\n",
       "      <td>-19979.273476</td>\n",
       "      <td>3169.619967</td>\n",
       "      <td>...</td>\n",
       "      <td>11979.555139</td>\n",
       "      <td>6950.403894</td>\n",
       "      <td>-1337.870389</td>\n",
       "      <td>10980.581080</td>\n",
       "      <td>-2731.321916</td>\n",
       "      <td>13832.668995</td>\n",
       "      <td>-4770.100418</td>\n",
       "      <td>6167.284262</td>\n",
       "      <td>4327.878377</td>\n",
       "      <td>171054.141659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2527311.0</td>\n",
       "      <td>103013.053812</td>\n",
       "      <td>-36361.603672</td>\n",
       "      <td>5917.770393</td>\n",
       "      <td>47863.129349</td>\n",
       "      <td>1575.078268</td>\n",
       "      <td>12099.674282</td>\n",
       "      <td>-3201.383018</td>\n",
       "      <td>18315.225460</td>\n",
       "      <td>1422.844543</td>\n",
       "      <td>...</td>\n",
       "      <td>-821.672825</td>\n",
       "      <td>16762.645859</td>\n",
       "      <td>2097.910709</td>\n",
       "      <td>12284.262029</td>\n",
       "      <td>195.439018</td>\n",
       "      <td>20480.883830</td>\n",
       "      <td>3132.492664</td>\n",
       "      <td>11516.628122</td>\n",
       "      <td>8400.271678</td>\n",
       "      <td>134299.780209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3378538.0</td>\n",
       "      <td>57117.757848</td>\n",
       "      <td>-80632.660661</td>\n",
       "      <td>-510.363287</td>\n",
       "      <td>11451.263244</td>\n",
       "      <td>-12619.841113</td>\n",
       "      <td>-28828.907259</td>\n",
       "      <td>-769.368737</td>\n",
       "      <td>27917.794633</td>\n",
       "      <td>-6883.608118</td>\n",
       "      <td>...</td>\n",
       "      <td>3963.350675</td>\n",
       "      <td>18954.699088</td>\n",
       "      <td>-2074.126958</td>\n",
       "      <td>8085.322444</td>\n",
       "      <td>1051.648198</td>\n",
       "      <td>8771.579378</td>\n",
       "      <td>-2117.981725</td>\n",
       "      <td>3647.296353</td>\n",
       "      <td>5448.970980</td>\n",
       "      <td>164009.682234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5659023.0</td>\n",
       "      <td>-217617.215247</td>\n",
       "      <td>39749.222928</td>\n",
       "      <td>-6034.575324</td>\n",
       "      <td>13640.673159</td>\n",
       "      <td>21378.007074</td>\n",
       "      <td>44068.112251</td>\n",
       "      <td>-24151.624353</td>\n",
       "      <td>14049.614456</td>\n",
       "      <td>-33151.322155</td>\n",
       "      <td>...</td>\n",
       "      <td>-4619.286498</td>\n",
       "      <td>15514.090473</td>\n",
       "      <td>-6651.294307</td>\n",
       "      <td>31327.480610</td>\n",
       "      <td>553.852950</td>\n",
       "      <td>28293.237294</td>\n",
       "      <td>-4090.823341</td>\n",
       "      <td>27115.154433</td>\n",
       "      <td>-18929.538381</td>\n",
       "      <td>296838.144091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2309921.0</td>\n",
       "      <td>-148810.686099</td>\n",
       "      <td>-37569.159223</td>\n",
       "      <td>52055.054845</td>\n",
       "      <td>44925.442955</td>\n",
       "      <td>-23770.114279</td>\n",
       "      <td>17043.186742</td>\n",
       "      <td>11900.041479</td>\n",
       "      <td>1297.065850</td>\n",
       "      <td>-35581.018742</td>\n",
       "      <td>...</td>\n",
       "      <td>-9263.364484</td>\n",
       "      <td>11693.901946</td>\n",
       "      <td>-7594.119586</td>\n",
       "      <td>7040.301359</td>\n",
       "      <td>-2945.920523</td>\n",
       "      <td>20936.096634</td>\n",
       "      <td>1642.000010</td>\n",
       "      <td>5613.007761</td>\n",
       "      <td>-10798.603049</td>\n",
       "      <td>122542.843959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v_legendre_0_0  v_legendre_0_1  v_legendre_0_2  v_legendre_0_3  \\\n",
       "0       3403502.0    97362.493274   -48201.759416   -43493.535531   \n",
       "1       2527311.0   103013.053812   -36361.603672     5917.770393   \n",
       "2       3378538.0    57117.757848   -80632.660661     -510.363287   \n",
       "3       5659023.0  -217617.215247    39749.222928    -6034.575324   \n",
       "4       2309921.0  -148810.686099   -37569.159223    52055.054845   \n",
       "\n",
       "   v_legendre_0_4  v_legendre_0_5  v_legendre_0_6  v_legendre_0_7  \\\n",
       "0    -7187.545250   -13629.967522    26794.954058   -16840.577069   \n",
       "1    47863.129349     1575.078268    12099.674282    -3201.383018   \n",
       "2    11451.263244   -12619.841113   -28828.907259     -769.368737   \n",
       "3    13640.673159    21378.007074    44068.112251   -24151.624353   \n",
       "4    44925.442955   -23770.114279    17043.186742    11900.041479   \n",
       "\n",
       "   v_legendre_0_8  v_legendre_0_9  ...  v_legendre_10_1  v_legendre_10_2  \\\n",
       "0   -19979.273476     3169.619967  ...     11979.555139      6950.403894   \n",
       "1    18315.225460     1422.844543  ...      -821.672825     16762.645859   \n",
       "2    27917.794633    -6883.608118  ...      3963.350675     18954.699088   \n",
       "3    14049.614456   -33151.322155  ...     -4619.286498     15514.090473   \n",
       "4     1297.065850   -35581.018742  ...     -9263.364484     11693.901946   \n",
       "\n",
       "   v_legendre_10_3  v_legendre_10_4  v_legendre_10_5  v_legendre_10_6  \\\n",
       "0     -1337.870389     10980.581080     -2731.321916     13832.668995   \n",
       "1      2097.910709     12284.262029       195.439018     20480.883830   \n",
       "2     -2074.126958      8085.322444      1051.648198      8771.579378   \n",
       "3     -6651.294307     31327.480610       553.852950     28293.237294   \n",
       "4     -7594.119586      7040.301359     -2945.920523     20936.096634   \n",
       "\n",
       "   v_legendre_10_7  v_legendre_10_8  v_legendre_10_9  v_legendre_10_10  \n",
       "0     -4770.100418      6167.284262      4327.878377     171054.141659  \n",
       "1      3132.492664     11516.628122      8400.271678     134299.780209  \n",
       "2     -2117.981725      3647.296353      5448.970980     164009.682234  \n",
       "3     -4090.823341     27115.154433    -18929.538381     296838.144091  \n",
       "4      1642.000010      5613.007761    -10798.603049     122542.843959  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_legendre = legendre_df.iloc[:, 4:]\n",
    "f_legendre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bb6a4-6f30-4f3c-8b50-0bad0e8b6c75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Complete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5931a6-4d94-44df-8c1a-82076732f0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with just the selected column\n",
    "classes = pd.DataFrame(extra_resized['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5002378-98b0-4b70-ba29-a07ba57764f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#complete_features = pd.concat([classes,f_color,f_histogram, f_glcm], axis=1)\n",
    "complete_features = pd.concat([classes,f_histogram, f_glcm, f_color, f_legendre, f_zernike], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3453770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_features.to_csv('complete_features.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "060e531f-0a6e-455b-8dbf-07ca777d8c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>223</td>\n",
       "      <td>231</td>\n",
       "      <td>305</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>153</td>\n",
       "      <td>210</td>\n",
       "      <td>261</td>\n",
       "      <td>308</td>\n",
       "      <td>349</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>358</td>\n",
       "      <td>383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>290</td>\n",
       "      <td>337</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048771</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  red_1  red_2  red_3  red_4  red_5  red_6  red_7  \\\n",
       "0  bacterial_leaf_blight     19     47     93    143    223    231    305   \n",
       "1  bacterial_leaf_blight    153    210    261    308    349    391    392   \n",
       "2  bacterial_leaf_blight     14     35     62    145    205    290    337   \n",
       "3  bacterial_leaf_blight     14     14     40     53     89    106    194   \n",
       "4  bacterial_leaf_blight      0      1      3      4      1      6      6   \n",
       "\n",
       "   red_8  red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0    314    330  ...    0.021457    0.009277    0.024865    0.004817   \n",
       "1    358    383  ...    0.019798    0.021939    0.024250    0.033492   \n",
       "2    325    338  ...    0.028761    0.049967    0.039179    0.039791   \n",
       "3    242    267  ...    0.017136    0.012084    0.020084    0.021049   \n",
       "4      9      8  ...    0.025135    0.003060    0.024900    0.048771   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.017575    0.003713    0.003742    0.016868    0.031700    0.035992  \n",
       "1    0.027907    0.000967    0.009835    0.017213    0.006593    0.008411  \n",
       "2    0.023068    0.031944    0.021562    0.009072    0.019779    0.024128  \n",
       "3    0.013913    0.004487    0.017935    0.029116    0.023423    0.023256  \n",
       "4    0.041041    0.005773    0.034733    0.012531    0.014290    0.004188  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5fb4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_features = complete_features.iloc[:,:738]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93653fd4-c7c1-4763-ab89-2102d2f29c4c",
   "metadata": {},
   "source": [
    "# Data Normalization and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80096471-c274-4870-bea1-05b14edc651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe(df):\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Extract numerical columns (only numerical columns need normalization)\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply normalization to each numerical column\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b235b92a-228e-4021-975a-b860cafec988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>b_72</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>0.071804</td>\n",
       "      <td>0.076584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077254</td>\n",
       "      <td>0.127354</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>0.046317</td>\n",
       "      <td>0.074320</td>\n",
       "      <td>0.078440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158804</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>0.282403</td>\n",
       "      <td>0.074004</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class     red_1     red_2     red_3     red_4     red_5  \\\n",
       "0  bacterial_leaf_blight  0.000995  0.003872  0.009432  0.006509  0.034435   \n",
       "1  bacterial_leaf_blight  0.008011  0.017300  0.026471  0.014019  0.053891   \n",
       "2  bacterial_leaf_blight  0.000733  0.002883  0.006288  0.006600  0.031655   \n",
       "3  bacterial_leaf_blight  0.000733  0.001153  0.004057  0.002412  0.013743   \n",
       "4  bacterial_leaf_blight  0.000000  0.000082  0.000304  0.000182  0.000154   \n",
       "\n",
       "      red_6     red_7     red_8     red_9  ...      b_72      b_73      b_74  \\\n",
       "0  0.020301  0.041919  0.071804  0.076584  ...  0.014706  0.017185  0.006730   \n",
       "1  0.034362  0.053876  0.081866  0.088884  ...  0.077254  0.127354  0.138584   \n",
       "2  0.025486  0.046317  0.074320  0.078440  ...  0.032850  0.036959  0.012712   \n",
       "3  0.009315  0.026663  0.055340  0.061963  ...  0.000000  0.000000  0.000000   \n",
       "4  0.000527  0.000825  0.002058  0.001857  ...  0.158804  0.333569  0.282403   \n",
       "\n",
       "       b_75      b_76      b_77      b_78  b_79  b_80  b_81  \n",
       "0  0.000000  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
       "1  0.070968  0.040987  0.022510  0.016200   0.0   0.0   0.0  \n",
       "2  0.000000  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
       "4  0.074004  0.017566  0.003831  0.000491   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features = normalize_dataframe(histogram_features)\n",
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b339da2-35a0-455d-8db7-266f056dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_features['class'] = label_encoder.fit_transform(normalized_features['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "097defd8-e917-45e2-a877-dfe178bfe066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>b_72</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>0.071804</td>\n",
       "      <td>0.076584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.017185</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077254</td>\n",
       "      <td>0.127354</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>0.046317</td>\n",
       "      <td>0.074320</td>\n",
       "      <td>0.078440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158804</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>0.282403</td>\n",
       "      <td>0.074004</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class     red_1     red_2     red_3     red_4     red_5     red_6  \\\n",
       "0      0  0.000995  0.003872  0.009432  0.006509  0.034435  0.020301   \n",
       "1      0  0.008011  0.017300  0.026471  0.014019  0.053891  0.034362   \n",
       "2      0  0.000733  0.002883  0.006288  0.006600  0.031655  0.025486   \n",
       "3      0  0.000733  0.001153  0.004057  0.002412  0.013743  0.009315   \n",
       "4      0  0.000000  0.000082  0.000304  0.000182  0.000154  0.000527   \n",
       "\n",
       "      red_7     red_8     red_9  ...      b_72      b_73      b_74      b_75  \\\n",
       "0  0.041919  0.071804  0.076584  ...  0.014706  0.017185  0.006730  0.000000   \n",
       "1  0.053876  0.081866  0.088884  ...  0.077254  0.127354  0.138584  0.070968   \n",
       "2  0.046317  0.074320  0.078440  ...  0.032850  0.036959  0.012712  0.000000   \n",
       "3  0.026663  0.055340  0.061963  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000825  0.002058  0.001857  ...  0.158804  0.333569  0.282403  0.074004   \n",
       "\n",
       "       b_76      b_77      b_78  b_79  b_80  b_81  \n",
       "0  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
       "1  0.040987  0.022510  0.016200   0.0   0.0   0.0  \n",
       "2  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
       "3  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
       "4  0.017566  0.003831  0.000491   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77638c94-04af-43fb-a1db-0548a9c497cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acc8851d-dc36-4634-8d2f-8a3016c14ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def custom_train_test_split(dataframe, target_column, test_size=0.2, random_state=None):\n",
    "    # Separate features and labels\n",
    "    X = dataframe.drop(target_column, axis=1)  # Features\n",
    "    y = dataframe[target_column]  # Labels\n",
    "\n",
    "    # Perform the train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53594f6d-e920-4b66-91d8-7ba1ad60e4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = custom_train_test_split(normalized_features, 'class', test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "165bd148-e43b-401d-94a1-24f08ca4ef46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features (all columns except the first)\n",
    "x_d = normalized_features.iloc[:, 1:].values\n",
    "\n",
    "# Extract target variable (first column)\n",
    "y_d = normalized_features.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b4890-0ac4-4c6d-b3c1-9acf0c770916",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "705fec05-d73e-470c-9a2b-d71b16d96f36",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "33/33 [==============================] - 2s 16ms/step - loss: 2.2657 - accuracy: 0.3302 - val_loss: 2.0815 - val_accuracy: 0.3571\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.5092 - accuracy: 0.5754 - val_loss: 1.7417 - val_accuracy: 0.5179\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1194 - accuracy: 0.7004 - val_loss: 1.5435 - val_accuracy: 0.5893\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8694 - accuracy: 0.7748 - val_loss: 1.3826 - val_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.8006 - val_loss: 1.2782 - val_accuracy: 0.6964\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.8282 - val_loss: 1.2668 - val_accuracy: 0.6786\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8597 - val_loss: 1.1896 - val_accuracy: 0.6964\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8702 - val_loss: 1.1270 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8884 - val_loss: 1.0770 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8998 - val_loss: 1.0805 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.9170 - val_loss: 1.0892 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9218 - val_loss: 1.1054 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9284 - val_loss: 1.1827 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9342 - val_loss: 1.1782 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9456 - val_loss: 1.1786 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9447 - val_loss: 1.2111 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9532 - val_loss: 1.2402 - val_accuracy: 0.7321\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9504 - val_loss: 1.2438 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9628 - val_loss: 1.2857 - val_accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9647 - val_loss: 1.3105 - val_accuracy: 0.7321\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9618 - val_loss: 1.3458 - val_accuracy: 0.7321\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9714 - val_loss: 1.3733 - val_accuracy: 0.7321\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9695 - val_loss: 1.3752 - val_accuracy: 0.7321\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9742 - val_loss: 1.4333 - val_accuracy: 0.7321\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9714 - val_loss: 1.4812 - val_accuracy: 0.7321\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9761 - val_loss: 1.4444 - val_accuracy: 0.7679\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9771 - val_loss: 1.5335 - val_accuracy: 0.7321\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9838 - val_loss: 1.5194 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9809 - val_loss: 1.6120 - val_accuracy: 0.7679\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9809 - val_loss: 1.5870 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9866 - val_loss: 1.6316 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9847 - val_loss: 1.6298 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9828 - val_loss: 1.6399 - val_accuracy: 0.7143\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9847 - val_loss: 1.6840 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9895 - val_loss: 1.6966 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9847 - val_loss: 1.7311 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9866 - val_loss: 1.7583 - val_accuracy: 0.7321\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9914 - val_loss: 1.7412 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9952 - val_loss: 1.8001 - val_accuracy: 0.7679\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9943 - val_loss: 1.8486 - val_accuracy: 0.7679\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9952 - val_loss: 1.8836 - val_accuracy: 0.7679\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9981 - val_loss: 1.9112 - val_accuracy: 0.7679\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9981 - val_loss: 1.8772 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9981 - val_loss: 1.9360 - val_accuracy: 0.7679\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9981 - val_loss: 1.9698 - val_accuracy: 0.7679\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9990 - val_loss: 1.9806 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9990 - val_loss: 1.9991 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9971 - val_loss: 2.0577 - val_accuracy: 0.7679\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9981 - val_loss: 2.0707 - val_accuracy: 0.7679\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9990 - val_loss: 2.0578 - val_accuracy: 0.7679\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.0575 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9990 - val_loss: 2.1230 - val_accuracy: 0.7679\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.1405 - val_accuracy: 0.7679\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 2.1396 - val_accuracy: 0.7679\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 2.2282 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9981 - val_loss: 2.1806 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.2216 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.2358 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.2756 - val_accuracy: 0.7857\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.2874 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.2759 - val_accuracy: 0.7679\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.3764 - val_accuracy: 0.7679\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.3231 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.3041 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.3648 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.3522 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.3930 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.3792 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.4842 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.4517 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.4627 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.4851 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.4901 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.4904 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5259 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5133 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5463 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5553 - val_accuracy: 0.8036\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.5915 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6247 - val_accuracy: 0.8036\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6216 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6185 - val_accuracy: 0.8036\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6252 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6430 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6580 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6693 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6965 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7113 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7173 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7363 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7342 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7489 - val_accuracy: 0.8036\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7424 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7671 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7773 - val_accuracy: 0.8036\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7884 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.7964 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.8036\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8228 - val_accuracy: 0.8036\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0197 - accuracy: 0.8188\n",
      "\n",
      "Test accuracy: 0.8188405632972717\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data in x_d and y_d\n",
    "X = x_d\n",
    "y = y_d\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c715fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(X_test_scaled)\n",
    "# predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "# np.savetxt('test_predictions.csv', np.hstack((predicted_labels.reshape(-1, 1), y_test.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "# # np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157b35a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Feature Selection PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9f8a956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 0.99\n",
      "(1380, 189)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 2.2783 - accuracy: 0.3092 - val_loss: 1.9014 - val_accuracy: 0.3571\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5050 - accuracy: 0.5582 - val_loss: 1.5577 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1242 - accuracy: 0.6765 - val_loss: 1.3825 - val_accuracy: 0.5536\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8871 - accuracy: 0.7443 - val_loss: 1.2930 - val_accuracy: 0.6607\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.7218 - accuracy: 0.7853 - val_loss: 1.1788 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.8292 - val_loss: 1.1187 - val_accuracy: 0.6786\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8521 - val_loss: 1.0580 - val_accuracy: 0.6964\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8750 - val_loss: 1.0582 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8960 - val_loss: 1.0470 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8960 - val_loss: 1.0619 - val_accuracy: 0.7321\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.9122 - val_loss: 1.0858 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.9265 - val_loss: 1.0558 - val_accuracy: 0.7321\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.9294 - val_loss: 1.0865 - val_accuracy: 0.7321\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.9342 - val_loss: 1.1447 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2208 - accuracy: 0.9437 - val_loss: 1.1359 - val_accuracy: 0.7679\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9466 - val_loss: 1.0988 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9475 - val_loss: 1.1006 - val_accuracy: 0.8036\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9647 - val_loss: 1.1660 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9685 - val_loss: 1.1775 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9714 - val_loss: 1.1836 - val_accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9733 - val_loss: 1.1836 - val_accuracy: 0.8214\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9742 - val_loss: 1.2291 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9819 - val_loss: 1.3240 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9828 - val_loss: 1.2848 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9828 - val_loss: 1.3062 - val_accuracy: 0.8214\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9838 - val_loss: 1.3690 - val_accuracy: 0.8036\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9828 - val_loss: 1.3523 - val_accuracy: 0.8036\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9847 - val_loss: 1.3358 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9847 - val_loss: 1.3973 - val_accuracy: 0.8393\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9895 - val_loss: 1.4507 - val_accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9876 - val_loss: 1.4326 - val_accuracy: 0.8393\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9876 - val_loss: 1.4418 - val_accuracy: 0.8393\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9876 - val_loss: 1.4882 - val_accuracy: 0.8214\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9924 - val_loss: 1.4996 - val_accuracy: 0.8214\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9933 - val_loss: 1.5006 - val_accuracy: 0.8393\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9924 - val_loss: 1.5211 - val_accuracy: 0.8214\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9943 - val_loss: 1.5678 - val_accuracy: 0.8036\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9924 - val_loss: 1.5394 - val_accuracy: 0.8036\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9952 - val_loss: 1.5988 - val_accuracy: 0.8214\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9981 - val_loss: 1.5879 - val_accuracy: 0.8036\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9952 - val_loss: 1.5919 - val_accuracy: 0.8214\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9962 - val_loss: 1.6290 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9971 - val_loss: 1.6432 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9971 - val_loss: 1.6771 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9962 - val_loss: 1.6760 - val_accuracy: 0.8036\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9981 - val_loss: 1.6943 - val_accuracy: 0.8393\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9971 - val_loss: 1.7044 - val_accuracy: 0.8036\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9981 - val_loss: 1.7216 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9990 - val_loss: 1.7207 - val_accuracy: 0.8214\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9981 - val_loss: 1.7430 - val_accuracy: 0.8036\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9990 - val_loss: 1.7768 - val_accuracy: 0.8036\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 1.7591 - val_accuracy: 0.8036\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9990 - val_loss: 1.7993 - val_accuracy: 0.8036\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9990 - val_loss: 1.7913 - val_accuracy: 0.8036\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.8076 - val_accuracy: 0.8036\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.8345 - val_accuracy: 0.8393\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 1.8265 - val_accuracy: 0.8214\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.8498 - val_accuracy: 0.8036\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.8575 - val_accuracy: 0.8036\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.8750 - val_accuracy: 0.8036\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 1.8699 - val_accuracy: 0.8393\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.8944 - val_accuracy: 0.8214\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.9346 - val_accuracy: 0.8036\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.9183 - val_accuracy: 0.8036\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.9215 - val_accuracy: 0.8393\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.9566 - val_accuracy: 0.8036\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.9496 - val_accuracy: 0.8393\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.9938 - val_accuracy: 0.8036\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.9642 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.9859 - val_accuracy: 0.8214\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.9946 - val_accuracy: 0.8214\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.0134 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.0041 - val_accuracy: 0.8393\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.0323 - val_accuracy: 0.8393\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.0481 - val_accuracy: 0.8393\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.0545 - val_accuracy: 0.8393\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0604 - val_accuracy: 0.8393\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.0966 - val_accuracy: 0.8036\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0841 - val_accuracy: 0.8214\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.8036\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1138 - val_accuracy: 0.8214\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1179 - val_accuracy: 0.8036\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1145 - val_accuracy: 0.8393\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1520 - val_accuracy: 0.8036\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.8393\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1809 - val_accuracy: 0.8036\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1698 - val_accuracy: 0.8393\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1761 - val_accuracy: 0.8214\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1841 - val_accuracy: 0.8214\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1998 - val_accuracy: 0.8393\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2091 - val_accuracy: 0.8036\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.2136 - val_accuracy: 0.8393\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2270 - val_accuracy: 0.8036\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2308 - val_accuracy: 0.8393\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2495 - val_accuracy: 0.8393\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2415 - val_accuracy: 0.8393\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2778 - val_accuracy: 0.8036\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2844 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2880 - val_accuracy: 0.8036\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2839 - val_accuracy: 0.8393\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4804 - accuracy: 0.8043\n",
      "\n",
      "Test accuracy: 0.804347813129425\n",
      "var: 0.991\n",
      "(1380, 198)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.2413 - accuracy: 0.3311 - val_loss: 2.0032 - val_accuracy: 0.3393\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.4986 - accuracy: 0.5830 - val_loss: 1.6073 - val_accuracy: 0.4643\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1216 - accuracy: 0.6775 - val_loss: 1.4434 - val_accuracy: 0.4821\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8773 - accuracy: 0.7586 - val_loss: 1.2608 - val_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7289 - accuracy: 0.7987 - val_loss: 1.1666 - val_accuracy: 0.5893\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.8330 - val_loss: 1.1008 - val_accuracy: 0.5893\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8464 - val_loss: 1.0261 - val_accuracy: 0.6607\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8731 - val_loss: 1.0859 - val_accuracy: 0.6429\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8941 - val_loss: 1.0863 - val_accuracy: 0.6964\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8979 - val_loss: 1.1013 - val_accuracy: 0.6964\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.9132 - val_loss: 1.0156 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9227 - val_loss: 1.0711 - val_accuracy: 0.6964\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.9294 - val_loss: 1.1131 - val_accuracy: 0.6786\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9332 - val_loss: 1.1172 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9447 - val_loss: 1.1343 - val_accuracy: 0.6964\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9475 - val_loss: 1.1286 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9532 - val_loss: 1.1744 - val_accuracy: 0.6964\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9532 - val_loss: 1.1853 - val_accuracy: 0.7321\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9599 - val_loss: 1.2131 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9666 - val_loss: 1.1911 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9704 - val_loss: 1.2624 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9723 - val_loss: 1.2833 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9723 - val_loss: 1.2917 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9800 - val_loss: 1.3307 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9866 - val_loss: 1.3036 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9847 - val_loss: 1.4051 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9905 - val_loss: 1.3674 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9876 - val_loss: 1.4318 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9885 - val_loss: 1.4412 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9914 - val_loss: 1.4757 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9943 - val_loss: 1.4767 - val_accuracy: 0.7679\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9924 - val_loss: 1.4976 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9924 - val_loss: 1.5464 - val_accuracy: 0.7679\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9971 - val_loss: 1.5243 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9962 - val_loss: 1.5472 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9962 - val_loss: 1.5748 - val_accuracy: 0.7679\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9962 - val_loss: 1.5946 - val_accuracy: 0.7679\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9981 - val_loss: 1.6106 - val_accuracy: 0.7679\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9962 - val_loss: 1.6327 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9971 - val_loss: 1.6411 - val_accuracy: 0.7679\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9981 - val_loss: 1.6507 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9962 - val_loss: 1.6751 - val_accuracy: 0.7679\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9981 - val_loss: 1.7000 - val_accuracy: 0.7679\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9990 - val_loss: 1.7091 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 1.7102 - val_accuracy: 0.7679\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9990 - val_loss: 1.7275 - val_accuracy: 0.7679\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 1.7716 - val_accuracy: 0.7679\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9990 - val_loss: 1.7161 - val_accuracy: 0.7679\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.7708 - val_accuracy: 0.7679\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.8029 - val_accuracy: 0.7679\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9990 - val_loss: 1.7753 - val_accuracy: 0.7679\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.8038 - val_accuracy: 0.7679\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9990 - val_loss: 1.8399 - val_accuracy: 0.7679\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.8304 - val_accuracy: 0.7679\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.8455 - val_accuracy: 0.7679\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.8772 - val_accuracy: 0.7679\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.8728 - val_accuracy: 0.7679\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.8711 - val_accuracy: 0.7679\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.9053 - val_accuracy: 0.7679\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.9165 - val_accuracy: 0.7679\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.9318 - val_accuracy: 0.7679\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.7679\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.9309 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.9652 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.9612 - val_accuracy: 0.7679\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.9891 - val_accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.9874 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.9959 - val_accuracy: 0.7679\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.9926 - val_accuracy: 0.7679\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.0045 - val_accuracy: 0.7679\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0358 - val_accuracy: 0.7679\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.0354 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0370 - val_accuracy: 0.7679\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0548 - val_accuracy: 0.7679\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0717 - val_accuracy: 0.7679\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.0851 - val_accuracy: 0.7679\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.0711 - val_accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.0947 - val_accuracy: 0.7679\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1024 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1121 - val_accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1094 - val_accuracy: 0.7679\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1159 - val_accuracy: 0.7679\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1298 - val_accuracy: 0.7679\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.7679\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1612 - val_accuracy: 0.7679\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1538 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1785 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1716 - val_accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.1810 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2082 - val_accuracy: 0.7679\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2103 - val_accuracy: 0.7679\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2033 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2367 - val_accuracy: 0.7679\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2316 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2337 - val_accuracy: 0.7679\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2423 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2624 - val_accuracy: 0.7679\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.2587 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.2555 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.8297\n",
      "\n",
      "Test accuracy: 0.8297101259231567\n",
      "var: 0.992\n",
      "(1380, 207)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.1548 - accuracy: 0.3683 - val_loss: 1.8591 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2798 - accuracy: 0.6231 - val_loss: 1.5636 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9547 - accuracy: 0.7214 - val_loss: 1.3721 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.7872 - val_loss: 1.2384 - val_accuracy: 0.6071\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.8092 - val_loss: 1.1707 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8445 - val_loss: 1.1709 - val_accuracy: 0.6607\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8655 - val_loss: 1.1387 - val_accuracy: 0.6964\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8807 - val_loss: 1.0920 - val_accuracy: 0.6964\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8960 - val_loss: 1.0618 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.9065 - val_loss: 1.0198 - val_accuracy: 0.6964\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.9151 - val_loss: 1.0377 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9265 - val_loss: 1.0269 - val_accuracy: 0.6964\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9370 - val_loss: 0.9965 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9427 - val_loss: 0.9900 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9456 - val_loss: 1.0201 - val_accuracy: 0.7321\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9542 - val_loss: 0.9796 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9513 - val_loss: 1.0305 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9618 - val_loss: 1.0592 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9695 - val_loss: 1.0951 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9656 - val_loss: 1.0712 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9676 - val_loss: 1.1393 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9761 - val_loss: 1.0708 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9800 - val_loss: 1.1402 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9809 - val_loss: 1.1245 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9838 - val_loss: 1.1757 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9828 - val_loss: 1.1701 - val_accuracy: 0.7679\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9819 - val_loss: 1.1829 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9828 - val_loss: 1.2199 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9924 - val_loss: 1.2302 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9885 - val_loss: 1.2668 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9905 - val_loss: 1.2741 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9952 - val_loss: 1.2882 - val_accuracy: 0.7679\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9914 - val_loss: 1.2780 - val_accuracy: 0.7321\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9952 - val_loss: 1.2654 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9952 - val_loss: 1.2925 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9990 - val_loss: 1.3289 - val_accuracy: 0.7679\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9971 - val_loss: 1.3059 - val_accuracy: 0.7679\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9981 - val_loss: 1.3258 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9952 - val_loss: 1.3379 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9933 - val_loss: 1.3960 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9990 - val_loss: 1.3691 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9990 - val_loss: 1.3804 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9981 - val_loss: 1.4009 - val_accuracy: 0.7679\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9971 - val_loss: 1.3849 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9990 - val_loss: 1.4294 - val_accuracy: 0.7679\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9981 - val_loss: 1.4230 - val_accuracy: 0.7679\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 1.4392 - val_accuracy: 0.7679\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9990 - val_loss: 1.4583 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9990 - val_loss: 1.4672 - val_accuracy: 0.7679\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 1.4698 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9990 - val_loss: 1.4854 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9990 - val_loss: 1.5179 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 1.4956 - val_accuracy: 0.7679\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.5216 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 1.5211 - val_accuracy: 0.7679\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.5345 - val_accuracy: 0.7679\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.5539 - val_accuracy: 0.7679\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5601 - val_accuracy: 0.7679\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5664 - val_accuracy: 0.7679\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.6049 - val_accuracy: 0.7679\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9990 - val_loss: 1.6190 - val_accuracy: 0.7679\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 1.6098 - val_accuracy: 0.7679\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5989 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.6155 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6274 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6531 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6540 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6518 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6649 - val_accuracy: 0.7679\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.6775 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6697 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.7679\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6917 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7192 - val_accuracy: 0.7679\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7176 - val_accuracy: 0.7679\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7147 - val_accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7209 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7384 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7492 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7610 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.7649 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7726 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7882 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.8127 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8117 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.8224 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8148 - val_accuracy: 0.8036\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.8036\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8475 - val_accuracy: 0.8036\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8575 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8597 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8713 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8907 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8836 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8902 - val_accuracy: 0.7857\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5057 - accuracy: 0.8080\n",
      "\n",
      "Test accuracy: 0.8079710006713867\n",
      "var: 0.993\n",
      "(1380, 219)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 2.1304 - accuracy: 0.3359 - val_loss: 1.8605 - val_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3589 - accuracy: 0.5945 - val_loss: 1.4999 - val_accuracy: 0.4643\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.7042 - val_loss: 1.3685 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8065 - accuracy: 0.7681 - val_loss: 1.2337 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.8006 - val_loss: 1.1074 - val_accuracy: 0.6964\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8397 - val_loss: 1.0481 - val_accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8597 - val_loss: 1.0434 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8760 - val_loss: 0.9413 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8922 - val_loss: 0.9654 - val_accuracy: 0.8036\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8998 - val_loss: 0.9314 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.9094 - val_loss: 0.9152 - val_accuracy: 0.7679\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.9179 - val_loss: 0.9089 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2573 - accuracy: 0.9275 - val_loss: 0.8906 - val_accuracy: 0.7857\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9265 - val_loss: 0.9253 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9437 - val_loss: 0.9134 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9475 - val_loss: 0.9382 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9447 - val_loss: 0.9015 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9513 - val_loss: 0.9792 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9628 - val_loss: 0.9444 - val_accuracy: 0.7679\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9685 - val_loss: 0.9927 - val_accuracy: 0.7857\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9618 - val_loss: 0.9536 - val_accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1399 - accuracy: 0.9676 - val_loss: 1.0012 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9704 - val_loss: 1.0072 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9733 - val_loss: 1.0496 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9771 - val_loss: 1.0486 - val_accuracy: 0.7857\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9828 - val_loss: 1.0691 - val_accuracy: 0.7857\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9809 - val_loss: 1.0825 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9857 - val_loss: 1.0993 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9866 - val_loss: 1.1509 - val_accuracy: 0.7679\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9866 - val_loss: 1.1611 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9885 - val_loss: 1.1597 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9914 - val_loss: 1.1195 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9905 - val_loss: 1.1761 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9943 - val_loss: 1.1781 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9895 - val_loss: 1.2001 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9914 - val_loss: 1.2078 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9971 - val_loss: 1.2263 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9933 - val_loss: 1.2539 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9971 - val_loss: 1.2372 - val_accuracy: 0.7679\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9952 - val_loss: 1.2587 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9952 - val_loss: 1.2752 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9943 - val_loss: 1.2997 - val_accuracy: 0.7679\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9971 - val_loss: 1.2907 - val_accuracy: 0.7679\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9990 - val_loss: 1.3493 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9990 - val_loss: 1.3602 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9962 - val_loss: 1.3600 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9971 - val_loss: 1.3551 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9981 - val_loss: 1.3894 - val_accuracy: 0.8036\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9990 - val_loss: 1.4067 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.4377 - val_accuracy: 0.7679\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.4273 - val_accuracy: 0.8036\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.4475 - val_accuracy: 0.8036\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.4486 - val_accuracy: 0.7857\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.5219 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 1.5199 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.5119 - val_accuracy: 0.8036\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9990 - val_loss: 1.5528 - val_accuracy: 0.8036\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 1.5575 - val_accuracy: 0.8036\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.5604 - val_accuracy: 0.7857\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.6078 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6000 - val_accuracy: 0.7857\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.6254 - val_accuracy: 0.8036\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6640 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6615 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6723 - val_accuracy: 0.8036\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.7149 - val_accuracy: 0.8036\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.7197 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7518 - val_accuracy: 0.8036\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.8036\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.8036\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7724 - val_accuracy: 0.8036\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7984 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.8056 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8257 - val_accuracy: 0.8036\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8390 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8628 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8594 - val_accuracy: 0.8036\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8777 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8878 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9055 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.8036\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9064 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9330 - val_accuracy: 0.8036\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9581 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9630 - val_accuracy: 0.8036\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9687 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9813 - val_accuracy: 0.8036\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9950 - val_accuracy: 0.8036\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0078 - val_accuracy: 0.8036\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0213 - val_accuracy: 0.8036\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0284 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0209 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0511 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0695 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0685 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0723 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0848 - val_accuracy: 0.7857\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6777 - accuracy: 0.8188\n",
      "\n",
      "Test accuracy: 0.8188405632972717\n",
      "var: 0.994\n",
      "(1380, 232)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.2530 - accuracy: 0.2853 - val_loss: 1.8616 - val_accuracy: 0.4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4696 - accuracy: 0.5926 - val_loss: 1.5401 - val_accuracy: 0.4464\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0733 - accuracy: 0.6937 - val_loss: 1.3041 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8232 - accuracy: 0.7739 - val_loss: 1.1761 - val_accuracy: 0.6607\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.8120 - val_loss: 1.0984 - val_accuracy: 0.6964\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.8502 - val_loss: 1.0578 - val_accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8693 - val_loss: 0.9835 - val_accuracy: 0.7679\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8836 - val_loss: 0.9677 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8922 - val_loss: 0.9412 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.9113 - val_loss: 0.9108 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.9189 - val_loss: 0.9252 - val_accuracy: 0.8036\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.9313 - val_loss: 0.9205 - val_accuracy: 0.8036\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9370 - val_loss: 0.9714 - val_accuracy: 0.8036\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9370 - val_loss: 0.9479 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9475 - val_loss: 1.0579 - val_accuracy: 0.7857\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1896 - accuracy: 0.9494 - val_loss: 0.9867 - val_accuracy: 0.8214\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9647 - val_loss: 0.9969 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9676 - val_loss: 1.0512 - val_accuracy: 0.8036\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9723 - val_loss: 1.0299 - val_accuracy: 0.8214\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9752 - val_loss: 1.0576 - val_accuracy: 0.8036\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9704 - val_loss: 1.1349 - val_accuracy: 0.8214\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9752 - val_loss: 1.0631 - val_accuracy: 0.7857\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9819 - val_loss: 1.0889 - val_accuracy: 0.8214\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9790 - val_loss: 1.1168 - val_accuracy: 0.8393\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9876 - val_loss: 1.0935 - val_accuracy: 0.8214\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9866 - val_loss: 1.1023 - val_accuracy: 0.8393\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9866 - val_loss: 1.1084 - val_accuracy: 0.8214\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9914 - val_loss: 1.1065 - val_accuracy: 0.8214\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9905 - val_loss: 1.1101 - val_accuracy: 0.8214\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9895 - val_loss: 1.1331 - val_accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9895 - val_loss: 1.1466 - val_accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9905 - val_loss: 1.1652 - val_accuracy: 0.8214\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9933 - val_loss: 1.1645 - val_accuracy: 0.8214\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9914 - val_loss: 1.1626 - val_accuracy: 0.8214\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9933 - val_loss: 1.1654 - val_accuracy: 0.8214\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9914 - val_loss: 1.1600 - val_accuracy: 0.8214\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9952 - val_loss: 1.1697 - val_accuracy: 0.8393\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9943 - val_loss: 1.1997 - val_accuracy: 0.8214\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9952 - val_loss: 1.1780 - val_accuracy: 0.8393\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9981 - val_loss: 1.1819 - val_accuracy: 0.8214\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9971 - val_loss: 1.1981 - val_accuracy: 0.8393\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9971 - val_loss: 1.1944 - val_accuracy: 0.8393\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9981 - val_loss: 1.1949 - val_accuracy: 0.8393\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 1.1987 - val_accuracy: 0.8393\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.8393\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9990 - val_loss: 1.2223 - val_accuracy: 0.8214\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9981 - val_loss: 1.2120 - val_accuracy: 0.8393\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 1.2110 - val_accuracy: 0.8393\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9990 - val_loss: 1.2358 - val_accuracy: 0.8214\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 1.2466 - val_accuracy: 0.8393\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.8214\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.2437 - val_accuracy: 0.8393\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9990 - val_loss: 1.2715 - val_accuracy: 0.8214\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 1.2867 - val_accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9981 - val_loss: 1.2654 - val_accuracy: 0.8393\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9990 - val_loss: 1.2733 - val_accuracy: 0.8393\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.3031 - val_accuracy: 0.8393\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.3141 - val_accuracy: 0.8214\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9990 - val_loss: 1.2973 - val_accuracy: 0.8393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3201 - val_accuracy: 0.8214\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.8214\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.3434 - val_accuracy: 0.8393\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.8393\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.3651 - val_accuracy: 0.8214\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.8393\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3559 - val_accuracy: 0.8214\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.8393\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3699 - val_accuracy: 0.8393\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3886 - val_accuracy: 0.8393\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3856 - val_accuracy: 0.8393\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3923 - val_accuracy: 0.8393\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4006 - val_accuracy: 0.8393\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4067 - val_accuracy: 0.8393\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4026 - val_accuracy: 0.8393\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.8393\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4204 - val_accuracy: 0.8393\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4317 - val_accuracy: 0.8393\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4194 - val_accuracy: 0.8393\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.8393\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4506 - val_accuracy: 0.8214\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4539 - val_accuracy: 0.8393\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.8393\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4558 - val_accuracy: 0.8393\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4741 - val_accuracy: 0.8393\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4723 - val_accuracy: 0.8393\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4628 - val_accuracy: 0.8393\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4833 - val_accuracy: 0.8393\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.4858 - val_accuracy: 0.8393\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4703 - val_accuracy: 0.8393\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4978 - val_accuracy: 0.8214\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5049 - val_accuracy: 0.8393\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5032 - val_accuracy: 0.8393\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5177 - val_accuracy: 0.8393\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5203 - val_accuracy: 0.8393\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5207 - val_accuracy: 0.8393\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5257 - val_accuracy: 0.8393\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5294 - val_accuracy: 0.8393\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.8393\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5455 - val_accuracy: 0.8393\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5460 - val_accuracy: 0.8393\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1800 - accuracy: 0.8297\n",
      "\n",
      "Test accuracy: 0.8297101259231567\n",
      "var: 0.995\n",
      "(1380, 248)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.1520 - accuracy: 0.3683 - val_loss: 1.7635 - val_accuracy: 0.5357\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3463 - accuracy: 0.6174 - val_loss: 1.4842 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9954 - accuracy: 0.7166 - val_loss: 1.3346 - val_accuracy: 0.6071\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7948 - accuracy: 0.7595 - val_loss: 1.3260 - val_accuracy: 0.6071\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.8130 - val_loss: 1.2386 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.8368 - val_loss: 1.2145 - val_accuracy: 0.6250\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8578 - val_loss: 1.1307 - val_accuracy: 0.6607\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8845 - val_loss: 1.1595 - val_accuracy: 0.6964\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8960 - val_loss: 1.2076 - val_accuracy: 0.6964\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8989 - val_loss: 1.1706 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9084 - val_loss: 1.2327 - val_accuracy: 0.6964\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.9237 - val_loss: 1.1716 - val_accuracy: 0.7321\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9351 - val_loss: 1.2330 - val_accuracy: 0.7321\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9408 - val_loss: 1.2052 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9399 - val_loss: 1.3054 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9456 - val_loss: 1.1991 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9599 - val_loss: 1.2507 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9618 - val_loss: 1.3121 - val_accuracy: 0.7321\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9656 - val_loss: 1.3182 - val_accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9666 - val_loss: 1.3392 - val_accuracy: 0.7321\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9695 - val_loss: 1.3421 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9704 - val_loss: 1.3288 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9742 - val_loss: 1.4055 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9781 - val_loss: 1.4410 - val_accuracy: 0.7321\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9809 - val_loss: 1.5446 - val_accuracy: 0.7321\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9838 - val_loss: 1.4585 - val_accuracy: 0.7321\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9819 - val_loss: 1.5335 - val_accuracy: 0.7321\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9828 - val_loss: 1.5032 - val_accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9866 - val_loss: 1.5851 - val_accuracy: 0.7321\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9876 - val_loss: 1.5251 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9905 - val_loss: 1.5506 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9914 - val_loss: 1.5564 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9924 - val_loss: 1.6401 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9933 - val_loss: 1.6193 - val_accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9943 - val_loss: 1.6298 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9962 - val_loss: 1.6509 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9933 - val_loss: 1.7224 - val_accuracy: 0.7679\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9943 - val_loss: 1.6868 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9971 - val_loss: 1.7354 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9962 - val_loss: 1.7741 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9962 - val_loss: 1.8177 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9981 - val_loss: 1.7840 - val_accuracy: 0.7321\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9990 - val_loss: 1.8484 - val_accuracy: 0.7321\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.8183 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9990 - val_loss: 1.8428 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9990 - val_loss: 1.8638 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.8489 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9990 - val_loss: 1.9038 - val_accuracy: 0.7321\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9990 - val_loss: 1.8880 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.9202 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.9146 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.9336 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.7321\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.9688 - val_accuracy: 0.7321\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.0118 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.0174 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.0508 - val_accuracy: 0.7321\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.0447 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0872 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.0910 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1138 - val_accuracy: 0.7321\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1425 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.1482 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1669 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1870 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.2021 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2356 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.2404 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.2524 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2505 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.2860 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3010 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3016 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3179 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3335 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.3546 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.3607 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3821 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3785 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4079 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4057 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4328 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4542 - val_accuracy: 0.7143\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4815 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4632 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4800 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5021 - val_accuracy: 0.7321\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5016 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5183 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5240 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5371 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5369 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5591 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5761 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5944 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6126 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6173 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6248 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.7244 - accuracy: 0.7899\n",
      "\n",
      "Test accuracy: 0.7898550629615784\n",
      "var: 0.996\n",
      "(1380, 268)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.0732 - accuracy: 0.3874 - val_loss: 1.9121 - val_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3468 - accuracy: 0.6069 - val_loss: 1.6117 - val_accuracy: 0.4643\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0369 - accuracy: 0.6985 - val_loss: 1.4179 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.7586 - val_loss: 1.3078 - val_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.7920 - val_loss: 1.2411 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.8273 - val_loss: 1.1967 - val_accuracy: 0.6429\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8693 - val_loss: 1.1438 - val_accuracy: 0.6786\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8807 - val_loss: 1.1609 - val_accuracy: 0.6964\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8874 - val_loss: 1.1333 - val_accuracy: 0.7321\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.9065 - val_loss: 1.1378 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.9065 - val_loss: 1.1715 - val_accuracy: 0.7321\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9179 - val_loss: 1.1228 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.9323 - val_loss: 1.1750 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9351 - val_loss: 1.1711 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9389 - val_loss: 1.2475 - val_accuracy: 0.7679\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9418 - val_loss: 1.2234 - val_accuracy: 0.8036\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9542 - val_loss: 1.3075 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9542 - val_loss: 1.3276 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9637 - val_loss: 1.3216 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9618 - val_loss: 1.3629 - val_accuracy: 0.7857\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9704 - val_loss: 1.3800 - val_accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9618 - val_loss: 1.3946 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9723 - val_loss: 1.3841 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9714 - val_loss: 1.4356 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9733 - val_loss: 1.4389 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9752 - val_loss: 1.4138 - val_accuracy: 0.8036\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9800 - val_loss: 1.4771 - val_accuracy: 0.7679\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9800 - val_loss: 1.4625 - val_accuracy: 0.8036\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9809 - val_loss: 1.4596 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9819 - val_loss: 1.4951 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9809 - val_loss: 1.4964 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9838 - val_loss: 1.4405 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9857 - val_loss: 1.4904 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9885 - val_loss: 1.4998 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9876 - val_loss: 1.4526 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9876 - val_loss: 1.4580 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9933 - val_loss: 1.4848 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9933 - val_loss: 1.4726 - val_accuracy: 0.7679\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9952 - val_loss: 1.5057 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9933 - val_loss: 1.5027 - val_accuracy: 0.7679\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9962 - val_loss: 1.5134 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9981 - val_loss: 1.5280 - val_accuracy: 0.7679\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9952 - val_loss: 1.5131 - val_accuracy: 0.7679\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9981 - val_loss: 1.5199 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9971 - val_loss: 1.4713 - val_accuracy: 0.7679\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9971 - val_loss: 1.5444 - val_accuracy: 0.8036\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9981 - val_loss: 1.5583 - val_accuracy: 0.7679\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9971 - val_loss: 1.5641 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9981 - val_loss: 1.5189 - val_accuracy: 0.8036\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.5720 - val_accuracy: 0.8036\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9990 - val_loss: 1.5561 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9990 - val_loss: 1.5375 - val_accuracy: 0.8036\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9990 - val_loss: 1.5528 - val_accuracy: 0.8036\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9990 - val_loss: 1.5726 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9990 - val_loss: 1.5852 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9990 - val_loss: 1.5862 - val_accuracy: 0.8036\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9990 - val_loss: 1.6286 - val_accuracy: 0.8036\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.6040 - val_accuracy: 0.8214\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 1.6190 - val_accuracy: 0.8036\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.6221 - val_accuracy: 0.8036\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.6235 - val_accuracy: 0.8214\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.6274 - val_accuracy: 0.8036\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.8036\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.6543 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.6605 - val_accuracy: 0.8214\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6646 - val_accuracy: 0.8036\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.6626 - val_accuracy: 0.8036\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.6705 - val_accuracy: 0.8214\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6898 - val_accuracy: 0.8214\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.8036\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.7055 - val_accuracy: 0.8214\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.8036\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.8214\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7197 - val_accuracy: 0.8036\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7167 - val_accuracy: 0.8214\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.8214\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7448 - val_accuracy: 0.8214\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7423 - val_accuracy: 0.8214\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7439 - val_accuracy: 0.8036\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7593 - val_accuracy: 0.8036\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.8036\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.7820 - val_accuracy: 0.8036\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7822 - val_accuracy: 0.8214\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7792 - val_accuracy: 0.8036\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7944 - val_accuracy: 0.8036\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8025 - val_accuracy: 0.8036\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.7854 - val_accuracy: 0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8123 - val_accuracy: 0.8036\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8131 - val_accuracy: 0.8036\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.8262 - val_accuracy: 0.8214\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8268 - val_accuracy: 0.8214\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8418 - val_accuracy: 0.8036\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8314 - val_accuracy: 0.8036\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8520 - val_accuracy: 0.8036\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8569 - val_accuracy: 0.8036\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8587 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8542 - val_accuracy: 0.8036\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8683 - val_accuracy: 0.8036\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5030 - accuracy: 0.7971\n",
      "\n",
      "Test accuracy: 0.7971014380455017\n",
      "var: 0.997\n",
      "(1380, 294)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 2.2275 - accuracy: 0.3168 - val_loss: 1.9534 - val_accuracy: 0.3929\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.4726 - accuracy: 0.5773 - val_loss: 1.6209 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.1055 - accuracy: 0.7004 - val_loss: 1.4153 - val_accuracy: 0.6071\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8715 - accuracy: 0.7567 - val_loss: 1.1631 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.8073 - val_loss: 1.0669 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.8321 - val_loss: 0.9523 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8578 - val_loss: 0.9595 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8779 - val_loss: 0.8944 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8998 - val_loss: 0.9059 - val_accuracy: 0.7321\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.9151 - val_loss: 0.9269 - val_accuracy: 0.7321\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9284 - val_loss: 0.8988 - val_accuracy: 0.7679\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9303 - val_loss: 0.8441 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9389 - val_loss: 0.9045 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9494 - val_loss: 0.8617 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9504 - val_loss: 0.9283 - val_accuracy: 0.7321\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9485 - val_loss: 0.8602 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9571 - val_loss: 0.9081 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9609 - val_loss: 0.8990 - val_accuracy: 0.7321\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9666 - val_loss: 0.9541 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9676 - val_loss: 0.9087 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9733 - val_loss: 0.9753 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9761 - val_loss: 0.9750 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9790 - val_loss: 0.9700 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9771 - val_loss: 0.9499 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9819 - val_loss: 1.0161 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9781 - val_loss: 0.9614 - val_accuracy: 0.7679\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9847 - val_loss: 1.0341 - val_accuracy: 0.8036\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9866 - val_loss: 1.0217 - val_accuracy: 0.7679\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9866 - val_loss: 1.0544 - val_accuracy: 0.7679\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9847 - val_loss: 1.0786 - val_accuracy: 0.7679\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9885 - val_loss: 1.0289 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9885 - val_loss: 1.0970 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9885 - val_loss: 1.0631 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9933 - val_loss: 1.1100 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9876 - val_loss: 1.1036 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9885 - val_loss: 1.1121 - val_accuracy: 0.7321\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9914 - val_loss: 1.1311 - val_accuracy: 0.7679\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.9943 - val_loss: 1.1493 - val_accuracy: 0.8036\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9952 - val_loss: 1.1140 - val_accuracy: 0.8036\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9933 - val_loss: 1.1662 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9943 - val_loss: 1.2079 - val_accuracy: 0.7679\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9962 - val_loss: 1.2282 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9952 - val_loss: 1.2019 - val_accuracy: 0.7679\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9981 - val_loss: 1.2117 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9990 - val_loss: 1.2410 - val_accuracy: 0.7679\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.2352 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 1.2508 - val_accuracy: 0.8036\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9971 - val_loss: 1.2622 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.2999 - val_accuracy: 0.7679\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.3046 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3038 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.7679\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3228 - val_accuracy: 0.7679\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.7679\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.7679\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3753 - val_accuracy: 0.7679\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3744 - val_accuracy: 0.7679\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3894 - val_accuracy: 0.7679\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.7679\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.4229 - val_accuracy: 0.7679\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4511 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4469 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.4862 - val_accuracy: 0.7679\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4889 - val_accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4813 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4990 - val_accuracy: 0.7679\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5024 - val_accuracy: 0.7679\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5035 - val_accuracy: 0.7679\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5399 - val_accuracy: 0.7679\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5280 - val_accuracy: 0.7679\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.5647 - val_accuracy: 0.7679\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5609 - val_accuracy: 0.7679\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5642 - val_accuracy: 0.7679\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5877 - val_accuracy: 0.7679\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5873 - val_accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6021 - val_accuracy: 0.7679\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6113 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6362 - val_accuracy: 0.7679\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6387 - val_accuracy: 0.7679\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6553 - val_accuracy: 0.7679\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6320 - val_accuracy: 0.7679\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6662 - val_accuracy: 0.7679\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6700 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7059 - val_accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7081 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.7679\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7374 - val_accuracy: 0.7679\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7179 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7445 - val_accuracy: 0.7679\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7443 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7577 - val_accuracy: 0.7679\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7704 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7676 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7820 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7837 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4972 - accuracy: 0.8261\n",
      "\n",
      "Test accuracy: 0.8260869383811951\n",
      "var: 0.998\n",
      "(1380, 331)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.1485 - accuracy: 0.3378 - val_loss: 1.8491 - val_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4536 - accuracy: 0.5802 - val_loss: 1.5565 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.7004 - val_loss: 1.3778 - val_accuracy: 0.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8381 - accuracy: 0.7624 - val_loss: 1.1755 - val_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.8073 - val_loss: 1.0457 - val_accuracy: 0.6964\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8521 - val_loss: 0.9793 - val_accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8721 - val_loss: 0.9247 - val_accuracy: 0.7321\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8874 - val_loss: 0.8865 - val_accuracy: 0.7321\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8969 - val_loss: 0.8426 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.9227 - val_loss: 0.8740 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.9284 - val_loss: 0.8671 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.9332 - val_loss: 0.8324 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.9332 - val_loss: 0.8612 - val_accuracy: 0.8036\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9418 - val_loss: 0.8888 - val_accuracy: 0.8036\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9532 - val_loss: 0.8315 - val_accuracy: 0.8036\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9542 - val_loss: 0.8494 - val_accuracy: 0.8214\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9656 - val_loss: 0.8865 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9676 - val_loss: 0.8634 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9733 - val_loss: 0.8728 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9761 - val_loss: 0.9088 - val_accuracy: 0.8214\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9771 - val_loss: 0.9059 - val_accuracy: 0.8036\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9828 - val_loss: 0.9475 - val_accuracy: 0.8036\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9828 - val_loss: 0.9413 - val_accuracy: 0.8036\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9876 - val_loss: 0.9559 - val_accuracy: 0.8036\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9885 - val_loss: 0.9847 - val_accuracy: 0.8036\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9914 - val_loss: 1.0296 - val_accuracy: 0.8036\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9905 - val_loss: 0.9404 - val_accuracy: 0.8036\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9914 - val_loss: 1.0509 - val_accuracy: 0.8036\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9943 - val_loss: 1.0287 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9943 - val_loss: 1.0438 - val_accuracy: 0.8036\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9971 - val_loss: 1.0617 - val_accuracy: 0.8036\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9943 - val_loss: 1.0600 - val_accuracy: 0.8036\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9971 - val_loss: 1.0783 - val_accuracy: 0.8036\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9971 - val_loss: 1.0651 - val_accuracy: 0.8036\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9971 - val_loss: 1.1149 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9952 - val_loss: 1.1588 - val_accuracy: 0.8036\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9990 - val_loss: 1.1392 - val_accuracy: 0.8036\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9971 - val_loss: 1.1409 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9981 - val_loss: 1.2085 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9990 - val_loss: 1.2130 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 1.1769 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9981 - val_loss: 1.2218 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 1.2472 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.2767 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 1.2511 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3268 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 1.3233 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3590 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3825 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3586 - val_accuracy: 0.7857\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4282 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.3755 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.4310 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4168 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4323 - val_accuracy: 0.7857\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4656 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4622 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4540 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.4893 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4934 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.5059 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5085 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5217 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5163 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5429 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5363 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5600 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5768 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6037 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5947 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5919 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6231 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6274 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6749 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6503 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6713 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6669 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6926 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6887 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7200 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7288 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7431 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7515 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7514 - val_accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7677 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7793 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7723 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7830 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7827 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8142 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8045 - val_accuracy: 0.7857\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6926 - accuracy: 0.8043\n",
      "\n",
      "Test accuracy: 0.804347813129425\n",
      "var: 0.999\n",
      "(1380, 394)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 2.1795 - accuracy: 0.3282 - val_loss: 1.7659 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3484 - accuracy: 0.6164 - val_loss: 1.3907 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0033 - accuracy: 0.7013 - val_loss: 1.2233 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8011 - accuracy: 0.7643 - val_loss: 1.1461 - val_accuracy: 0.6607\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.8158 - val_loss: 1.1097 - val_accuracy: 0.6607\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.8349 - val_loss: 1.0599 - val_accuracy: 0.6786\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8655 - val_loss: 0.9802 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8912 - val_loss: 1.0581 - val_accuracy: 0.6964\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.9008 - val_loss: 0.9952 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.9084 - val_loss: 1.0674 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.9170 - val_loss: 1.1203 - val_accuracy: 0.7321\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.9265 - val_loss: 1.0561 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9265 - val_loss: 1.0755 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9475 - val_loss: 1.1239 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9389 - val_loss: 1.1149 - val_accuracy: 0.7679\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1921 - accuracy: 0.9504 - val_loss: 1.1681 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9571 - val_loss: 1.1293 - val_accuracy: 0.8036\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9561 - val_loss: 1.1476 - val_accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9676 - val_loss: 1.2222 - val_accuracy: 0.8036\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9723 - val_loss: 1.2306 - val_accuracy: 0.8036\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9714 - val_loss: 1.2542 - val_accuracy: 0.8214\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9752 - val_loss: 1.3006 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9809 - val_loss: 1.3460 - val_accuracy: 0.8036\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9790 - val_loss: 1.3967 - val_accuracy: 0.8036\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9847 - val_loss: 1.3413 - val_accuracy: 0.8036\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9857 - val_loss: 1.4164 - val_accuracy: 0.8214\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9857 - val_loss: 1.4088 - val_accuracy: 0.8214\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9885 - val_loss: 1.4076 - val_accuracy: 0.8214\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9914 - val_loss: 1.4864 - val_accuracy: 0.8036\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9895 - val_loss: 1.5568 - val_accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9914 - val_loss: 1.5333 - val_accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9933 - val_loss: 1.5145 - val_accuracy: 0.8214\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9952 - val_loss: 1.5773 - val_accuracy: 0.8214\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9962 - val_loss: 1.6274 - val_accuracy: 0.8214\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9943 - val_loss: 1.6075 - val_accuracy: 0.8036\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9962 - val_loss: 1.6526 - val_accuracy: 0.8214\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9952 - val_loss: 1.7326 - val_accuracy: 0.8036\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9981 - val_loss: 1.6405 - val_accuracy: 0.8214\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9981 - val_loss: 1.6569 - val_accuracy: 0.8214\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.7416 - val_accuracy: 0.8036\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 1.7148 - val_accuracy: 0.8214\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9971 - val_loss: 1.7877 - val_accuracy: 0.8214\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9990 - val_loss: 1.7650 - val_accuracy: 0.8214\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 1.7939 - val_accuracy: 0.8214\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9981 - val_loss: 1.8558 - val_accuracy: 0.8036\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9990 - val_loss: 1.8257 - val_accuracy: 0.8214\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9990 - val_loss: 1.8324 - val_accuracy: 0.8214\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.8751 - val_accuracy: 0.8214\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.8586 - val_accuracy: 0.8214\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9990 - val_loss: 1.9245 - val_accuracy: 0.8214\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 1.9073 - val_accuracy: 0.8036\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.8934 - val_accuracy: 0.8036\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 1.8962 - val_accuracy: 0.8214\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.9504 - val_accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.9590 - val_accuracy: 0.8214\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.9672 - val_accuracy: 0.8214\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.8036\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.0345 - val_accuracy: 0.8036\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.0344 - val_accuracy: 0.8214\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.0492 - val_accuracy: 0.8036\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.0507 - val_accuracy: 0.8036\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.0514 - val_accuracy: 0.8214\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.0972 - val_accuracy: 0.8036\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.0967 - val_accuracy: 0.8036\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1046 - val_accuracy: 0.8036\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1116 - val_accuracy: 0.8036\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1365 - val_accuracy: 0.8036\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1477 - val_accuracy: 0.8214\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1976 - val_accuracy: 0.8036\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1737 - val_accuracy: 0.8036\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1677 - val_accuracy: 0.8214\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1774 - val_accuracy: 0.8036\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2380 - val_accuracy: 0.8036\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1977 - val_accuracy: 0.8036\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2167 - val_accuracy: 0.8036\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2303 - val_accuracy: 0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.2646 - val_accuracy: 0.8036\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2556 - val_accuracy: 0.8036\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.2836 - val_accuracy: 0.8036\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.2866 - val_accuracy: 0.8036\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2995 - val_accuracy: 0.8036\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3133 - val_accuracy: 0.8036\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3176 - val_accuracy: 0.8036\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3405 - val_accuracy: 0.8036\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.3494 - val_accuracy: 0.8036\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3640 - val_accuracy: 0.8036\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3635 - val_accuracy: 0.8036\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3662 - val_accuracy: 0.8036\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3994 - val_accuracy: 0.8036\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3817 - val_accuracy: 0.8036\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4140 - val_accuracy: 0.8036\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4098 - val_accuracy: 0.8036\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4251 - val_accuracy: 0.8036\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4377 - val_accuracy: 0.8036\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4452 - val_accuracy: 0.8036\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4490 - val_accuracy: 0.8036\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4425 - val_accuracy: 0.8036\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4816 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4966 - val_accuracy: 0.8036\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4868 - val_accuracy: 0.8036\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5118 - accuracy: 0.8043\n",
      "\n",
      "Test accuracy: 0.804347813129425\n",
      "Best Accuracy: 0.8297101259231567\n",
      "Trimmed x_d with Best Selected Features:\n",
      "(1380, 198)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_pca_for_feature_selection(X, desired_variance_ratio):\n",
    "    pca = PCA(n_components=desired_variance_ratio)\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "    return reduced_features, pca\n",
    "\n",
    "def pca(X, y, test_size=0.2, random_state=42):\n",
    "\n",
    "    variance_ratios = [i / 1000 for i in range(990, 1000)]\n",
    "    max_accuracy = 0.0\n",
    "    best_selected_features = None\n",
    "    best_pca_model = None\n",
    "\n",
    "    for desired_variance_ratio in variance_ratios:\n",
    "        reduced_features, pca_model = apply_pca_for_feature_selection(X, desired_variance_ratio)\n",
    "        print(f\"var: {desired_variance_ratio}\")\n",
    "        print(np.shape(reduced_features))\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Build the ANN model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Update max accuracy and store corresponding features\n",
    "        if test_acc > max_accuracy:\n",
    "            max_accuracy = test_acc\n",
    "            best_selected_features = reduced_features.copy()\n",
    "            best_pca_model = pca_model\n",
    "\n",
    "    # Apply inverse_transform to the full dataset with the best selected features\n",
    "    trimmed_x_d = best_pca_model.inverse_transform(best_selected_features)\n",
    "\n",
    "    return best_selected_features, max_accuracy\n",
    "\n",
    "# Example usage:\n",
    "reduced_x_d, max_accuracy = pca(x_d, y_d)\n",
    "print(f\"Best Accuracy: {max_accuracy}\")\n",
    "print(\"Trimmed x_d with Best Selected Features:\")\n",
    "print(np.shape(reduced_x_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bcf09",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## ANN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca19135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01, 0.1, 0.3, 0.5], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X = reduced_x_d\n",
    "y = y_d\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # Tune the number of layers.\n",
    "        for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "            model.add(\n",
    "                layers.Dense(\n",
    "                    # Tune number of units separately.\n",
    "                    units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model.add(layers.Dense(14, activation=\"softmax\"))\n",
    "\n",
    "        learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.01, 0.1, 0.3, 0.5])\n",
    "#         alpha = hp.Choice(\"alpha\", [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate), #, momentum=alpha\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create an instance of HyperParameters\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "# Build the model with default hyperparameters\n",
    "my_hypermodel = MyHyperModel()\n",
    "my_model = my_hypermodel.build(hp)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=my_hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    factor=2,\n",
    "    directory=\"Parameter Tuning\",\n",
    "    project_name=\"14 Classes - Histogram\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96f1d549",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.1964285671710968\n",
      "\n",
      "Best val_accuracy So Far: 0.8392857313156128\n",
      "Total elapsed time: 00h 09m 29s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.05, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02db1ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Parameter Tuning\\14 Classes - Histogram\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0057 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 32\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 160\n",
      "activation_1: sigmoid\n",
      "units_2: 64\n",
      "activation_2: tanh\n",
      "batch_size: 16\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 5\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0047\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0062 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 224\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 160\n",
      "activation_1: relu\n",
      "units_2: 288\n",
      "activation_2: sigmoid\n",
      "batch_size: 64\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 5\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0048\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0068 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 224\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 160\n",
      "activation_1: relu\n",
      "units_2: 288\n",
      "activation_2: sigmoid\n",
      "batch_size: 64\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0062\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0100 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 448\n",
      "activation_0: relu\n",
      "learning_rate: 0.3\n",
      "units_1: 192\n",
      "activation_1: tanh\n",
      "units_2: 32\n",
      "activation_2: relu\n",
      "batch_size: 128\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 4\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0088\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0160 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 32\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 448\n",
      "activation_1: sigmoid\n",
      "units_2: 128\n",
      "activation_2: tanh\n",
      "batch_size: 16\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0156\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0165 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 32\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 448\n",
      "activation_1: sigmoid\n",
      "units_2: 128\n",
      "activation_2: tanh\n",
      "batch_size: 16\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0160\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0171 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 160\n",
      "activation_0: relu\n",
      "learning_rate: 0.001\n",
      "units_1: 96\n",
      "activation_1: sigmoid\n",
      "units_2: 160\n",
      "activation_2: sigmoid\n",
      "batch_size: 16\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0058 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 288\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 512\n",
      "activation_1: sigmoid\n",
      "units_2: 416\n",
      "activation_2: relu\n",
      "batch_size: 16\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 5\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0038\n",
      "Score: 0.8214285969734192\n",
      "\n",
      "Trial 0069 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 288\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 512\n",
      "activation_1: sigmoid\n",
      "units_2: 416\n",
      "activation_2: relu\n",
      "batch_size: 16\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0058\n",
      "Score: 0.8214285969734192\n",
      "\n",
      "Trial 0070 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 320\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 128\n",
      "activation_1: tanh\n",
      "units_2: 352\n",
      "activation_2: tanh\n",
      "batch_size: 128\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0059\n",
      "Score: 0.8214285969734192\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e38f980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 1.6964 - accuracy: 0.4676 - val_loss: 1.1810 - val_accuracy: 0.6786\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.7939 - val_loss: 0.9938 - val_accuracy: 0.6607\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8616 - val_loss: 1.1811 - val_accuracy: 0.7143\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8855 - val_loss: 0.8623 - val_accuracy: 0.7857\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9256 - val_loss: 0.9587 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9437 - val_loss: 1.0322 - val_accuracy: 0.7679\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9599 - val_loss: 0.9731 - val_accuracy: 0.8036\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9752 - val_loss: 1.0314 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9704 - val_loss: 1.2326 - val_accuracy: 0.7679\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9714 - val_loss: 1.0616 - val_accuracy: 0.8036\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9781 - val_loss: 1.3405 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9876 - val_loss: 1.1197 - val_accuracy: 0.8036\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9952 - val_loss: 1.0752 - val_accuracy: 0.8214\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9981 - val_loss: 1.0876 - val_accuracy: 0.8036\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 1.1033 - val_accuracy: 0.7679\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.1287 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2089 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.8036\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2653 - val_accuracy: 0.8036\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2565 - val_accuracy: 0.8036\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2845 - val_accuracy: 0.8036\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3204 - val_accuracy: 0.8036\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3112 - val_accuracy: 0.8036\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.8036\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.8036\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3616 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3580 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3846 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3736 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3910 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4041 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4142 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4197 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4315 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4429 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4501 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4642 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4670 - val_accuracy: 0.8036\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.9719e-04 - accuracy: 1.0000 - val_loss: 1.4780 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.5458e-04 - accuracy: 1.0000 - val_loss: 1.4785 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.1556e-04 - accuracy: 1.0000 - val_loss: 1.4871 - val_accuracy: 0.8036\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.6930e-04 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.3306e-04 - accuracy: 1.0000 - val_loss: 1.4968 - val_accuracy: 0.8036\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.0150e-04 - accuracy: 1.0000 - val_loss: 1.5131 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.7101e-04 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.3506e-04 - accuracy: 1.0000 - val_loss: 1.5247 - val_accuracy: 0.8036\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0691e-04 - accuracy: 1.0000 - val_loss: 1.5347 - val_accuracy: 0.8036\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.7560e-04 - accuracy: 1.0000 - val_loss: 1.5369 - val_accuracy: 0.8036\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5103e-04 - accuracy: 1.0000 - val_loss: 1.5356 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.2977e-04 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.8036\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0099e-04 - accuracy: 1.0000 - val_loss: 1.5470 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8155e-04 - accuracy: 1.0000 - val_loss: 1.5573 - val_accuracy: 0.8036\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.5853e-04 - accuracy: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.3783e-04 - accuracy: 1.0000 - val_loss: 1.5679 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 5.1615e-04 - accuracy: 1.0000 - val_loss: 1.5741 - val_accuracy: 0.8036\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0162e-04 - accuracy: 1.0000 - val_loss: 1.5765 - val_accuracy: 0.8036\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.8137e-04 - accuracy: 1.0000 - val_loss: 1.5811 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.6614e-04 - accuracy: 1.0000 - val_loss: 1.5892 - val_accuracy: 0.8036\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.5432e-04 - accuracy: 1.0000 - val_loss: 1.5979 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.4231e-04 - accuracy: 1.0000 - val_loss: 1.5934 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.2453e-04 - accuracy: 1.0000 - val_loss: 1.6026 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.1223e-04 - accuracy: 1.0000 - val_loss: 1.6056 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.9203e-04 - accuracy: 1.0000 - val_loss: 1.6143 - val_accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.7895e-04 - accuracy: 1.0000 - val_loss: 1.6112 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.6719e-04 - accuracy: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.5817e-04 - accuracy: 1.0000 - val_loss: 1.6279 - val_accuracy: 0.7679\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.4674e-04 - accuracy: 1.0000 - val_loss: 1.6306 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.3569e-04 - accuracy: 1.0000 - val_loss: 1.6306 - val_accuracy: 0.7679\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2505e-04 - accuracy: 1.0000 - val_loss: 1.6378 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.1620e-04 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0593e-04 - accuracy: 1.0000 - val_loss: 1.6472 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9591e-04 - accuracy: 1.0000 - val_loss: 1.6477 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8634e-04 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.7679\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.7980e-04 - accuracy: 1.0000 - val_loss: 1.6587 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.7109e-04 - accuracy: 1.0000 - val_loss: 1.6600 - val_accuracy: 0.7679\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.6419e-04 - accuracy: 1.0000 - val_loss: 1.6658 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.5689e-04 - accuracy: 1.0000 - val_loss: 1.6727 - val_accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.4932e-04 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.7679\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.4298e-04 - accuracy: 1.0000 - val_loss: 1.6794 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.3781e-04 - accuracy: 1.0000 - val_loss: 1.6830 - val_accuracy: 0.7679\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.2895e-04 - accuracy: 1.0000 - val_loss: 1.6842 - val_accuracy: 0.7679\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.2316e-04 - accuracy: 1.0000 - val_loss: 1.6906 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.1669e-04 - accuracy: 1.0000 - val_loss: 1.6922 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.1137e-04 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.0670e-04 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.0140e-04 - accuracy: 1.0000 - val_loss: 1.7086 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.9559e-04 - accuracy: 1.0000 - val_loss: 1.7031 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.9166e-04 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.7679\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.8625e-04 - accuracy: 1.0000 - val_loss: 1.7097 - val_accuracy: 0.7679\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.8141e-04 - accuracy: 1.0000 - val_loss: 1.7163 - val_accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.7666e-04 - accuracy: 1.0000 - val_loss: 1.7222 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.7203e-04 - accuracy: 1.0000 - val_loss: 1.7256 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.6794e-04 - accuracy: 1.0000 - val_loss: 1.7232 - val_accuracy: 0.7679\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.6398e-04 - accuracy: 1.0000 - val_loss: 1.7330 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5987e-04 - accuracy: 1.0000 - val_loss: 1.7346 - val_accuracy: 0.7679\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5537e-04 - accuracy: 1.0000 - val_loss: 1.7351 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5201e-04 - accuracy: 1.0000 - val_loss: 1.7427 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6480 - accuracy: 0.7862\n",
      "[test loss, test accuracy]: [1.6480294466018677, 0.7862318754196167]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
    "\n",
    "# Check Result\n",
    "y_pred_a = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_a, axis=1)\n",
    "\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ded1ce49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68        19\n",
      "           1       0.76      0.93      0.84        14\n",
      "           2       0.88      1.00      0.94        22\n",
      "           3       0.62      0.33      0.43        24\n",
      "           4       0.90      0.95      0.93        20\n",
      "           5       0.67      0.57      0.62        21\n",
      "           6       1.00      0.91      0.95        22\n",
      "           7       0.80      0.95      0.87        21\n",
      "           8       0.73      0.52      0.61        21\n",
      "           9       0.64      0.67      0.65        21\n",
      "          10       0.85      0.85      0.85        20\n",
      "          11       0.80      0.80      0.80        15\n",
      "          12       0.70      0.93      0.80        15\n",
      "          13       0.91      1.00      0.95        21\n",
      "\n",
      "    accuracy                           0.79       276\n",
      "   macro avg       0.78      0.80      0.78       276\n",
      "weighted avg       0.78      0.79      0.78       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_list = set(y_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_pred, y_test)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_list, yticklabels=class_list)\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix[0])):\n",
    "        if i == j:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='white')\n",
    "        else:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='black')\n",
    "            \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d440e015",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions.csv', np.hstack((y_test.reshape(-1, 1), y_pred.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ada0d7e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Mapping:\n",
      "{'bacterial_leaf_blight': 0, 'bacterial_leaf_streak': 1, 'bakanae': 2, 'brown_spot': 3, 'grassy_stunt_virus': 4, 'healthy_rice_plant': 5, 'narrow_brown_spot': 6, 'ragged_stunt_virus': 7, 'rice_blast': 8, 'rice_false_smut': 9, 'sheath_blight': 10, 'sheath_rot': 11, 'stem_rot': 12, 'tungro_virus': 13}\n"
     ]
    }
   ],
   "source": [
    "# Display the mapping between class names and encoded numbers\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\nClass Mapping:\")\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3359008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
