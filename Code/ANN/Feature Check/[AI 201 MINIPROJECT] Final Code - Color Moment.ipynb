{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64653a26-b164-4036-93b5-be0f7358a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxiliaries (Importing Datafile, Checking Time)\n",
    "import os \n",
    "import time\n",
    "\n",
    "# Calculations\n",
    "import numpy as np\n",
    "\n",
    "# For Importing Data Files\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from skimage import color\n",
    "\n",
    "# For Image Pre-Processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979b03d-2172-4465-999b-1e65d282be22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create dataframe\n",
    "\n",
    "3 columns\n",
    "1. Disease Classification\n",
    "2. Image Name\n",
    "3. Image RGB Values (RGB Converted from BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce4c625-de79-4861-b12a-56db5eb4203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def create_dataframe_from_folders(root_folder):\n",
    "    # Initialize empty lists to store data for each column\n",
    "    folder_names = []\n",
    "    photo_names = []\n",
    "    photos = []\n",
    "\n",
    "    # Traverse through the root folder and its subfolders\n",
    "    for folder_name in sorted(os.listdir(root_folder)):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if the entry in the root folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for photo_name in sorted(os.listdir(folder_path), key=natural_sort_key):\n",
    "                # Photos are in common image formats (e.g., jpg, png)\n",
    "                if photo_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    photo_path = os.path.join(folder_path, photo_name)\n",
    "\n",
    "                    # Read image data using cv2\n",
    "                    image_data = cv2.imread(photo_path)\n",
    "\n",
    "                    # Convert BGR to RGB\n",
    "                    image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Append data to the lists\n",
    "                    folder_names.append(folder_name)\n",
    "                    photo_names.append(photo_name)\n",
    "                    photos.append(image_data_rgb)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'class': folder_names,\n",
    "        'img_name': photo_names,\n",
    "        'rgb': photos\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af7bde-ac77-45fa-8c61-7a53363109b4",
   "metadata": {},
   "source": [
    "Get data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f698915-bb74-4ec7-8ff1-606c6471d686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   class                img_name  \\\n",
      "0  bacterial_leaf_blight  BLB_multi_leaf (1).jpg   \n",
      "1  bacterial_leaf_blight  BLB_multi_leaf (2).jpg   \n",
      "2  bacterial_leaf_blight  BLB_multi_leaf (3).jpg   \n",
      "3  bacterial_leaf_blight  BLB_multi_leaf (4).jpg   \n",
      "4  bacterial_leaf_blight  BLB_multi_leaf (5).jpg   \n",
      "\n",
      "                                                 rgb  \n",
      "0  [[[115, 152, 47], [78, 113, 9], [116, 147, 43]...  \n",
      "1  [[[198, 218, 97], [190, 210, 89], [189, 208, 9...  \n",
      "2  [[[137, 176, 51], [166, 203, 64], [165, 200, 3...  \n",
      "3  [[[192, 212, 143], [201, 222, 157], [187, 206,...  \n",
      "4  [[[132, 176, 27], [135, 180, 27], [161, 206, 4...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "extra_resized_folder_path = r\"C:\\Users\\Josh\\000 Files\\003 Mengg AI\\01a 201 (AI)\\03 Mini-Project\\resized_raw_images (14 Classes)\"\n",
    "extra_resized = create_dataframe_from_folders(extra_resized_folder_path)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(extra_resized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5426b9d-5fe5-470e-95cd-b9bd72e1875a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Class Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be65000-1849-48e3-b646-93efd2758afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "bakanae                  100\n",
      "brown_spot               100\n",
      "grassy_stunt_virus       100\n",
      "healthy_rice_plant       100\n",
      "ragged_stunt_virus       100\n",
      "stem_rot                 100\n",
      "tungro_virus             100\n",
      "bacterial_leaf_streak     99\n",
      "rice_false_smut           99\n",
      "narrow_brown_spot         98\n",
      "rice_blast                98\n",
      "sheath_blight             98\n",
      "bacterial_leaf_blight     97\n",
      "sheath_rot                91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = extra_resized['class'].value_counts()\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac8225-3fe7-4259-a715-381055cfb61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d99ab4-0a06-495a-8af2-2d2ca69d19a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Texture Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef73441b-106f-4a76-af4a-30d0192a58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mahotas\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def compute_glcm_features(df):\n",
    "    df['gray'] = df['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2GRAY))\n",
    "    def calculate_glcm(gray_image):\n",
    "        # Compute GLCM using mahotas\n",
    "        glcm = mahotas.features.haralick(gray_image.astype(np.uint8), ignore_zeros=True)\n",
    "        return glcm.mean(axis=0)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gray_image = row['gray']\n",
    "        glcm_features = calculate_glcm(gray_image)\n",
    "        features.append(glcm_features)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Define meaningful column names for GLCM features\n",
    "    glcm_columns = [\n",
    "        'Angular Second Moment',\n",
    "        'Contrast',\n",
    "        'Correlation',\n",
    "        'Sum of Squares: Variance',\n",
    "        'Inverse Difference Moment',\n",
    "        'Sum Average',\n",
    "        'Sum Variance',\n",
    "        'Sum Entropy',\n",
    "        'Entropy',\n",
    "        'Difference Variance',\n",
    "        'Difference Entropy',\n",
    "        'Informational Measure of Correlation 1',\n",
    "        'Informational Measure of Correlation 2'\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with the new GLCM features and meaningful column names\n",
    "    glcm_df = pd.DataFrame(features, columns=[f'GLCM_{col}' for col in glcm_columns])\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, glcm_df], axis=1)\n",
    "\n",
    "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2b059a-fa17-4742-a4e9-61286361606a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 34.97 seconds\n"
     ]
    }
   ],
   "source": [
    "glcm = compute_glcm_features(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564a00a9-a6ed-4d71-b79b-82ded4744d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the first n columns\n",
    "f_glcm = glcm.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3555e8-efe3-4a70-8258-9bf9d11a2d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_Angular Second Moment</th>\n",
       "      <th>GLCM_Contrast</th>\n",
       "      <th>GLCM_Correlation</th>\n",
       "      <th>GLCM_Sum of Squares: Variance</th>\n",
       "      <th>GLCM_Inverse Difference Moment</th>\n",
       "      <th>GLCM_Sum Average</th>\n",
       "      <th>GLCM_Sum Variance</th>\n",
       "      <th>GLCM_Sum Entropy</th>\n",
       "      <th>GLCM_Entropy</th>\n",
       "      <th>GLCM_Difference Variance</th>\n",
       "      <th>GLCM_Difference Entropy</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 1</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>1876.058313</td>\n",
       "      <td>0.693690</td>\n",
       "      <td>3062.090566</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>281.006018</td>\n",
       "      <td>10372.303952</td>\n",
       "      <td>8.629042</td>\n",
       "      <td>14.243405</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>6.206143</td>\n",
       "      <td>-0.154215</td>\n",
       "      <td>0.950487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>1334.884861</td>\n",
       "      <td>0.797998</td>\n",
       "      <td>3303.508641</td>\n",
       "      <td>0.077155</td>\n",
       "      <td>276.277140</td>\n",
       "      <td>11879.149702</td>\n",
       "      <td>8.601060</td>\n",
       "      <td>14.082083</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>6.006272</td>\n",
       "      <td>-0.160813</td>\n",
       "      <td>0.952879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000140</td>\n",
       "      <td>1340.143870</td>\n",
       "      <td>0.744815</td>\n",
       "      <td>2625.859569</td>\n",
       "      <td>0.091972</td>\n",
       "      <td>293.873154</td>\n",
       "      <td>9163.294405</td>\n",
       "      <td>8.446153</td>\n",
       "      <td>13.764957</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>5.900897</td>\n",
       "      <td>-0.165284</td>\n",
       "      <td>0.954139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>1293.754229</td>\n",
       "      <td>0.776222</td>\n",
       "      <td>2890.458305</td>\n",
       "      <td>0.071097</td>\n",
       "      <td>289.332162</td>\n",
       "      <td>10268.078990</td>\n",
       "      <td>8.648174</td>\n",
       "      <td>14.226573</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>6.040155</td>\n",
       "      <td>-0.157107</td>\n",
       "      <td>0.952233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000101</td>\n",
       "      <td>1076.703851</td>\n",
       "      <td>0.693791</td>\n",
       "      <td>1757.932426</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>284.620945</td>\n",
       "      <td>5955.025853</td>\n",
       "      <td>8.284213</td>\n",
       "      <td>13.795743</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>5.881877</td>\n",
       "      <td>-0.134893</td>\n",
       "      <td>0.923023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_Angular Second Moment  GLCM_Contrast  GLCM_Correlation  \\\n",
       "0                    0.000093    1876.058313          0.693690   \n",
       "1                    0.000090    1334.884861          0.797998   \n",
       "2                    0.000140    1340.143870          0.744815   \n",
       "3                    0.000071    1293.754229          0.776222   \n",
       "4                    0.000101    1076.703851          0.693791   \n",
       "\n",
       "   GLCM_Sum of Squares: Variance  GLCM_Inverse Difference Moment  \\\n",
       "0                    3062.090566                        0.086892   \n",
       "1                    3303.508641                        0.077155   \n",
       "2                    2625.859569                        0.091972   \n",
       "3                    2890.458305                        0.071097   \n",
       "4                    1757.932426                        0.082002   \n",
       "\n",
       "   GLCM_Sum Average  GLCM_Sum Variance  GLCM_Sum Entropy  GLCM_Entropy  \\\n",
       "0        281.006018       10372.303952          8.629042     14.243405   \n",
       "1        276.277140       11879.149702          8.601060     14.082083   \n",
       "2        293.873154        9163.294405          8.446153     13.764957   \n",
       "3        289.332162       10268.078990          8.648174     14.226573   \n",
       "4        284.620945        5955.025853          8.284213     13.795743   \n",
       "\n",
       "   GLCM_Difference Variance  GLCM_Difference Entropy  \\\n",
       "0                  0.000072                 6.206143   \n",
       "1                  0.000079                 6.006272   \n",
       "2                  0.000095                 5.900897   \n",
       "3                  0.000073                 6.040155   \n",
       "4                  0.000086                 5.881877   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 1  \\\n",
       "0                                    -0.154215   \n",
       "1                                    -0.160813   \n",
       "2                                    -0.165284   \n",
       "3                                    -0.157107   \n",
       "4                                    -0.134893   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 2  \n",
       "0                                     0.950487  \n",
       "1                                     0.952879  \n",
       "2                                     0.954139  \n",
       "3                                     0.952233  \n",
       "4                                     0.923023  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_glcm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ad4b-7eb0-4110-bcb4-6e592e28d837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94ca35f-9437-4b01-8009-1a0eed2ae870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354c8451-629c-447d-beef-076db3311418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def values(dataframe):\n",
    "    # Ensure the 'rgb' column exists in the dataframe\n",
    "    dataframe['hsv'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2HSV))\n",
    "    #dataframe['hsi'] = dataframe['rgb'].apply(lambda x: color.rgb2hsi(np.uint8(x)))\n",
    "    dataframe['lab'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    dataframe['red'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,0])\n",
    "    dataframe['green'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,1])\n",
    "    dataframe['blue'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,2])\n",
    "    \n",
    "    dataframe['hue_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,0])\n",
    "    dataframe['saturation_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,1])\n",
    "    dataframe['value_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,2])\n",
    "    \n",
    "    #dataframe['hue_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,0])\n",
    "    #dataframe['saturation_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,1])\n",
    "    #dataframe['intensity_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,2])\n",
    "    \n",
    "    dataframe['lightness'] = dataframe['lab'].apply(lambda lab: lab[:, :, 0])\n",
    "    dataframe['a'] = dataframe['lab'].apply(lambda lab: lab[:, :, 1])\n",
    "    dataframe['b'] = dataframe['lab'].apply(lambda lab: lab[:, :, 2])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5082c1-48a7-4a77-ae63-d276523f8173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_bins_to_dataframe(dataframe, column_name, num_bins):\n",
    "    # Extract the specified column\n",
    "    original_column = dataframe[column_name]\n",
    "\n",
    "    # Define bin edges based on the min and max values in the matrices\n",
    "    min_value = np.min([np.min(matrix) for matrix in original_column])\n",
    "    max_value = np.max([np.max(matrix) for matrix in original_column])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "    # Create column names for the bins\n",
    "    bin_column_names = [f'{column_name}_{i}' for i in range(num_bins)]\n",
    "\n",
    "    # Iterate through each matrix in the original column\n",
    "    for i, matrix in enumerate(original_column):\n",
    "        # Digitize each element in the matrix into the corresponding bin\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "\n",
    "        # Count the occurrences of each bin index\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        # Add new columns to the DataFrame for each bin\n",
    "        for j, bin_column_name in enumerate(bin_column_names):\n",
    "            dataframe.loc[i, bin_column_name] = bin_counts[j]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb1fba-0704-4f4b-b34a-2e2ef1cbd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = values(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ab83c9-fc0e-4cff-9869-3fa8c12e4469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_bins_dataframe(dataframe, col, num_bins):\n",
    "    bins_dataframe = pd.DataFrame()\n",
    "\n",
    "    #print(col)\n",
    "    min_value = np.min([np.min(matrix) for matrix in dataframe[col]])\n",
    "    max_value = np.max([np.max(matrix) for matrix in dataframe[col]])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "    bin_column_names = [f'{col}_{i}' for i in range(1, num_bins + 1)]\n",
    "\n",
    "    for matrix in dataframe[col]:\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        bins_dataframe = pd.concat([bins_dataframe, pd.DataFrame(bin_counts).transpose()], axis=0, ignore_index=True)\n",
    "\n",
    "    bins_dataframe.columns = bin_column_names\n",
    "        \n",
    "    return bins_dataframe\n",
    "\n",
    "def hist_features(df, cols, bins):\n",
    "    complete_bins = pd.DataFrame()\n",
    "\n",
    "    for col in cols:\n",
    "        col_bins = create_bins_dataframe(df, col, bins)\n",
    "        complete_bins = pd.concat([complete_bins, col_bins], axis=1)\n",
    "\n",
    "    return complete_bins\n",
    "\n",
    "cols = ['red', 'green', 'blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef1f4f2-7b29-4783-80bb-942502c3f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_histogram = hist_features(channels, cols, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200b7499-7dd8-4545-a930-7e28dd715d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>red_10</th>\n",
       "      <th>...</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "      <th>b_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>223</td>\n",
       "      <td>231</td>\n",
       "      <td>305</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>210</td>\n",
       "      <td>261</td>\n",
       "      <td>308</td>\n",
       "      <td>349</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>358</td>\n",
       "      <td>383</td>\n",
       "      <td>554</td>\n",
       "      <td>...</td>\n",
       "      <td>541</td>\n",
       "      <td>556</td>\n",
       "      <td>187</td>\n",
       "      <td>98</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>290</td>\n",
       "      <td>337</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>454</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>1417</td>\n",
       "      <td>1133</td>\n",
       "      <td>195</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_1  red_2  red_3  red_4  red_5  red_6  red_7  red_8  red_9  red_10  ...  \\\n",
       "0     19     47     93    143    223    231    305    314    330     432  ...   \n",
       "1    153    210    261    308    349    391    392    358    383     554  ...   \n",
       "2     14     35     62    145    205    290    337    325    338     454  ...   \n",
       "3     14     14     40     53     89    106    194    242    267     436  ...   \n",
       "4      0      1      3      4      1      6      6      9      8      31  ...   \n",
       "\n",
       "   b_73  b_74  b_75  b_76  b_77  b_78  b_79  b_80  b_81  b_82  \n",
       "0    73    27     0     0     0     0     0     0     0     0  \n",
       "1   541   556   187    98    47    33     0     0     0     0  \n",
       "2   157    51     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4  1417  1133   195    42     8     1     0     0     0     0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_histogram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58cb8f-65ac-44fc-99e6-58e42abfabfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Color Moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b0823e-3e5b-4f1c-95a6-8b8b4cc97e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "\n",
    "def color_moments(dataframe, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        mean_values = []\n",
    "        variance_values = []\n",
    "        kurtosis_values = []\n",
    "        skewness_values = []\n",
    "\n",
    "        for img in dataframe[col]:\n",
    "            # 'img' is a 3D numpy array representing an RGB image\n",
    "            # Calculate statistics for each image\n",
    "            mean_channel = np.mean(img, axis=(0, 1))\n",
    "            variance_channel = np.var(img, axis=(0, 1))\n",
    "            kurtosis_channel = kurtosis(img, axis=(0, 1))\n",
    "            skewness_channel = skew(img, axis=(0, 1))\n",
    "\n",
    "            # Append values to respective lists\n",
    "            mean_values.append(mean_channel)\n",
    "            variance_values.append(variance_channel)\n",
    "            kurtosis_values.append(kurtosis_channel)\n",
    "            skewness_values.append(skewness_channel)\n",
    "\n",
    "        # Add the new columns to the DataFrame with channel names\n",
    "        for i in range(img.shape[2]):  # 'img' has shape (height, width, channels)\n",
    "            dataframe[f'{col}_channel_{i}_mean'] = [x[i] for x in mean_values]\n",
    "            dataframe[f'{col}_channel_{i}_variance'] = [x[i] for x in variance_values]\n",
    "            dataframe[f'{col}_channel_{i}_kurtosis'] = [x[i] for x in kurtosis_values]\n",
    "            dataframe[f'{col}_channel_{i}_skewness'] = [x[i] for x in skewness_values]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cc9e6e-ddcb-41fe-aa4b-72e3f44afc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb\n",
      "hsv\n",
      "lab\n"
     ]
    }
   ],
   "source": [
    "color_df = color_moments(extra_resized, ['rgb','hsv','lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c245d80-93b2-4cc8-82a3-77f40ab9b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_color = color_df.drop(columns=['class','img_name','rgb','gray','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52a436e-88b8-43bc-b1d7-b17b428f0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>rgb_channel_2_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "      <th>lab_channel_2_skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.110013</td>\n",
       "      <td>3078.218207</td>\n",
       "      <td>-0.689453</td>\n",
       "      <td>-0.192670</td>\n",
       "      <td>157.315011</td>\n",
       "      <td>3449.301597</td>\n",
       "      <td>-0.484632</td>\n",
       "      <td>-0.518085</td>\n",
       "      <td>67.831274</td>\n",
       "      <td>2087.782836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296129</td>\n",
       "      <td>-0.606758</td>\n",
       "      <td>106.950853</td>\n",
       "      <td>61.335754</td>\n",
       "      <td>0.410354</td>\n",
       "      <td>0.917856</td>\n",
       "      <td>169.947226</td>\n",
       "      <td>203.966363</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>-0.576146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.208227</td>\n",
       "      <td>3961.755789</td>\n",
       "      <td>-1.130258</td>\n",
       "      <td>-0.302681</td>\n",
       "      <td>158.333586</td>\n",
       "      <td>3558.081163</td>\n",
       "      <td>-0.908913</td>\n",
       "      <td>-0.458059</td>\n",
       "      <td>50.368921</td>\n",
       "      <td>1453.704717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781886</td>\n",
       "      <td>-0.534726</td>\n",
       "      <td>103.516083</td>\n",
       "      <td>21.999662</td>\n",
       "      <td>2.755215</td>\n",
       "      <td>1.327478</td>\n",
       "      <td>177.711097</td>\n",
       "      <td>198.029258</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>-0.735196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143.534598</td>\n",
       "      <td>2684.064771</td>\n",
       "      <td>-0.122034</td>\n",
       "      <td>-0.726785</td>\n",
       "      <td>163.988122</td>\n",
       "      <td>3032.684210</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>-0.932985</td>\n",
       "      <td>67.333745</td>\n",
       "      <td>1393.034182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395657</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>106.869300</td>\n",
       "      <td>39.706570</td>\n",
       "      <td>1.180393</td>\n",
       "      <td>1.184484</td>\n",
       "      <td>173.509228</td>\n",
       "      <td>201.620730</td>\n",
       "      <td>0.534828</td>\n",
       "      <td>-0.842716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.806521</td>\n",
       "      <td>3150.853829</td>\n",
       "      <td>-0.752603</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>155.817223</td>\n",
       "      <td>2935.205771</td>\n",
       "      <td>-0.687641</td>\n",
       "      <td>-0.282174</td>\n",
       "      <td>112.783462</td>\n",
       "      <td>2356.163989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573437</td>\n",
       "      <td>-0.355013</td>\n",
       "      <td>112.668666</td>\n",
       "      <td>26.981995</td>\n",
       "      <td>2.443752</td>\n",
       "      <td>0.798156</td>\n",
       "      <td>148.112783</td>\n",
       "      <td>56.290194</td>\n",
       "      <td>1.918221</td>\n",
       "      <td>-0.305414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133.956593</td>\n",
       "      <td>1928.268962</td>\n",
       "      <td>-0.601913</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>165.174087</td>\n",
       "      <td>1995.183999</td>\n",
       "      <td>-0.653920</td>\n",
       "      <td>-0.250057</td>\n",
       "      <td>46.036372</td>\n",
       "      <td>1525.296728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566688</td>\n",
       "      <td>-0.252408</td>\n",
       "      <td>101.051419</td>\n",
       "      <td>77.759832</td>\n",
       "      <td>0.647577</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>180.711256</td>\n",
       "      <td>190.856598</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>-0.751957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgb_channel_0_mean  rgb_channel_0_variance  rgb_channel_0_kurtosis  \\\n",
       "0          135.110013             3078.218207               -0.689453   \n",
       "1          132.208227             3961.755789               -1.130258   \n",
       "2          143.534598             2684.064771               -0.122034   \n",
       "3          134.806521             3150.853829               -0.752603   \n",
       "4          133.956593             1928.268962               -0.601913   \n",
       "\n",
       "   rgb_channel_0_skewness  rgb_channel_1_mean  rgb_channel_1_variance  \\\n",
       "0               -0.192670          157.315011             3449.301597   \n",
       "1               -0.302681          158.333586             3558.081163   \n",
       "2               -0.726785          163.988122             3032.684210   \n",
       "3                0.011988          155.817223             2935.205771   \n",
       "4                0.189324          165.174087             1995.183999   \n",
       "\n",
       "   rgb_channel_1_kurtosis  rgb_channel_1_skewness  rgb_channel_2_mean  \\\n",
       "0               -0.484632               -0.518085           67.831274   \n",
       "1               -0.908913               -0.458059           50.368921   \n",
       "2                0.098623               -0.932985           67.333745   \n",
       "3               -0.687641               -0.282174          112.783462   \n",
       "4               -0.653920               -0.250057           46.036372   \n",
       "\n",
       "   rgb_channel_2_variance  ...  lab_channel_0_kurtosis  \\\n",
       "0             2087.782836  ...               -0.296129   \n",
       "1             1453.704717  ...               -0.781886   \n",
       "2             1393.034182  ...                0.395657   \n",
       "3             2356.163989  ...               -0.573437   \n",
       "4             1525.296728  ...               -0.566688   \n",
       "\n",
       "   lab_channel_0_skewness  lab_channel_1_mean  lab_channel_1_variance  \\\n",
       "0               -0.606758          106.950853               61.335754   \n",
       "1               -0.534726          103.516083               21.999662   \n",
       "2               -1.041771          106.869300               39.706570   \n",
       "3               -0.355013          112.668666               26.981995   \n",
       "4               -0.252408          101.051419               77.759832   \n",
       "\n",
       "   lab_channel_1_kurtosis  lab_channel_1_skewness  lab_channel_2_mean  \\\n",
       "0                0.410354                0.917856          169.947226   \n",
       "1                2.755215                1.327478          177.711097   \n",
       "2                1.180393                1.184484          173.509228   \n",
       "3                2.443752                0.798156          148.112783   \n",
       "4                0.647577                1.165816          180.711256   \n",
       "\n",
       "   lab_channel_2_variance  lab_channel_2_kurtosis  lab_channel_2_skewness  \n",
       "0              203.966363                0.049806               -0.576146  \n",
       "1              198.029258                0.350495               -0.735196  \n",
       "2              201.620730                0.534828               -0.842716  \n",
       "3               56.290194                1.918221               -0.305414  \n",
       "4              190.856598                0.315457               -0.751957  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_color.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374ff69-1bee-49c9-a127-38bf7b2154fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Zernike Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2e3d8b-9bcb-4314-8271-fbda88d99c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas.features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def zernike(df, zernike_order):\n",
    "    features_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        gray_img = row['gray']\n",
    "\n",
    "        # Check if the image is grayscale\n",
    "        if len(gray_img.shape) == 2:\n",
    "            # If grayscale, compute Zernike moments directly\n",
    "            moments = mahotas.features.zernike_moments(gray_img, radius=zernike_order)\n",
    "        else:\n",
    "            raise ValueError(\"Input image must be grayscale.\")\n",
    "\n",
    "        features_list.append(moments)\n",
    "\n",
    "    # Determine the number of features per image\n",
    "    num_features_per_image = len(features_list[0])\n",
    "\n",
    "    # Add features to the DataFrame\n",
    "    feature_columns = [f'feature_{i}' for i in range(num_features_per_image)]\n",
    "    df_features = pd.DataFrame(features_list, columns=feature_columns)\n",
    "    df_result = pd.concat([df, df_features], axis=1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2839e315-3874-4df5-9d76-5f159e11d6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.085352</td>\n",
       "      <td>0.096424</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>0.047294</td>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>0.021023</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.030770</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.047826</td>\n",
       "      <td>0.057547</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.035470</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.037121</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.044010</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>0.050413</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.056392</td>\n",
       "      <td>0.064779</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048771</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    0.31831   0.017224   0.085352   0.096424   0.007132   0.019454   \n",
       "1    0.31831   0.014304   0.028368   0.037181   0.013888   0.019413   \n",
       "2    0.31831   0.079290   0.030770   0.009481   0.047826   0.057547   \n",
       "3    0.31831   0.037962   0.004782   0.037121   0.070988   0.044010   \n",
       "4    0.31831   0.008223   0.041976   0.050413   0.029785   0.035719   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0   0.035195   0.047294   0.034389   0.012664  ...    0.021457    0.009277   \n",
       "1   0.032812   0.021023   0.036471   0.003854  ...    0.019798    0.021939   \n",
       "2   0.014013   0.021884   0.035470   0.021808  ...    0.028761    0.049967   \n",
       "3   0.004336   0.021578   0.015647   0.008096  ...    0.017136    0.012084   \n",
       "4   0.045422   0.056392   0.064779   0.029646  ...    0.025135    0.003060   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.024865    0.004817    0.017575    0.003713    0.003742    0.016868   \n",
       "1    0.024250    0.033492    0.027907    0.000967    0.009835    0.017213   \n",
       "2    0.039179    0.039791    0.023068    0.031944    0.021562    0.009072   \n",
       "3    0.020084    0.021049    0.013913    0.004487    0.017935    0.029116   \n",
       "4    0.024900    0.048771    0.041041    0.005773    0.034733    0.012531   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.031700    0.035992  \n",
       "1    0.006593    0.008411  \n",
       "2    0.019779    0.024128  \n",
       "3    0.023423    0.023256  \n",
       "4    0.014290    0.004188  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zernike_df = zernike(extra_resized, 10)\n",
    "f_zernike = zernike_df.iloc[:, 51:]\n",
    "f_zernike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f9f14-f5c1-49e8-bc81-0ff472678dd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Legendre Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c31faf-4303-4c2c-9116-db4207ca5f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extra_resized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11c6966-8fce-4fe6-b283-0ae5a249459b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_input = extra_resized.drop(columns=['class','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])\n",
    "l_input = l_input.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797a48fb-2cbb-4377-a2c7-c851bf96b9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>rgb</th>\n",
       "      <th>gray</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLB_multi_leaf (1).jpg</td>\n",
       "      <td>[[[115, 152, 47], [78, 113, 9], [116, 147, 43]...</td>\n",
       "      <td>[[129, 91, 126, 196, 208, 157, 175, 128, 114, ...</td>\n",
       "      <td>135.110013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLB_multi_leaf (2).jpg</td>\n",
       "      <td>[[[198, 218, 97], [190, 210, 89], [189, 208, 9...</td>\n",
       "      <td>[[198, 190, 189, 183, 189, 189, 187, 187, 189,...</td>\n",
       "      <td>132.208227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLB_multi_leaf (3).jpg</td>\n",
       "      <td>[[[137, 176, 51], [166, 203, 64], [165, 200, 3...</td>\n",
       "      <td>[[150, 176, 171, 177, 193, 187, 142, 136, 135,...</td>\n",
       "      <td>143.534598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLB_multi_leaf (4).jpg</td>\n",
       "      <td>[[[192, 212, 143], [201, 222, 157], [187, 206,...</td>\n",
       "      <td>[[198, 208, 194, 198, 196, 159, 143, 145, 165,...</td>\n",
       "      <td>134.806521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLB_multi_leaf (5).jpg</td>\n",
       "      <td>[[[132, 176, 27], [135, 180, 27], [161, 206, 4...</td>\n",
       "      <td>[[146, 149, 174, 126, 153, 153, 185, 201, 210,...</td>\n",
       "      <td>133.956593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 img_name                                                rgb  \\\n",
       "0  BLB_multi_leaf (1).jpg  [[[115, 152, 47], [78, 113, 9], [116, 147, 43]...   \n",
       "1  BLB_multi_leaf (2).jpg  [[[198, 218, 97], [190, 210, 89], [189, 208, 9...   \n",
       "2  BLB_multi_leaf (3).jpg  [[[137, 176, 51], [166, 203, 64], [165, 200, 3...   \n",
       "3  BLB_multi_leaf (4).jpg  [[[192, 212, 143], [201, 222, 157], [187, 206,...   \n",
       "4  BLB_multi_leaf (5).jpg  [[[132, 176, 27], [135, 180, 27], [161, 206, 4...   \n",
       "\n",
       "                                                gray  rgb_channel_0_mean  \n",
       "0  [[129, 91, 126, 196, 208, 157, 175, 128, 114, ...          135.110013  \n",
       "1  [[198, 190, 189, 183, 189, 189, 187, 187, 189,...          132.208227  \n",
       "2  [[150, 176, 171, 177, 193, 187, 142, 136, 135,...          143.534598  \n",
       "3  [[198, 208, 194, 198, 196, 159, 143, 145, 165,...          134.806521  \n",
       "4  [[146, 149, 174, 126, 153, 153, 185, 201, 210,...          133.956593  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac178d0-3ed3-4c52-a778-5ae124e3d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.special import legendre\n",
    "\n",
    "def compute_legendre_features(rgb_image, degree):\n",
    "    # Get V channel from RGB image\n",
    "    v_channel = rgb_image[:, :, 2]\n",
    "\n",
    "    # Define x and y coordinates\n",
    "    x_size, y_size = v_channel.shape\n",
    "    x = np.linspace(-1, 1, x_size)\n",
    "    y = np.linspace(-1, 1, y_size)\n",
    "\n",
    "    # Compute Legendre features for the V channel\n",
    "    legendre_features = np.zeros((degree + 1, degree + 1))\n",
    "\n",
    "    for j in range(degree + 1):\n",
    "        for k in range(degree + 1):\n",
    "            legendre_features[j, k] = np.sum(v_channel * legendre(j)(x) * legendre(k)(y))\n",
    "\n",
    "    return legendre_features.flatten()\n",
    "\n",
    "def add_legendre(df, degree):\n",
    "    # Create a new DataFrame for Legendre features\n",
    "    legendre_columns = [f'v_legendre_{i}_{j}' for i in range(degree + 1) for j in range(degree + 1)]\n",
    "    legendre_df = pd.DataFrame(df['rgb'].apply(lambda rgb: compute_legendre_features(rgb, degree)).values.tolist(), columns=legendre_columns)\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, legendre_df], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43846dc1-14e3-448d-adc4-a22e38c851ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "legendre_df = add_legendre(l_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74b7ce3-9c49-42a7-95d2-ea2df961247b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_legendre_0_0</th>\n",
       "      <th>v_legendre_0_1</th>\n",
       "      <th>v_legendre_0_2</th>\n",
       "      <th>v_legendre_0_3</th>\n",
       "      <th>v_legendre_0_4</th>\n",
       "      <th>v_legendre_0_5</th>\n",
       "      <th>v_legendre_0_6</th>\n",
       "      <th>v_legendre_0_7</th>\n",
       "      <th>v_legendre_0_8</th>\n",
       "      <th>v_legendre_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>v_legendre_10_1</th>\n",
       "      <th>v_legendre_10_2</th>\n",
       "      <th>v_legendre_10_3</th>\n",
       "      <th>v_legendre_10_4</th>\n",
       "      <th>v_legendre_10_5</th>\n",
       "      <th>v_legendre_10_6</th>\n",
       "      <th>v_legendre_10_7</th>\n",
       "      <th>v_legendre_10_8</th>\n",
       "      <th>v_legendre_10_9</th>\n",
       "      <th>v_legendre_10_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3403502.0</td>\n",
       "      <td>97362.493274</td>\n",
       "      <td>-48201.759416</td>\n",
       "      <td>-43493.535531</td>\n",
       "      <td>-7187.545250</td>\n",
       "      <td>-13629.967522</td>\n",
       "      <td>26794.954058</td>\n",
       "      <td>-16840.577069</td>\n",
       "      <td>-19979.273476</td>\n",
       "      <td>3169.619967</td>\n",
       "      <td>...</td>\n",
       "      <td>11979.555139</td>\n",
       "      <td>6950.403894</td>\n",
       "      <td>-1337.870389</td>\n",
       "      <td>10980.581080</td>\n",
       "      <td>-2731.321916</td>\n",
       "      <td>13832.668995</td>\n",
       "      <td>-4770.100418</td>\n",
       "      <td>6167.284262</td>\n",
       "      <td>4327.878377</td>\n",
       "      <td>171054.141659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2527311.0</td>\n",
       "      <td>103013.053812</td>\n",
       "      <td>-36361.603672</td>\n",
       "      <td>5917.770393</td>\n",
       "      <td>47863.129349</td>\n",
       "      <td>1575.078268</td>\n",
       "      <td>12099.674282</td>\n",
       "      <td>-3201.383018</td>\n",
       "      <td>18315.225460</td>\n",
       "      <td>1422.844543</td>\n",
       "      <td>...</td>\n",
       "      <td>-821.672825</td>\n",
       "      <td>16762.645859</td>\n",
       "      <td>2097.910709</td>\n",
       "      <td>12284.262029</td>\n",
       "      <td>195.439018</td>\n",
       "      <td>20480.883830</td>\n",
       "      <td>3132.492664</td>\n",
       "      <td>11516.628122</td>\n",
       "      <td>8400.271678</td>\n",
       "      <td>134299.780209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3378538.0</td>\n",
       "      <td>57117.757848</td>\n",
       "      <td>-80632.660661</td>\n",
       "      <td>-510.363287</td>\n",
       "      <td>11451.263244</td>\n",
       "      <td>-12619.841113</td>\n",
       "      <td>-28828.907259</td>\n",
       "      <td>-769.368737</td>\n",
       "      <td>27917.794633</td>\n",
       "      <td>-6883.608118</td>\n",
       "      <td>...</td>\n",
       "      <td>3963.350675</td>\n",
       "      <td>18954.699088</td>\n",
       "      <td>-2074.126958</td>\n",
       "      <td>8085.322444</td>\n",
       "      <td>1051.648198</td>\n",
       "      <td>8771.579378</td>\n",
       "      <td>-2117.981725</td>\n",
       "      <td>3647.296353</td>\n",
       "      <td>5448.970980</td>\n",
       "      <td>164009.682234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5659023.0</td>\n",
       "      <td>-217617.215247</td>\n",
       "      <td>39749.222928</td>\n",
       "      <td>-6034.575324</td>\n",
       "      <td>13640.673159</td>\n",
       "      <td>21378.007074</td>\n",
       "      <td>44068.112251</td>\n",
       "      <td>-24151.624353</td>\n",
       "      <td>14049.614456</td>\n",
       "      <td>-33151.322155</td>\n",
       "      <td>...</td>\n",
       "      <td>-4619.286498</td>\n",
       "      <td>15514.090473</td>\n",
       "      <td>-6651.294307</td>\n",
       "      <td>31327.480610</td>\n",
       "      <td>553.852950</td>\n",
       "      <td>28293.237294</td>\n",
       "      <td>-4090.823341</td>\n",
       "      <td>27115.154433</td>\n",
       "      <td>-18929.538381</td>\n",
       "      <td>296838.144091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2309921.0</td>\n",
       "      <td>-148810.686099</td>\n",
       "      <td>-37569.159223</td>\n",
       "      <td>52055.054845</td>\n",
       "      <td>44925.442955</td>\n",
       "      <td>-23770.114279</td>\n",
       "      <td>17043.186742</td>\n",
       "      <td>11900.041479</td>\n",
       "      <td>1297.065850</td>\n",
       "      <td>-35581.018742</td>\n",
       "      <td>...</td>\n",
       "      <td>-9263.364484</td>\n",
       "      <td>11693.901946</td>\n",
       "      <td>-7594.119586</td>\n",
       "      <td>7040.301359</td>\n",
       "      <td>-2945.920523</td>\n",
       "      <td>20936.096634</td>\n",
       "      <td>1642.000010</td>\n",
       "      <td>5613.007761</td>\n",
       "      <td>-10798.603049</td>\n",
       "      <td>122542.843959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v_legendre_0_0  v_legendre_0_1  v_legendre_0_2  v_legendre_0_3  \\\n",
       "0       3403502.0    97362.493274   -48201.759416   -43493.535531   \n",
       "1       2527311.0   103013.053812   -36361.603672     5917.770393   \n",
       "2       3378538.0    57117.757848   -80632.660661     -510.363287   \n",
       "3       5659023.0  -217617.215247    39749.222928    -6034.575324   \n",
       "4       2309921.0  -148810.686099   -37569.159223    52055.054845   \n",
       "\n",
       "   v_legendre_0_4  v_legendre_0_5  v_legendre_0_6  v_legendre_0_7  \\\n",
       "0    -7187.545250   -13629.967522    26794.954058   -16840.577069   \n",
       "1    47863.129349     1575.078268    12099.674282    -3201.383018   \n",
       "2    11451.263244   -12619.841113   -28828.907259     -769.368737   \n",
       "3    13640.673159    21378.007074    44068.112251   -24151.624353   \n",
       "4    44925.442955   -23770.114279    17043.186742    11900.041479   \n",
       "\n",
       "   v_legendre_0_8  v_legendre_0_9  ...  v_legendre_10_1  v_legendre_10_2  \\\n",
       "0   -19979.273476     3169.619967  ...     11979.555139      6950.403894   \n",
       "1    18315.225460     1422.844543  ...      -821.672825     16762.645859   \n",
       "2    27917.794633    -6883.608118  ...      3963.350675     18954.699088   \n",
       "3    14049.614456   -33151.322155  ...     -4619.286498     15514.090473   \n",
       "4     1297.065850   -35581.018742  ...     -9263.364484     11693.901946   \n",
       "\n",
       "   v_legendre_10_3  v_legendre_10_4  v_legendre_10_5  v_legendre_10_6  \\\n",
       "0     -1337.870389     10980.581080     -2731.321916     13832.668995   \n",
       "1      2097.910709     12284.262029       195.439018     20480.883830   \n",
       "2     -2074.126958      8085.322444      1051.648198      8771.579378   \n",
       "3     -6651.294307     31327.480610       553.852950     28293.237294   \n",
       "4     -7594.119586      7040.301359     -2945.920523     20936.096634   \n",
       "\n",
       "   v_legendre_10_7  v_legendre_10_8  v_legendre_10_9  v_legendre_10_10  \n",
       "0     -4770.100418      6167.284262      4327.878377     171054.141659  \n",
       "1      3132.492664     11516.628122      8400.271678     134299.780209  \n",
       "2     -2117.981725      3647.296353      5448.970980     164009.682234  \n",
       "3     -4090.823341     27115.154433    -18929.538381     296838.144091  \n",
       "4      1642.000010      5613.007761    -10798.603049     122542.843959  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_legendre = legendre_df.iloc[:, 4:]\n",
    "f_legendre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bb6a4-6f30-4f3c-8b50-0bad0e8b6c75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Complete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5931a6-4d94-44df-8c1a-82076732f0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with just the selected column\n",
    "classes = pd.DataFrame(extra_resized['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5002378-98b0-4b70-ba29-a07ba57764f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#complete_features = pd.concat([classes,f_color,f_histogram, f_glcm], axis=1)\n",
    "complete_features = pd.concat([classes,f_histogram, f_glcm, f_color, f_legendre, f_zernike], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3453770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_features.to_csv('complete_features.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "060e531f-0a6e-455b-8dbf-07ca777d8c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>223</td>\n",
       "      <td>231</td>\n",
       "      <td>305</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>153</td>\n",
       "      <td>210</td>\n",
       "      <td>261</td>\n",
       "      <td>308</td>\n",
       "      <td>349</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>358</td>\n",
       "      <td>383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>290</td>\n",
       "      <td>337</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048771</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  red_1  red_2  red_3  red_4  red_5  red_6  red_7  \\\n",
       "0  bacterial_leaf_blight     19     47     93    143    223    231    305   \n",
       "1  bacterial_leaf_blight    153    210    261    308    349    391    392   \n",
       "2  bacterial_leaf_blight     14     35     62    145    205    290    337   \n",
       "3  bacterial_leaf_blight     14     14     40     53     89    106    194   \n",
       "4  bacterial_leaf_blight      0      1      3      4      1      6      6   \n",
       "\n",
       "   red_8  red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0    314    330  ...    0.021457    0.009277    0.024865    0.004817   \n",
       "1    358    383  ...    0.019798    0.021939    0.024250    0.033492   \n",
       "2    325    338  ...    0.028761    0.049967    0.039179    0.039791   \n",
       "3    242    267  ...    0.017136    0.012084    0.020084    0.021049   \n",
       "4      9      8  ...    0.025135    0.003060    0.024900    0.048771   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.017575    0.003713    0.003742    0.016868    0.031700    0.035992  \n",
       "1    0.027907    0.000967    0.009835    0.017213    0.006593    0.008411  \n",
       "2    0.023068    0.031944    0.021562    0.009072    0.019779    0.024128  \n",
       "3    0.013913    0.004487    0.017935    0.029116    0.023423    0.023256  \n",
       "4    0.041041    0.005773    0.034733    0.012531    0.014290    0.004188  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5fb4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_features = complete_features.iloc[:, [0] + list(range(752, 787))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93653fd4-c7c1-4763-ab89-2102d2f29c4c",
   "metadata": {},
   "source": [
    "# Data Normalization and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80096471-c274-4870-bea1-05b14edc651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe(df):\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Extract numerical columns (only numerical columns need normalization)\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply normalization to each numerical column\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b235b92a-228e-4021-975a-b860cafec988",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11540\\3205247050.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_variance</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.502370</td>\n",
       "      <td>0.299143</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.632941</td>\n",
       "      <td>0.572798</td>\n",
       "      <td>0.376351</td>\n",
       "      <td>0.031551</td>\n",
       "      <td>0.583184</td>\n",
       "      <td>0.244273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336935</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.577796</td>\n",
       "      <td>0.361295</td>\n",
       "      <td>0.126468</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>0.629981</td>\n",
       "      <td>0.746523</td>\n",
       "      <td>0.179498</td>\n",
       "      <td>0.061120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.490106</td>\n",
       "      <td>0.388549</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.622172</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>0.388565</td>\n",
       "      <td>0.021879</td>\n",
       "      <td>0.589852</td>\n",
       "      <td>0.168911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358429</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.586108</td>\n",
       "      <td>0.313810</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.149124</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.834971</td>\n",
       "      <td>0.174121</td>\n",
       "      <td>0.070484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.033110</td>\n",
       "      <td>0.580656</td>\n",
       "      <td>0.602786</td>\n",
       "      <td>0.329572</td>\n",
       "      <td>0.044848</td>\n",
       "      <td>0.537098</td>\n",
       "      <td>0.242125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296867</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.527598</td>\n",
       "      <td>0.360167</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>0.098401</td>\n",
       "      <td>0.659350</td>\n",
       "      <td>0.787102</td>\n",
       "      <td>0.177374</td>\n",
       "      <td>0.076225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.501087</td>\n",
       "      <td>0.306493</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.652975</td>\n",
       "      <td>0.566068</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.609388</td>\n",
       "      <td>0.438271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>0.606846</td>\n",
       "      <td>0.440341</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.139092</td>\n",
       "      <td>0.616796</td>\n",
       "      <td>0.497782</td>\n",
       "      <td>0.045744</td>\n",
       "      <td>0.119308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0.182779</td>\n",
       "      <td>0.023982</td>\n",
       "      <td>0.670335</td>\n",
       "      <td>0.608115</td>\n",
       "      <td>0.213078</td>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.612956</td>\n",
       "      <td>0.150213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176747</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>0.618686</td>\n",
       "      <td>0.279737</td>\n",
       "      <td>0.160906</td>\n",
       "      <td>0.081239</td>\n",
       "      <td>0.657293</td>\n",
       "      <td>0.869149</td>\n",
       "      <td>0.167625</td>\n",
       "      <td>0.069393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  rgb_channel_0_mean  rgb_channel_0_variance  \\\n",
       "0  bacterial_leaf_blight            0.502370                0.299143   \n",
       "1  bacterial_leaf_blight            0.490106                0.388549   \n",
       "2  bacterial_leaf_blight            0.537975                0.259259   \n",
       "3  bacterial_leaf_blight            0.501087                0.306493   \n",
       "4  bacterial_leaf_blight            0.497495                0.182779   \n",
       "\n",
       "   rgb_channel_0_kurtosis  rgb_channel_0_skewness  rgb_channel_1_mean  \\\n",
       "0                0.022317                0.632941            0.572798   \n",
       "1                0.013933                0.622172            0.577376   \n",
       "2                0.033110                0.580656            0.602786   \n",
       "3                0.021116                0.652975            0.566068   \n",
       "4                0.023982                0.670335            0.608115   \n",
       "\n",
       "   rgb_channel_1_variance  rgb_channel_1_kurtosis  rgb_channel_1_skewness  \\\n",
       "0                0.376351                0.031551                0.583184   \n",
       "1                0.388565                0.021879                0.589852   \n",
       "2                0.329572                0.044848                0.537098   \n",
       "3                0.318627                0.026923                0.609388   \n",
       "4                0.213078                0.027692                0.612956   \n",
       "\n",
       "   rgb_channel_2_mean  ...  lab_channel_0_variance  lab_channel_0_kurtosis  \\\n",
       "0            0.244273  ...                0.336935                0.037914   \n",
       "1            0.168911  ...                0.358429                0.026249   \n",
       "2            0.242125  ...                0.296867                0.054527   \n",
       "3            0.438271  ...                0.294621                0.031255   \n",
       "4            0.150213  ...                0.176747                0.031417   \n",
       "\n",
       "   lab_channel_0_skewness  lab_channel_1_mean  lab_channel_1_variance  \\\n",
       "0                0.577796            0.361295                0.126468   \n",
       "1                0.586108            0.313810                0.043988   \n",
       "2                0.527598            0.360167                0.081116   \n",
       "3                0.606846            0.440341                0.054435   \n",
       "4                0.618686            0.279737                0.160906   \n",
       "\n",
       "   lab_channel_1_kurtosis  lab_channel_1_skewness  lab_channel_2_mean  \\\n",
       "0                0.073599                0.629981            0.746523   \n",
       "1                0.149124                0.675100            0.834971   \n",
       "2                0.098401                0.659350            0.787102   \n",
       "3                0.139092                0.616796            0.497782   \n",
       "4                0.081239                0.657293            0.869149   \n",
       "\n",
       "   lab_channel_2_variance  lab_channel_2_kurtosis  \n",
       "0                0.179498                0.061120  \n",
       "1                0.174121                0.070484  \n",
       "2                0.177374                0.076225  \n",
       "3                0.045744                0.119308  \n",
       "4                0.167625                0.069393  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features = normalize_dataframe(cm_features)\n",
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b339da2-35a0-455d-8db7-266f056dd5ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11540\\1409264267.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normalized_features['class'] = label_encoder.fit_transform(normalized_features['class'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_features['class'] = label_encoder.fit_transform(normalized_features['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "097defd8-e917-45e2-a877-dfe178bfe066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_variance</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.502370</td>\n",
       "      <td>0.299143</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.632941</td>\n",
       "      <td>0.572798</td>\n",
       "      <td>0.376351</td>\n",
       "      <td>0.031551</td>\n",
       "      <td>0.583184</td>\n",
       "      <td>0.244273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336935</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.577796</td>\n",
       "      <td>0.361295</td>\n",
       "      <td>0.126468</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>0.629981</td>\n",
       "      <td>0.746523</td>\n",
       "      <td>0.179498</td>\n",
       "      <td>0.061120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490106</td>\n",
       "      <td>0.388549</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.622172</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>0.388565</td>\n",
       "      <td>0.021879</td>\n",
       "      <td>0.589852</td>\n",
       "      <td>0.168911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358429</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.586108</td>\n",
       "      <td>0.313810</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.149124</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.834971</td>\n",
       "      <td>0.174121</td>\n",
       "      <td>0.070484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.033110</td>\n",
       "      <td>0.580656</td>\n",
       "      <td>0.602786</td>\n",
       "      <td>0.329572</td>\n",
       "      <td>0.044848</td>\n",
       "      <td>0.537098</td>\n",
       "      <td>0.242125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296867</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.527598</td>\n",
       "      <td>0.360167</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>0.098401</td>\n",
       "      <td>0.659350</td>\n",
       "      <td>0.787102</td>\n",
       "      <td>0.177374</td>\n",
       "      <td>0.076225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.501087</td>\n",
       "      <td>0.306493</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.652975</td>\n",
       "      <td>0.566068</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.609388</td>\n",
       "      <td>0.438271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>0.606846</td>\n",
       "      <td>0.440341</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.139092</td>\n",
       "      <td>0.616796</td>\n",
       "      <td>0.497782</td>\n",
       "      <td>0.045744</td>\n",
       "      <td>0.119308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0.182779</td>\n",
       "      <td>0.023982</td>\n",
       "      <td>0.670335</td>\n",
       "      <td>0.608115</td>\n",
       "      <td>0.213078</td>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.612956</td>\n",
       "      <td>0.150213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176747</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>0.618686</td>\n",
       "      <td>0.279737</td>\n",
       "      <td>0.160906</td>\n",
       "      <td>0.081239</td>\n",
       "      <td>0.657293</td>\n",
       "      <td>0.869149</td>\n",
       "      <td>0.167625</td>\n",
       "      <td>0.069393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  rgb_channel_0_mean  rgb_channel_0_variance  rgb_channel_0_kurtosis  \\\n",
       "0      0            0.502370                0.299143                0.022317   \n",
       "1      0            0.490106                0.388549                0.013933   \n",
       "2      0            0.537975                0.259259                0.033110   \n",
       "3      0            0.501087                0.306493                0.021116   \n",
       "4      0            0.497495                0.182779                0.023982   \n",
       "\n",
       "   rgb_channel_0_skewness  rgb_channel_1_mean  rgb_channel_1_variance  \\\n",
       "0                0.632941            0.572798                0.376351   \n",
       "1                0.622172            0.577376                0.388565   \n",
       "2                0.580656            0.602786                0.329572   \n",
       "3                0.652975            0.566068                0.318627   \n",
       "4                0.670335            0.608115                0.213078   \n",
       "\n",
       "   rgb_channel_1_kurtosis  rgb_channel_1_skewness  rgb_channel_2_mean  ...  \\\n",
       "0                0.031551                0.583184            0.244273  ...   \n",
       "1                0.021879                0.589852            0.168911  ...   \n",
       "2                0.044848                0.537098            0.242125  ...   \n",
       "3                0.026923                0.609388            0.438271  ...   \n",
       "4                0.027692                0.612956            0.150213  ...   \n",
       "\n",
       "   lab_channel_0_variance  lab_channel_0_kurtosis  lab_channel_0_skewness  \\\n",
       "0                0.336935                0.037914                0.577796   \n",
       "1                0.358429                0.026249                0.586108   \n",
       "2                0.296867                0.054527                0.527598   \n",
       "3                0.294621                0.031255                0.606846   \n",
       "4                0.176747                0.031417                0.618686   \n",
       "\n",
       "   lab_channel_1_mean  lab_channel_1_variance  lab_channel_1_kurtosis  \\\n",
       "0            0.361295                0.126468                0.073599   \n",
       "1            0.313810                0.043988                0.149124   \n",
       "2            0.360167                0.081116                0.098401   \n",
       "3            0.440341                0.054435                0.139092   \n",
       "4            0.279737                0.160906                0.081239   \n",
       "\n",
       "   lab_channel_1_skewness  lab_channel_2_mean  lab_channel_2_variance  \\\n",
       "0                0.629981            0.746523                0.179498   \n",
       "1                0.675100            0.834971                0.174121   \n",
       "2                0.659350            0.787102                0.177374   \n",
       "3                0.616796            0.497782                0.045744   \n",
       "4                0.657293            0.869149                0.167625   \n",
       "\n",
       "   lab_channel_2_kurtosis  \n",
       "0                0.061120  \n",
       "1                0.070484  \n",
       "2                0.076225  \n",
       "3                0.119308  \n",
       "4                0.069393  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77638c94-04af-43fb-a1db-0548a9c497cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acc8851d-dc36-4634-8d2f-8a3016c14ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def custom_train_test_split(dataframe, target_column, test_size=0.2, random_state=None):\n",
    "    # Separate features and labels\n",
    "    X = dataframe.drop(target_column, axis=1)  # Features\n",
    "    y = dataframe[target_column]  # Labels\n",
    "\n",
    "    # Perform the train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53594f6d-e920-4b66-91d8-7ba1ad60e4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = custom_train_test_split(normalized_features, 'class', test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "165bd148-e43b-401d-94a1-24f08ca4ef46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features (all columns except the first)\n",
    "x_d = normalized_features.iloc[:, 1:].values\n",
    "\n",
    "# Extract target variable (first column)\n",
    "y_d = normalized_features.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b4890-0ac4-4c6d-b3c1-9acf0c770916",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "705fec05-d73e-470c-9a2b-d71b16d96f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "33/33 [==============================] - 2s 12ms/step - loss: 2.5140 - accuracy: 0.1689 - val_loss: 2.4083 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2040 - accuracy: 0.3626 - val_loss: 2.2414 - val_accuracy: 0.3929\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.9611 - accuracy: 0.4532 - val_loss: 2.0443 - val_accuracy: 0.4107\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.7311 - accuracy: 0.5029 - val_loss: 1.8492 - val_accuracy: 0.4286\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5473 - accuracy: 0.5296 - val_loss: 1.7219 - val_accuracy: 0.4286\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4109 - accuracy: 0.5658 - val_loss: 1.6069 - val_accuracy: 0.4821\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3087 - accuracy: 0.5964 - val_loss: 1.5400 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2328 - accuracy: 0.6202 - val_loss: 1.4691 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1702 - accuracy: 0.6403 - val_loss: 1.4314 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1198 - accuracy: 0.6479 - val_loss: 1.3975 - val_accuracy: 0.5893\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.6737 - val_loss: 1.3725 - val_accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.6775 - val_loss: 1.3310 - val_accuracy: 0.5893\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9971 - accuracy: 0.6880 - val_loss: 1.3157 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9636 - accuracy: 0.6927 - val_loss: 1.2886 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9316 - accuracy: 0.7013 - val_loss: 1.2638 - val_accuracy: 0.6071\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9045 - accuracy: 0.7090 - val_loss: 1.2389 - val_accuracy: 0.5893\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8815 - accuracy: 0.7176 - val_loss: 1.2208 - val_accuracy: 0.6071\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8562 - accuracy: 0.7261 - val_loss: 1.1956 - val_accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8312 - accuracy: 0.7376 - val_loss: 1.1989 - val_accuracy: 0.6071\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.7405 - val_loss: 1.1613 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.7424 - val_loss: 1.1625 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7725 - accuracy: 0.7538 - val_loss: 1.1403 - val_accuracy: 0.6071\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.7643 - val_loss: 1.1295 - val_accuracy: 0.6071\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.7586 - val_loss: 1.0909 - val_accuracy: 0.6607\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7202 - accuracy: 0.7729 - val_loss: 1.1172 - val_accuracy: 0.6250\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.7729 - val_loss: 1.0841 - val_accuracy: 0.6071\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.7796 - val_loss: 1.0776 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7968 - val_loss: 1.0380 - val_accuracy: 0.6071\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.7968 - val_loss: 1.0439 - val_accuracy: 0.6429\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7987 - val_loss: 1.0352 - val_accuracy: 0.6250\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7948 - val_loss: 1.0267 - val_accuracy: 0.6607\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.8082 - val_loss: 1.0292 - val_accuracy: 0.6607\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.8063 - val_loss: 0.9994 - val_accuracy: 0.6786\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.8168 - val_loss: 0.9994 - val_accuracy: 0.6607\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.8139 - val_loss: 0.9712 - val_accuracy: 0.6786\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8187 - val_loss: 0.9927 - val_accuracy: 0.6786\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8302 - val_loss: 0.9766 - val_accuracy: 0.6786\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8216 - val_loss: 0.9534 - val_accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8282 - val_loss: 0.9439 - val_accuracy: 0.6964\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.8397 - val_loss: 0.9432 - val_accuracy: 0.6786\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.8387 - val_loss: 0.9369 - val_accuracy: 0.6786\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.8416 - val_loss: 0.9230 - val_accuracy: 0.6786\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.8454 - val_loss: 0.9336 - val_accuracy: 0.6964\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8445 - val_loss: 0.9427 - val_accuracy: 0.6964\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8464 - val_loss: 0.9168 - val_accuracy: 0.6964\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8559 - val_loss: 0.8901 - val_accuracy: 0.6964\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8559 - val_loss: 0.9106 - val_accuracy: 0.6964\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8635 - val_loss: 0.8945 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8702 - val_loss: 0.8906 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.8702 - val_loss: 0.8704 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8616 - val_loss: 0.8693 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8702 - val_loss: 0.8762 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8731 - val_loss: 0.8663 - val_accuracy: 0.7143\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8779 - val_loss: 0.8675 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8798 - val_loss: 0.8694 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8826 - val_loss: 0.8688 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8817 - val_loss: 0.8469 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8836 - val_loss: 0.8487 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8874 - val_loss: 0.8379 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8884 - val_loss: 0.8545 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8931 - val_loss: 0.8414 - val_accuracy: 0.7679\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8950 - val_loss: 0.8410 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8989 - val_loss: 0.8261 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8950 - val_loss: 0.8500 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8998 - val_loss: 0.8396 - val_accuracy: 0.7679\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.9065 - val_loss: 0.8677 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.9055 - val_loss: 0.8365 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.9094 - val_loss: 0.8404 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.9065 - val_loss: 0.8467 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.9132 - val_loss: 0.8379 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.9160 - val_loss: 0.8392 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.9122 - val_loss: 0.8239 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.9151 - val_loss: 0.8174 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.9198 - val_loss: 0.8324 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.9132 - val_loss: 0.8277 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.9208 - val_loss: 0.8215 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.9218 - val_loss: 0.8474 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.9265 - val_loss: 0.8089 - val_accuracy: 0.7679\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9294 - val_loss: 0.8332 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.9275 - val_loss: 0.8341 - val_accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9294 - val_loss: 0.8211 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9294 - val_loss: 0.8181 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9294 - val_loss: 0.8163 - val_accuracy: 0.7679\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.9313 - val_loss: 0.8625 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9303 - val_loss: 0.8307 - val_accuracy: 0.7679\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9332 - val_loss: 0.8288 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9361 - val_loss: 0.8505 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9361 - val_loss: 0.8523 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9370 - val_loss: 0.8451 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9399 - val_loss: 0.8388 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9456 - val_loss: 0.8596 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9332 - val_loss: 0.8670 - val_accuracy: 0.8036\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9389 - val_loss: 0.8594 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9389 - val_loss: 0.8579 - val_accuracy: 0.8036\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9418 - val_loss: 0.8584 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9456 - val_loss: 0.8441 - val_accuracy: 0.8036\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9466 - val_loss: 0.8690 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9475 - val_loss: 0.8585 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9475 - val_loss: 0.8591 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9504 - val_loss: 0.8619 - val_accuracy: 0.7857\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8436 - accuracy: 0.7826\n",
      "\n",
      "Test accuracy: 0.782608687877655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data in x_d and y_d\n",
    "X = x_d\n",
    "y = y_d\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c715fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(X_test_scaled)\n",
    "# predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "# np.savetxt('test_predictions.csv', np.hstack((predicted_labels.reshape(-1, 1), y_test.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "# # np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157b35a",
   "metadata": {},
   "source": [
    "## Feature Selection PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9f8a956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 0.99\n",
      "(1380, 19)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.5704 - accuracy: 0.1460 - val_loss: 2.3927 - val_accuracy: 0.2321\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2282 - accuracy: 0.3387 - val_loss: 2.2064 - val_accuracy: 0.3036\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0018 - accuracy: 0.4284 - val_loss: 2.0353 - val_accuracy: 0.4286\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.7922 - accuracy: 0.4838 - val_loss: 1.8595 - val_accuracy: 0.4286\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6137 - accuracy: 0.5076 - val_loss: 1.7191 - val_accuracy: 0.4464\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4772 - accuracy: 0.5477 - val_loss: 1.6363 - val_accuracy: 0.4821\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3748 - accuracy: 0.5706 - val_loss: 1.5758 - val_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2970 - accuracy: 0.5849 - val_loss: 1.5362 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2370 - accuracy: 0.6021 - val_loss: 1.4787 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1827 - accuracy: 0.6183 - val_loss: 1.4639 - val_accuracy: 0.4821\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1394 - accuracy: 0.6365 - val_loss: 1.4274 - val_accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0906 - accuracy: 0.6489 - val_loss: 1.3767 - val_accuracy: 0.5893\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.6584 - val_loss: 1.3594 - val_accuracy: 0.5536\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.6803 - val_loss: 1.3319 - val_accuracy: 0.5536\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9768 - accuracy: 0.6937 - val_loss: 1.3198 - val_accuracy: 0.5893\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9442 - accuracy: 0.6975 - val_loss: 1.2910 - val_accuracy: 0.5357\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9165 - accuracy: 0.7071 - val_loss: 1.2862 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8880 - accuracy: 0.7156 - val_loss: 1.2441 - val_accuracy: 0.5893\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8683 - accuracy: 0.7261 - val_loss: 1.2319 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.7338 - val_loss: 1.2278 - val_accuracy: 0.5893\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8214 - accuracy: 0.7405 - val_loss: 1.1982 - val_accuracy: 0.6071\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8020 - accuracy: 0.7452 - val_loss: 1.2198 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7818 - accuracy: 0.7481 - val_loss: 1.1815 - val_accuracy: 0.5893\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7691 - accuracy: 0.7452 - val_loss: 1.1878 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7615 - val_loss: 1.1691 - val_accuracy: 0.6071\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.7634 - val_loss: 1.1456 - val_accuracy: 0.5893\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.7634 - val_loss: 1.1569 - val_accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.7691 - val_loss: 1.1265 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.7767 - val_loss: 1.1187 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.7815 - val_loss: 1.1185 - val_accuracy: 0.5893\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.7796 - val_loss: 1.1112 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7910 - val_loss: 1.1138 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7920 - val_loss: 1.1053 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7968 - val_loss: 1.1105 - val_accuracy: 0.6071\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7987 - val_loss: 1.0774 - val_accuracy: 0.6071\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.8044 - val_loss: 1.0895 - val_accuracy: 0.6071\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.8101 - val_loss: 1.0684 - val_accuracy: 0.6071\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.8130 - val_loss: 1.0669 - val_accuracy: 0.6071\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.8120 - val_loss: 1.0668 - val_accuracy: 0.6071\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8139 - val_loss: 1.0578 - val_accuracy: 0.6429\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.8225 - val_loss: 1.0631 - val_accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.8168 - val_loss: 1.0633 - val_accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8263 - val_loss: 1.0314 - val_accuracy: 0.6071\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.8292 - val_loss: 1.0240 - val_accuracy: 0.6071\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8330 - val_loss: 1.0187 - val_accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.8435 - val_loss: 1.0076 - val_accuracy: 0.6607\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8349 - val_loss: 1.0256 - val_accuracy: 0.6250\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8378 - val_loss: 1.0173 - val_accuracy: 0.6429\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.8492 - val_loss: 0.9952 - val_accuracy: 0.6071\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.8464 - val_loss: 0.9843 - val_accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8531 - val_loss: 1.0173 - val_accuracy: 0.6250\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8559 - val_loss: 0.9792 - val_accuracy: 0.6250\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8511 - val_loss: 0.9816 - val_accuracy: 0.6429\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8655 - val_loss: 0.9662 - val_accuracy: 0.6429\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8626 - val_loss: 0.9635 - val_accuracy: 0.6429\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8626 - val_loss: 0.9667 - val_accuracy: 0.6607\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8712 - val_loss: 0.9497 - val_accuracy: 0.6786\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8674 - val_loss: 0.9602 - val_accuracy: 0.6786\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8760 - val_loss: 0.9582 - val_accuracy: 0.6607\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8731 - val_loss: 0.9407 - val_accuracy: 0.6607\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8798 - val_loss: 0.9305 - val_accuracy: 0.6607\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8798 - val_loss: 0.9278 - val_accuracy: 0.7143\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8855 - val_loss: 0.9593 - val_accuracy: 0.6964\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8807 - val_loss: 0.9112 - val_accuracy: 0.6786\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8893 - val_loss: 0.9341 - val_accuracy: 0.7143\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8855 - val_loss: 0.9366 - val_accuracy: 0.6964\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8865 - val_loss: 0.9093 - val_accuracy: 0.6964\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8903 - val_loss: 0.9118 - val_accuracy: 0.6607\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8836 - val_loss: 0.9082 - val_accuracy: 0.6786\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8931 - val_loss: 0.9070 - val_accuracy: 0.7143\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8950 - val_loss: 0.9210 - val_accuracy: 0.6964\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.9008 - val_loss: 0.9183 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.9008 - val_loss: 0.9128 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8989 - val_loss: 0.8853 - val_accuracy: 0.7143\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9055 - val_loss: 0.8932 - val_accuracy: 0.7143\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.9065 - val_loss: 0.8938 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.9065 - val_loss: 0.8996 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.9084 - val_loss: 0.8921 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.9094 - val_loss: 0.8865 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.9151 - val_loss: 0.8898 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9160 - val_loss: 0.8949 - val_accuracy: 0.6964\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.9103 - val_loss: 0.8856 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.9160 - val_loss: 0.8886 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.9132 - val_loss: 0.8816 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9198 - val_loss: 0.8561 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9227 - val_loss: 0.8663 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.9160 - val_loss: 0.8715 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.9170 - val_loss: 0.8719 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.9198 - val_loss: 0.8667 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9284 - val_loss: 0.8783 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.9275 - val_loss: 0.8703 - val_accuracy: 0.7679\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9208 - val_loss: 0.8650 - val_accuracy: 0.7679\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9265 - val_loss: 0.8582 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9294 - val_loss: 0.8403 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9256 - val_loss: 0.8669 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.9323 - val_loss: 0.8411 - val_accuracy: 0.8036\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9351 - val_loss: 0.8341 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9284 - val_loss: 0.8354 - val_accuracy: 0.7679\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.9284 - val_loss: 0.8345 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9408 - val_loss: 0.8233 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9813 - accuracy: 0.7935\n",
      "\n",
      "Test accuracy: 0.79347825050354\n",
      "var: 0.991\n",
      "(1380, 19)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 2.5470 - accuracy: 0.1374 - val_loss: 2.4300 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2308 - accuracy: 0.2929 - val_loss: 2.2374 - val_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.9782 - accuracy: 0.4351 - val_loss: 2.0544 - val_accuracy: 0.3929\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.7399 - accuracy: 0.4952 - val_loss: 1.8733 - val_accuracy: 0.3929\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5435 - accuracy: 0.5315 - val_loss: 1.7446 - val_accuracy: 0.3929\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4056 - accuracy: 0.5573 - val_loss: 1.6466 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3096 - accuracy: 0.5725 - val_loss: 1.5807 - val_accuracy: 0.4464\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2358 - accuracy: 0.6011 - val_loss: 1.5196 - val_accuracy: 0.4821\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1780 - accuracy: 0.6097 - val_loss: 1.4836 - val_accuracy: 0.4821\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1271 - accuracy: 0.6250 - val_loss: 1.4403 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0847 - accuracy: 0.6374 - val_loss: 1.4044 - val_accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0499 - accuracy: 0.6498 - val_loss: 1.3699 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0172 - accuracy: 0.6670 - val_loss: 1.3269 - val_accuracy: 0.5536\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9901 - accuracy: 0.6727 - val_loss: 1.3029 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9565 - accuracy: 0.6937 - val_loss: 1.2728 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9309 - accuracy: 0.6985 - val_loss: 1.2499 - val_accuracy: 0.5536\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9016 - accuracy: 0.7118 - val_loss: 1.2201 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.7223 - val_loss: 1.1989 - val_accuracy: 0.6071\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8539 - accuracy: 0.7252 - val_loss: 1.1764 - val_accuracy: 0.6071\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8299 - accuracy: 0.7424 - val_loss: 1.1628 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8123 - accuracy: 0.7405 - val_loss: 1.1580 - val_accuracy: 0.6429\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.7490 - val_loss: 1.1391 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7727 - accuracy: 0.7548 - val_loss: 1.1205 - val_accuracy: 0.6786\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.7624 - val_loss: 1.0970 - val_accuracy: 0.6607\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.7681 - val_loss: 1.0906 - val_accuracy: 0.6786\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.7691 - val_loss: 1.0843 - val_accuracy: 0.6786\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.7615 - val_loss: 1.0596 - val_accuracy: 0.6964\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.7834 - val_loss: 1.0757 - val_accuracy: 0.6607\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.7853 - val_loss: 1.0316 - val_accuracy: 0.6786\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.7882 - val_loss: 1.0411 - val_accuracy: 0.6964\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7939 - val_loss: 1.0293 - val_accuracy: 0.6786\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7996 - val_loss: 1.0194 - val_accuracy: 0.7143\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.8092 - val_loss: 1.0141 - val_accuracy: 0.7143\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.8015 - val_loss: 0.9829 - val_accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.8092 - val_loss: 0.9808 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.8034 - val_loss: 0.9959 - val_accuracy: 0.6964\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.8225 - val_loss: 1.0135 - val_accuracy: 0.6964\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.8225 - val_loss: 0.9976 - val_accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.8197 - val_loss: 0.9666 - val_accuracy: 0.6964\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8235 - val_loss: 0.9712 - val_accuracy: 0.7321\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.8311 - val_loss: 0.9638 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8349 - val_loss: 0.9583 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8311 - val_loss: 0.9718 - val_accuracy: 0.7143\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8378 - val_loss: 0.9368 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8435 - val_loss: 0.9566 - val_accuracy: 0.6964\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.8435 - val_loss: 0.9412 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8483 - val_loss: 0.9403 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8511 - val_loss: 0.9448 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.8492 - val_loss: 0.9413 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8531 - val_loss: 0.9351 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8588 - val_loss: 0.9271 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8588 - val_loss: 0.9426 - val_accuracy: 0.7679\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8588 - val_loss: 0.9116 - val_accuracy: 0.7321\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8607 - val_loss: 0.9359 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8664 - val_loss: 0.9319 - val_accuracy: 0.7321\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8702 - val_loss: 0.9283 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8712 - val_loss: 0.9112 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8779 - val_loss: 0.9133 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8769 - val_loss: 0.9153 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8836 - val_loss: 0.9273 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8750 - val_loss: 0.9072 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8817 - val_loss: 0.9252 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8855 - val_loss: 0.9025 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8941 - val_loss: 0.9122 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8931 - val_loss: 0.9149 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8989 - val_loss: 0.9284 - val_accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8922 - val_loss: 0.9182 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.9055 - val_loss: 0.9280 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.9008 - val_loss: 0.9119 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.9074 - val_loss: 0.9247 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.9132 - val_loss: 0.9070 - val_accuracy: 0.7679\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.9151 - val_loss: 0.9127 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.9160 - val_loss: 0.9277 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.9113 - val_loss: 0.9076 - val_accuracy: 0.7679\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.9189 - val_loss: 0.9353 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.9179 - val_loss: 0.9153 - val_accuracy: 0.7679\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.9170 - val_loss: 0.9192 - val_accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.9170 - val_loss: 0.9157 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.9265 - val_loss: 0.9253 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.9256 - val_loss: 0.9228 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.9323 - val_loss: 0.9210 - val_accuracy: 0.7679\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.9303 - val_loss: 0.9250 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.9342 - val_loss: 0.9273 - val_accuracy: 0.7679\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.9361 - val_loss: 0.9103 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9351 - val_loss: 0.9407 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9361 - val_loss: 0.9331 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9332 - val_loss: 0.9472 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9370 - val_loss: 0.9336 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9389 - val_loss: 0.9218 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.9427 - val_loss: 0.9481 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9380 - val_loss: 0.9485 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9361 - val_loss: 0.9295 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9456 - val_loss: 0.9435 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9437 - val_loss: 0.9603 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.9370 - val_loss: 0.9551 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9466 - val_loss: 0.9552 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9437 - val_loss: 0.9448 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9504 - val_loss: 0.9628 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9494 - val_loss: 0.9537 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9485 - val_loss: 0.9419 - val_accuracy: 0.7500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0041 - accuracy: 0.7971\n",
      "\n",
      "Test accuracy: 0.7971014380455017\n",
      "var: 0.992\n",
      "(1380, 20)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.5297 - accuracy: 0.1174 - val_loss: 2.4345 - val_accuracy: 0.1607\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2559 - accuracy: 0.3044 - val_loss: 2.2915 - val_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0513 - accuracy: 0.4208 - val_loss: 2.1212 - val_accuracy: 0.3393\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8391 - accuracy: 0.4523 - val_loss: 1.9568 - val_accuracy: 0.3214\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6452 - accuracy: 0.4933 - val_loss: 1.8112 - val_accuracy: 0.3571\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4986 - accuracy: 0.5372 - val_loss: 1.7109 - val_accuracy: 0.4286\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3841 - accuracy: 0.5840 - val_loss: 1.6173 - val_accuracy: 0.4643\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2946 - accuracy: 0.6116 - val_loss: 1.5676 - val_accuracy: 0.5179\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2233 - accuracy: 0.6250 - val_loss: 1.5049 - val_accuracy: 0.5179\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1627 - accuracy: 0.6403 - val_loss: 1.4466 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1075 - accuracy: 0.6574 - val_loss: 1.4146 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0635 - accuracy: 0.6679 - val_loss: 1.3701 - val_accuracy: 0.6071\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0207 - accuracy: 0.6851 - val_loss: 1.3207 - val_accuracy: 0.6071\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9796 - accuracy: 0.6899 - val_loss: 1.3018 - val_accuracy: 0.6071\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9426 - accuracy: 0.7080 - val_loss: 1.2634 - val_accuracy: 0.6071\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9122 - accuracy: 0.7128 - val_loss: 1.2425 - val_accuracy: 0.5893\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8880 - accuracy: 0.7195 - val_loss: 1.2155 - val_accuracy: 0.6071\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8584 - accuracy: 0.7300 - val_loss: 1.1995 - val_accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.7309 - val_loss: 1.2068 - val_accuracy: 0.5893\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8111 - accuracy: 0.7366 - val_loss: 1.1636 - val_accuracy: 0.6071\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7853 - accuracy: 0.7481 - val_loss: 1.1584 - val_accuracy: 0.6429\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.7634 - val_loss: 1.1456 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.7691 - val_loss: 1.1080 - val_accuracy: 0.6429\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.7643 - val_loss: 1.1018 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.7767 - val_loss: 1.0869 - val_accuracy: 0.6607\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.7844 - val_loss: 1.0784 - val_accuracy: 0.6429\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7910 - val_loss: 1.0754 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.7910 - val_loss: 1.0476 - val_accuracy: 0.6429\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7948 - val_loss: 1.0433 - val_accuracy: 0.6607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7987 - val_loss: 1.0195 - val_accuracy: 0.6607\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.8025 - val_loss: 1.0090 - val_accuracy: 0.6786\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.8092 - val_loss: 0.9879 - val_accuracy: 0.6607\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.8073 - val_loss: 0.9697 - val_accuracy: 0.6964\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.8111 - val_loss: 0.9606 - val_accuracy: 0.6786\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8187 - val_loss: 0.9393 - val_accuracy: 0.6786\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.8216 - val_loss: 0.9569 - val_accuracy: 0.6964\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.8225 - val_loss: 0.9295 - val_accuracy: 0.6964\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8292 - val_loss: 0.9148 - val_accuracy: 0.6964\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8254 - val_loss: 0.9001 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.8321 - val_loss: 0.8898 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8406 - val_loss: 0.8947 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8426 - val_loss: 0.8547 - val_accuracy: 0.6964\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8435 - val_loss: 0.8571 - val_accuracy: 0.6786\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8445 - val_loss: 0.8462 - val_accuracy: 0.6786\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8502 - val_loss: 0.8323 - val_accuracy: 0.6964\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8569 - val_loss: 0.8384 - val_accuracy: 0.6964\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8578 - val_loss: 0.8438 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8655 - val_loss: 0.8461 - val_accuracy: 0.6964\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8626 - val_loss: 0.8179 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8721 - val_loss: 0.8248 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8702 - val_loss: 0.8131 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8740 - val_loss: 0.7978 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8721 - val_loss: 0.7984 - val_accuracy: 0.6964\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8779 - val_loss: 0.7872 - val_accuracy: 0.7321\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8884 - val_loss: 0.8066 - val_accuracy: 0.7321\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8807 - val_loss: 0.7992 - val_accuracy: 0.6964\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8903 - val_loss: 0.7846 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8912 - val_loss: 0.7956 - val_accuracy: 0.6964\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8950 - val_loss: 0.7946 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8998 - val_loss: 0.7692 - val_accuracy: 0.6964\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.9065 - val_loss: 0.7659 - val_accuracy: 0.7143\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8998 - val_loss: 0.7739 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.9074 - val_loss: 0.7558 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.9141 - val_loss: 0.7683 - val_accuracy: 0.6964\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.9084 - val_loss: 0.7677 - val_accuracy: 0.7143\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.9160 - val_loss: 0.7461 - val_accuracy: 0.6964\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.9132 - val_loss: 0.7613 - val_accuracy: 0.7143\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.9084 - val_loss: 0.7468 - val_accuracy: 0.7143\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.9189 - val_loss: 0.7643 - val_accuracy: 0.7143\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9179 - val_loss: 0.7627 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9189 - val_loss: 0.7417 - val_accuracy: 0.7143\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.9189 - val_loss: 0.7620 - val_accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.9227 - val_loss: 0.7386 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9256 - val_loss: 0.7404 - val_accuracy: 0.7143\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.9265 - val_loss: 0.7518 - val_accuracy: 0.7143\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.9342 - val_loss: 0.7438 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.9265 - val_loss: 0.7339 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9313 - val_loss: 0.7228 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9323 - val_loss: 0.7277 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9361 - val_loss: 0.7355 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9380 - val_loss: 0.7269 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9342 - val_loss: 0.7317 - val_accuracy: 0.7143\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9303 - val_loss: 0.7434 - val_accuracy: 0.7143\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9408 - val_loss: 0.7292 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9399 - val_loss: 0.7379 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9389 - val_loss: 0.7305 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9399 - val_loss: 0.7263 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9447 - val_loss: 0.7265 - val_accuracy: 0.7143\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9437 - val_loss: 0.7465 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9456 - val_loss: 0.7205 - val_accuracy: 0.7143\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.9475 - val_loss: 0.7237 - val_accuracy: 0.7143\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9437 - val_loss: 0.7307 - val_accuracy: 0.7143\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1969 - accuracy: 0.9437 - val_loss: 0.7305 - val_accuracy: 0.7143\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9466 - val_loss: 0.7297 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.9494 - val_loss: 0.7685 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9475 - val_loss: 0.7314 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9504 - val_loss: 0.7338 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9504 - val_loss: 0.7465 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9485 - val_loss: 0.7370 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9532 - val_loss: 0.7498 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.8459 - accuracy: 0.7717\n",
      "\n",
      "Test accuracy: 0.77173912525177\n",
      "var: 0.993\n",
      "(1380, 20)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 2.6874 - accuracy: 0.1164 - val_loss: 2.4643 - val_accuracy: 0.1607\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3187 - accuracy: 0.2719 - val_loss: 2.2690 - val_accuracy: 0.3036\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0578 - accuracy: 0.4523 - val_loss: 2.0847 - val_accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.8181 - accuracy: 0.5048 - val_loss: 1.9173 - val_accuracy: 0.4107\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6294 - accuracy: 0.5286 - val_loss: 1.7926 - val_accuracy: 0.4464\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4902 - accuracy: 0.5496 - val_loss: 1.7056 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3784 - accuracy: 0.5811 - val_loss: 1.6324 - val_accuracy: 0.4286\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2908 - accuracy: 0.6088 - val_loss: 1.5586 - val_accuracy: 0.4107\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.2158 - accuracy: 0.6116 - val_loss: 1.5238 - val_accuracy: 0.4286\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.1581 - accuracy: 0.6193 - val_loss: 1.4474 - val_accuracy: 0.4643\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1048 - accuracy: 0.6584 - val_loss: 1.4079 - val_accuracy: 0.4464\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0581 - accuracy: 0.6536 - val_loss: 1.3814 - val_accuracy: 0.4821\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0177 - accuracy: 0.6765 - val_loss: 1.3390 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9832 - accuracy: 0.6861 - val_loss: 1.3223 - val_accuracy: 0.5179\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9532 - accuracy: 0.6937 - val_loss: 1.2739 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.7023 - val_loss: 1.2448 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8987 - accuracy: 0.7090 - val_loss: 1.2257 - val_accuracy: 0.5536\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.7271 - val_loss: 1.2013 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.7414 - val_loss: 1.1896 - val_accuracy: 0.5536\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.7347 - val_loss: 1.1996 - val_accuracy: 0.5536\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7995 - accuracy: 0.7481 - val_loss: 1.1555 - val_accuracy: 0.5536\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7821 - accuracy: 0.7643 - val_loss: 1.1433 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.7634 - val_loss: 1.1222 - val_accuracy: 0.6071\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.7653 - val_loss: 1.1108 - val_accuracy: 0.5893\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.7710 - val_loss: 1.0981 - val_accuracy: 0.5893\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7183 - accuracy: 0.7777 - val_loss: 1.0773 - val_accuracy: 0.6071\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.7824 - val_loss: 1.0710 - val_accuracy: 0.6071\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.7758 - val_loss: 1.0534 - val_accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7891 - val_loss: 1.0403 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.7948 - val_loss: 1.0065 - val_accuracy: 0.6071\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.8053 - val_loss: 1.0095 - val_accuracy: 0.6429\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.8053 - val_loss: 1.0045 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.8044 - val_loss: 0.9430 - val_accuracy: 0.6429\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.8111 - val_loss: 0.9501 - val_accuracy: 0.6429\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8139 - val_loss: 0.9454 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.8177 - val_loss: 0.9382 - val_accuracy: 0.6250\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.8244 - val_loss: 0.9042 - val_accuracy: 0.6964\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.8263 - val_loss: 0.9069 - val_accuracy: 0.6429\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.8282 - val_loss: 0.9012 - val_accuracy: 0.6250\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.8445 - val_loss: 0.8767 - val_accuracy: 0.6607\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.8368 - val_loss: 0.8606 - val_accuracy: 0.6607\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.8406 - val_loss: 0.8706 - val_accuracy: 0.6786\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.8483 - val_loss: 0.8735 - val_accuracy: 0.6786\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.8483 - val_loss: 0.8534 - val_accuracy: 0.6964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.8483 - val_loss: 0.8174 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.8597 - val_loss: 0.8393 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.8569 - val_loss: 0.8112 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8569 - val_loss: 0.8440 - val_accuracy: 0.6964\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8607 - val_loss: 0.7990 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8531 - val_loss: 0.8039 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8655 - val_loss: 0.7958 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8597 - val_loss: 0.7860 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8607 - val_loss: 0.7996 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8702 - val_loss: 0.7824 - val_accuracy: 0.7679\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8702 - val_loss: 0.7869 - val_accuracy: 0.7679\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8750 - val_loss: 0.7647 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8798 - val_loss: 0.7702 - val_accuracy: 0.7679\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8721 - val_loss: 0.7727 - val_accuracy: 0.8214\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8750 - val_loss: 0.7719 - val_accuracy: 0.7679\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8884 - val_loss: 0.7587 - val_accuracy: 0.8036\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8788 - val_loss: 0.7437 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8826 - val_loss: 0.7691 - val_accuracy: 0.7679\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8788 - val_loss: 0.7509 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8817 - val_loss: 0.7413 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8922 - val_loss: 0.7568 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8950 - val_loss: 0.7479 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8969 - val_loss: 0.7572 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8865 - val_loss: 0.7381 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8941 - val_loss: 0.7383 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8931 - val_loss: 0.7388 - val_accuracy: 0.8036\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.9008 - val_loss: 0.7177 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.9074 - val_loss: 0.7523 - val_accuracy: 0.8036\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.9036 - val_loss: 0.7471 - val_accuracy: 0.8036\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.9046 - val_loss: 0.7667 - val_accuracy: 0.8214\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.9103 - val_loss: 0.7364 - val_accuracy: 0.8036\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.9094 - val_loss: 0.7402 - val_accuracy: 0.8036\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.9065 - val_loss: 0.7492 - val_accuracy: 0.8036\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9122 - val_loss: 0.7300 - val_accuracy: 0.8036\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.9103 - val_loss: 0.7296 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.9141 - val_loss: 0.7428 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9151 - val_loss: 0.7269 - val_accuracy: 0.8214\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.9179 - val_loss: 0.7549 - val_accuracy: 0.8036\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.9141 - val_loss: 0.7561 - val_accuracy: 0.8036\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.9170 - val_loss: 0.7590 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.9170 - val_loss: 0.7394 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.9179 - val_loss: 0.7662 - val_accuracy: 0.8393\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2606 - accuracy: 0.9198 - val_loss: 0.7448 - val_accuracy: 0.8214\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9208 - val_loss: 0.7503 - val_accuracy: 0.8036\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9198 - val_loss: 0.7293 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.9313 - val_loss: 0.7410 - val_accuracy: 0.8036\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9256 - val_loss: 0.7598 - val_accuracy: 0.8393\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9380 - val_loss: 0.7523 - val_accuracy: 0.8214\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9332 - val_loss: 0.7292 - val_accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9294 - val_loss: 0.7503 - val_accuracy: 0.8214\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9342 - val_loss: 0.7415 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9323 - val_loss: 0.7340 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9323 - val_loss: 0.7751 - val_accuracy: 0.8393\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9370 - val_loss: 0.7264 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9389 - val_loss: 0.7627 - val_accuracy: 0.8393\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9389 - val_loss: 0.7528 - val_accuracy: 0.8214\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.7717\n",
      "\n",
      "Test accuracy: 0.77173912525177\n",
      "var: 0.994\n",
      "(1380, 21)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 2.5825 - accuracy: 0.1135 - val_loss: 2.5123 - val_accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2860 - accuracy: 0.3158 - val_loss: 2.3044 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0500 - accuracy: 0.3836 - val_loss: 2.1374 - val_accuracy: 0.3571\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8421 - accuracy: 0.4914 - val_loss: 1.9687 - val_accuracy: 0.3571\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6566 - accuracy: 0.5353 - val_loss: 1.8148 - val_accuracy: 0.3929\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5082 - accuracy: 0.5677 - val_loss: 1.7005 - val_accuracy: 0.3929\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3998 - accuracy: 0.5830 - val_loss: 1.6110 - val_accuracy: 0.4107\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3100 - accuracy: 0.6021 - val_loss: 1.5330 - val_accuracy: 0.4821\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2373 - accuracy: 0.6231 - val_loss: 1.4744 - val_accuracy: 0.4821\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.1767 - accuracy: 0.6355 - val_loss: 1.4224 - val_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1195 - accuracy: 0.6450 - val_loss: 1.3888 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0699 - accuracy: 0.6594 - val_loss: 1.3584 - val_accuracy: 0.5893\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0281 - accuracy: 0.6746 - val_loss: 1.3254 - val_accuracy: 0.6071\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.6908 - val_loss: 1.2964 - val_accuracy: 0.6071\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9501 - accuracy: 0.7071 - val_loss: 1.2707 - val_accuracy: 0.6071\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9163 - accuracy: 0.7214 - val_loss: 1.2415 - val_accuracy: 0.6071\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8830 - accuracy: 0.7376 - val_loss: 1.2489 - val_accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8498 - accuracy: 0.7471 - val_loss: 1.2341 - val_accuracy: 0.6071\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.7510 - val_loss: 1.2150 - val_accuracy: 0.6071\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7974 - accuracy: 0.7605 - val_loss: 1.2047 - val_accuracy: 0.6071\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7707 - accuracy: 0.7672 - val_loss: 1.1927 - val_accuracy: 0.6071\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.7739 - val_loss: 1.1665 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.7805 - val_loss: 1.1499 - val_accuracy: 0.6250\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.7844 - val_loss: 1.1180 - val_accuracy: 0.6429\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.7844 - val_loss: 1.1272 - val_accuracy: 0.6429\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.7910 - val_loss: 1.1096 - val_accuracy: 0.6429\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.8025 - val_loss: 1.0910 - val_accuracy: 0.6429\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.8034 - val_loss: 1.0783 - val_accuracy: 0.6429\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.8149 - val_loss: 1.0580 - val_accuracy: 0.6429\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.8149 - val_loss: 1.0633 - val_accuracy: 0.6429\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.8263 - val_loss: 1.0487 - val_accuracy: 0.6429\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.8273 - val_loss: 1.0343 - val_accuracy: 0.6786\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.8282 - val_loss: 1.0389 - val_accuracy: 0.6429\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8368 - val_loss: 1.0077 - val_accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.8311 - val_loss: 1.0131 - val_accuracy: 0.6607\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8378 - val_loss: 1.0078 - val_accuracy: 0.6607\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.8483 - val_loss: 0.9960 - val_accuracy: 0.6429\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8502 - val_loss: 0.9914 - val_accuracy: 0.6607\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.8578 - val_loss: 0.9850 - val_accuracy: 0.6607\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8559 - val_loss: 0.9602 - val_accuracy: 0.6786\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8616 - val_loss: 0.9649 - val_accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8626 - val_loss: 0.9432 - val_accuracy: 0.6964\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8664 - val_loss: 0.9384 - val_accuracy: 0.6786\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8788 - val_loss: 0.9429 - val_accuracy: 0.6607\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8702 - val_loss: 0.9461 - val_accuracy: 0.6786\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8731 - val_loss: 0.9244 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8845 - val_loss: 0.9133 - val_accuracy: 0.6964\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8855 - val_loss: 0.9156 - val_accuracy: 0.6964\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8912 - val_loss: 0.9241 - val_accuracy: 0.6964\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8979 - val_loss: 0.9177 - val_accuracy: 0.6964\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8912 - val_loss: 0.9293 - val_accuracy: 0.6786\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8912 - val_loss: 0.9118 - val_accuracy: 0.6964\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8998 - val_loss: 0.8851 - val_accuracy: 0.7143\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8998 - val_loss: 0.8890 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8998 - val_loss: 0.9138 - val_accuracy: 0.6964\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.9074 - val_loss: 0.8829 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.9036 - val_loss: 0.8938 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.9055 - val_loss: 0.8856 - val_accuracy: 0.7143\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.9084 - val_loss: 0.8872 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.9027 - val_loss: 0.8876 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.9113 - val_loss: 0.8724 - val_accuracy: 0.7143\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.9122 - val_loss: 0.8705 - val_accuracy: 0.7143\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.9170 - val_loss: 0.8953 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.9141 - val_loss: 0.8784 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.9179 - val_loss: 0.8982 - val_accuracy: 0.7143\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.9189 - val_loss: 0.8516 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.9189 - val_loss: 0.8940 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.9208 - val_loss: 0.8720 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.9284 - val_loss: 0.8810 - val_accuracy: 0.7143\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.9265 - val_loss: 0.8856 - val_accuracy: 0.7143\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9303 - val_loss: 0.8851 - val_accuracy: 0.7143\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9294 - val_loss: 0.8909 - val_accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9265 - val_loss: 0.8954 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2405 - accuracy: 0.9323 - val_loss: 0.8707 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2361 - accuracy: 0.9370 - val_loss: 0.8984 - val_accuracy: 0.7143\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9323 - val_loss: 0.8908 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.9389 - val_loss: 0.9075 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9303 - val_loss: 0.9026 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9408 - val_loss: 0.9285 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9370 - val_loss: 0.8960 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9447 - val_loss: 0.9188 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9380 - val_loss: 0.9218 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9427 - val_loss: 0.9333 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.9437 - val_loss: 0.9150 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9485 - val_loss: 0.9351 - val_accuracy: 0.7143\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9475 - val_loss: 0.9279 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.9466 - val_loss: 0.9255 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9456 - val_loss: 0.9296 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9475 - val_loss: 0.9461 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9494 - val_loss: 0.9370 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1828 - accuracy: 0.9532 - val_loss: 0.9604 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9513 - val_loss: 0.9721 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9552 - val_loss: 0.9573 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9523 - val_loss: 0.9750 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9571 - val_loss: 0.9653 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9552 - val_loss: 0.9905 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9561 - val_loss: 0.9637 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9571 - val_loss: 0.9910 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9599 - val_loss: 0.9979 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9599 - val_loss: 0.9615 - val_accuracy: 0.7500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0665 - accuracy: 0.7717\n",
      "\n",
      "Test accuracy: 0.77173912525177\n",
      "var: 0.995\n",
      "(1380, 21)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 2.6018 - accuracy: 0.1574 - val_loss: 2.4553 - val_accuracy: 0.1786\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2810 - accuracy: 0.3616 - val_loss: 2.2395 - val_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0363 - accuracy: 0.4380 - val_loss: 2.0516 - val_accuracy: 0.3571\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8274 - accuracy: 0.4809 - val_loss: 1.8797 - val_accuracy: 0.4107\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6395 - accuracy: 0.5134 - val_loss: 1.7370 - val_accuracy: 0.4464\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4837 - accuracy: 0.5534 - val_loss: 1.6206 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3700 - accuracy: 0.5735 - val_loss: 1.5498 - val_accuracy: 0.4643\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2824 - accuracy: 0.6078 - val_loss: 1.4833 - val_accuracy: 0.4643\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2112 - accuracy: 0.6221 - val_loss: 1.4246 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1492 - accuracy: 0.6469 - val_loss: 1.4071 - val_accuracy: 0.4821\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0999 - accuracy: 0.6508 - val_loss: 1.3601 - val_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0589 - accuracy: 0.6584 - val_loss: 1.3184 - val_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0193 - accuracy: 0.6756 - val_loss: 1.2956 - val_accuracy: 0.5179\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9817 - accuracy: 0.6842 - val_loss: 1.2586 - val_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.6908 - val_loss: 1.2333 - val_accuracy: 0.5357\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.6937 - val_loss: 1.2217 - val_accuracy: 0.5357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8922 - accuracy: 0.7128 - val_loss: 1.2075 - val_accuracy: 0.5357\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8674 - accuracy: 0.7090 - val_loss: 1.1703 - val_accuracy: 0.5357\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8416 - accuracy: 0.7290 - val_loss: 1.1637 - val_accuracy: 0.5357\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.7309 - val_loss: 1.1229 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8045 - accuracy: 0.7338 - val_loss: 1.1289 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7794 - accuracy: 0.7414 - val_loss: 1.1055 - val_accuracy: 0.5179\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7627 - accuracy: 0.7433 - val_loss: 1.1036 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7548 - val_loss: 1.0877 - val_accuracy: 0.5357\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.7567 - val_loss: 1.0769 - val_accuracy: 0.5179\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.7643 - val_loss: 1.0580 - val_accuracy: 0.5893\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.7719 - val_loss: 1.0361 - val_accuracy: 0.5893\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.7700 - val_loss: 1.0517 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7863 - val_loss: 1.0261 - val_accuracy: 0.6429\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.7948 - val_loss: 1.0185 - val_accuracy: 0.6071\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.7863 - val_loss: 1.0048 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.8025 - val_loss: 1.0385 - val_accuracy: 0.6429\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.8044 - val_loss: 0.9813 - val_accuracy: 0.5893\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.8073 - val_loss: 0.9938 - val_accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.8092 - val_loss: 0.9785 - val_accuracy: 0.6429\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8139 - val_loss: 0.9780 - val_accuracy: 0.6071\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.8177 - val_loss: 0.9733 - val_accuracy: 0.6429\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8092 - val_loss: 0.9681 - val_accuracy: 0.6429\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8235 - val_loss: 0.9611 - val_accuracy: 0.6429\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.8292 - val_loss: 0.9409 - val_accuracy: 0.6607\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.8235 - val_loss: 0.9720 - val_accuracy: 0.6429\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8263 - val_loss: 0.9624 - val_accuracy: 0.6429\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.8311 - val_loss: 0.9441 - val_accuracy: 0.6964\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.8282 - val_loss: 0.9596 - val_accuracy: 0.6250\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8387 - val_loss: 0.9432 - val_accuracy: 0.6786\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8349 - val_loss: 0.9491 - val_accuracy: 0.6429\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8340 - val_loss: 0.9298 - val_accuracy: 0.6071\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8435 - val_loss: 0.9362 - val_accuracy: 0.6607\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8473 - val_loss: 0.9261 - val_accuracy: 0.6964\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.8483 - val_loss: 0.9478 - val_accuracy: 0.6607\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8502 - val_loss: 0.9203 - val_accuracy: 0.6786\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8578 - val_loss: 0.9232 - val_accuracy: 0.6429\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8578 - val_loss: 0.9127 - val_accuracy: 0.6429\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8569 - val_loss: 0.9250 - val_accuracy: 0.6429\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8635 - val_loss: 0.9159 - val_accuracy: 0.6786\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8664 - val_loss: 0.9038 - val_accuracy: 0.6786\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8635 - val_loss: 0.9149 - val_accuracy: 0.6607\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8740 - val_loss: 0.9108 - val_accuracy: 0.6964\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8693 - val_loss: 0.9228 - val_accuracy: 0.6964\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8702 - val_loss: 0.9116 - val_accuracy: 0.6786\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8721 - val_loss: 0.8839 - val_accuracy: 0.6607\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8855 - val_loss: 0.9107 - val_accuracy: 0.6964\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8807 - val_loss: 0.9122 - val_accuracy: 0.6964\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8798 - val_loss: 0.9152 - val_accuracy: 0.6786\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8836 - val_loss: 0.9282 - val_accuracy: 0.6429\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8865 - val_loss: 0.8991 - val_accuracy: 0.6964\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8989 - val_loss: 0.9035 - val_accuracy: 0.6786\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8941 - val_loss: 0.8904 - val_accuracy: 0.6964\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8969 - val_loss: 0.8981 - val_accuracy: 0.6786\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8950 - val_loss: 0.8776 - val_accuracy: 0.6964\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8979 - val_loss: 0.9240 - val_accuracy: 0.6964\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.9055 - val_loss: 0.8847 - val_accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.9046 - val_loss: 0.9050 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.9027 - val_loss: 0.8907 - val_accuracy: 0.6607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.9151 - val_loss: 0.9119 - val_accuracy: 0.7143\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.9008 - val_loss: 0.9045 - val_accuracy: 0.6964\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.9065 - val_loss: 0.8758 - val_accuracy: 0.7143\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.9160 - val_loss: 0.8993 - val_accuracy: 0.7143\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.9170 - val_loss: 0.8805 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.9170 - val_loss: 0.8895 - val_accuracy: 0.7143\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.9170 - val_loss: 0.8657 - val_accuracy: 0.7143\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.9189 - val_loss: 0.8969 - val_accuracy: 0.7143\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.9179 - val_loss: 0.8783 - val_accuracy: 0.7143\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.9265 - val_loss: 0.9053 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.9275 - val_loss: 0.9232 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9237 - val_loss: 0.8930 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.9313 - val_loss: 0.8956 - val_accuracy: 0.7143\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.9265 - val_loss: 0.8912 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9246 - val_loss: 0.8696 - val_accuracy: 0.7143\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9303 - val_loss: 0.8831 - val_accuracy: 0.7143\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.9351 - val_loss: 0.8695 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9323 - val_loss: 0.8674 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9370 - val_loss: 0.8688 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9380 - val_loss: 0.8791 - val_accuracy: 0.7143\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9332 - val_loss: 0.8700 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9389 - val_loss: 0.8599 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9399 - val_loss: 0.8702 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9389 - val_loss: 0.8725 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9427 - val_loss: 0.8666 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9408 - val_loss: 0.8913 - val_accuracy: 0.7500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9115 - accuracy: 0.7790\n",
      "\n",
      "Test accuracy: 0.7789855003356934\n",
      "var: 0.996\n",
      "(1380, 21)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 2s 11ms/step - loss: 2.6061 - accuracy: 0.1412 - val_loss: 2.3150 - val_accuracy: 0.3571\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.2155 - accuracy: 0.3302 - val_loss: 2.0931 - val_accuracy: 0.3750\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.9765 - accuracy: 0.4294 - val_loss: 1.9042 - val_accuracy: 0.3929\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.7649 - accuracy: 0.4952 - val_loss: 1.7603 - val_accuracy: 0.4107\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5803 - accuracy: 0.5200 - val_loss: 1.6436 - val_accuracy: 0.4286\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4362 - accuracy: 0.5334 - val_loss: 1.5655 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3287 - accuracy: 0.5802 - val_loss: 1.5116 - val_accuracy: 0.4643\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2448 - accuracy: 0.5983 - val_loss: 1.4531 - val_accuracy: 0.4821\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1792 - accuracy: 0.6212 - val_loss: 1.4222 - val_accuracy: 0.4643\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1242 - accuracy: 0.6441 - val_loss: 1.3826 - val_accuracy: 0.4464\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0762 - accuracy: 0.6441 - val_loss: 1.3385 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0348 - accuracy: 0.6641 - val_loss: 1.3338 - val_accuracy: 0.4643\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9982 - accuracy: 0.6622 - val_loss: 1.2823 - val_accuracy: 0.5536\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9642 - accuracy: 0.6823 - val_loss: 1.2445 - val_accuracy: 0.5536\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9335 - accuracy: 0.6985 - val_loss: 1.2342 - val_accuracy: 0.5893\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8998 - accuracy: 0.6985 - val_loss: 1.1962 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8735 - accuracy: 0.7080 - val_loss: 1.1836 - val_accuracy: 0.5893\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8486 - accuracy: 0.7156 - val_loss: 1.1619 - val_accuracy: 0.5893\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.7252 - val_loss: 1.1388 - val_accuracy: 0.5893\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8019 - accuracy: 0.7328 - val_loss: 1.1372 - val_accuracy: 0.5893\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.7376 - val_loss: 1.1036 - val_accuracy: 0.6071\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7603 - accuracy: 0.7471 - val_loss: 1.0938 - val_accuracy: 0.5893\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.7595 - val_loss: 1.0898 - val_accuracy: 0.5893\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7246 - accuracy: 0.7567 - val_loss: 1.0694 - val_accuracy: 0.6071\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.7681 - val_loss: 1.0507 - val_accuracy: 0.5893\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.7748 - val_loss: 1.0482 - val_accuracy: 0.6071\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.7786 - val_loss: 1.0094 - val_accuracy: 0.6607\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.7910 - val_loss: 1.0313 - val_accuracy: 0.6071\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.7863 - val_loss: 1.0230 - val_accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7939 - val_loss: 1.0109 - val_accuracy: 0.6250\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.8073 - val_loss: 0.9951 - val_accuracy: 0.6607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.8073 - val_loss: 0.9822 - val_accuracy: 0.6786\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.8092 - val_loss: 0.9753 - val_accuracy: 0.6786\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.8177 - val_loss: 0.9860 - val_accuracy: 0.6429\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.8158 - val_loss: 0.9636 - val_accuracy: 0.6607\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.8197 - val_loss: 0.9716 - val_accuracy: 0.6429\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.8254 - val_loss: 0.9589 - val_accuracy: 0.6429\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8282 - val_loss: 0.9528 - val_accuracy: 0.6429\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.8225 - val_loss: 0.9546 - val_accuracy: 0.6786\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8349 - val_loss: 0.9425 - val_accuracy: 0.6607\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.8311 - val_loss: 0.9318 - val_accuracy: 0.6607\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.8397 - val_loss: 0.9432 - val_accuracy: 0.6786\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8397 - val_loss: 0.9420 - val_accuracy: 0.6607\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8445 - val_loss: 0.9419 - val_accuracy: 0.6429\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.8464 - val_loss: 0.9389 - val_accuracy: 0.6607\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8521 - val_loss: 0.9248 - val_accuracy: 0.6786\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8607 - val_loss: 0.9302 - val_accuracy: 0.6786\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8607 - val_loss: 0.9412 - val_accuracy: 0.6607\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8607 - val_loss: 0.9208 - val_accuracy: 0.6786\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8664 - val_loss: 0.9311 - val_accuracy: 0.6964\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8645 - val_loss: 0.9422 - val_accuracy: 0.6964\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8712 - val_loss: 0.9178 - val_accuracy: 0.6964\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8750 - val_loss: 0.9165 - val_accuracy: 0.6964\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8836 - val_loss: 0.9234 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8836 - val_loss: 0.9147 - val_accuracy: 0.6607\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8798 - val_loss: 0.9173 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8903 - val_loss: 0.9080 - val_accuracy: 0.6964\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8884 - val_loss: 0.8992 - val_accuracy: 0.6786\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8922 - val_loss: 0.9029 - val_accuracy: 0.6964\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8922 - val_loss: 0.9052 - val_accuracy: 0.6964\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8893 - val_loss: 0.9033 - val_accuracy: 0.6964\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8989 - val_loss: 0.9131 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8884 - val_loss: 0.9156 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8979 - val_loss: 0.8852 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.9017 - val_loss: 0.9250 - val_accuracy: 0.7143\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8998 - val_loss: 0.8933 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8969 - val_loss: 0.8906 - val_accuracy: 0.7143\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.9084 - val_loss: 0.9034 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.9055 - val_loss: 0.9002 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.9055 - val_loss: 0.8865 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.9065 - val_loss: 0.8947 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.9074 - val_loss: 0.8793 - val_accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.9103 - val_loss: 0.9048 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.9113 - val_loss: 0.8800 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.9113 - val_loss: 0.8882 - val_accuracy: 0.7143\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.9113 - val_loss: 0.8877 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.9151 - val_loss: 0.8846 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.9113 - val_loss: 0.8957 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.9189 - val_loss: 0.8688 - val_accuracy: 0.7143\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.9198 - val_loss: 0.8908 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.9256 - val_loss: 0.8797 - val_accuracy: 0.7143\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.9256 - val_loss: 0.8855 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.9275 - val_loss: 0.8738 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.9227 - val_loss: 0.8884 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9294 - val_loss: 0.8783 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9208 - val_loss: 0.8898 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9294 - val_loss: 0.8995 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.9313 - val_loss: 0.8792 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.9265 - val_loss: 0.8952 - val_accuracy: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9342 - val_loss: 0.9143 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9294 - val_loss: 0.8843 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9332 - val_loss: 0.9112 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2352 - accuracy: 0.9294 - val_loss: 0.8722 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9294 - val_loss: 0.9090 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9399 - val_loss: 0.9214 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.9361 - val_loss: 0.8930 - val_accuracy: 0.7679\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9351 - val_loss: 0.8875 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9437 - val_loss: 0.9075 - val_accuracy: 0.7143\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9408 - val_loss: 0.8974 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9332 - val_loss: 0.8983 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9224 - accuracy: 0.7826\n",
      "\n",
      "Test accuracy: 0.782608687877655\n",
      "var: 0.997\n",
      "(1380, 22)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 2.5692 - accuracy: 0.1365 - val_loss: 2.4210 - val_accuracy: 0.1607\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2270 - accuracy: 0.3015 - val_loss: 2.1804 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.4208 - val_loss: 1.9750 - val_accuracy: 0.4107\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.7067 - accuracy: 0.5076 - val_loss: 1.8150 - val_accuracy: 0.4107\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.5204 - accuracy: 0.5458 - val_loss: 1.6977 - val_accuracy: 0.4107\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3882 - accuracy: 0.5802 - val_loss: 1.6190 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2932 - accuracy: 0.5906 - val_loss: 1.5560 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2220 - accuracy: 0.6155 - val_loss: 1.4988 - val_accuracy: 0.5179\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1675 - accuracy: 0.6307 - val_loss: 1.4591 - val_accuracy: 0.5179\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1218 - accuracy: 0.6374 - val_loss: 1.4189 - val_accuracy: 0.5536\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0808 - accuracy: 0.6527 - val_loss: 1.3809 - val_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0449 - accuracy: 0.6622 - val_loss: 1.3618 - val_accuracy: 0.5536\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0082 - accuracy: 0.6784 - val_loss: 1.3113 - val_accuracy: 0.5536\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9796 - accuracy: 0.6851 - val_loss: 1.2939 - val_accuracy: 0.6071\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9489 - accuracy: 0.6889 - val_loss: 1.2832 - val_accuracy: 0.6071\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.7099 - val_loss: 1.2445 - val_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8970 - accuracy: 0.7128 - val_loss: 1.2348 - val_accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8726 - accuracy: 0.7204 - val_loss: 1.2113 - val_accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8488 - accuracy: 0.7328 - val_loss: 1.2070 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.7395 - val_loss: 1.2006 - val_accuracy: 0.6429\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8102 - accuracy: 0.7366 - val_loss: 1.1584 - val_accuracy: 0.6429\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7899 - accuracy: 0.7519 - val_loss: 1.1719 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7648 - accuracy: 0.7595 - val_loss: 1.1510 - val_accuracy: 0.6429\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7482 - accuracy: 0.7691 - val_loss: 1.1304 - val_accuracy: 0.6607\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.7710 - val_loss: 1.1530 - val_accuracy: 0.6607\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7130 - accuracy: 0.7844 - val_loss: 1.1263 - val_accuracy: 0.6429\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.7796 - val_loss: 1.1076 - val_accuracy: 0.6429\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7901 - val_loss: 1.1060 - val_accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7929 - val_loss: 1.1035 - val_accuracy: 0.6429\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.7939 - val_loss: 1.0942 - val_accuracy: 0.6429\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7929 - val_loss: 1.0937 - val_accuracy: 0.6429\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.8073 - val_loss: 1.0817 - val_accuracy: 0.6607\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.8073 - val_loss: 1.0539 - val_accuracy: 0.6429\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.8120 - val_loss: 1.0690 - val_accuracy: 0.6607\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.8168 - val_loss: 1.0510 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8139 - val_loss: 1.0688 - val_accuracy: 0.6429\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.8254 - val_loss: 1.0228 - val_accuracy: 0.6607\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.8263 - val_loss: 1.0273 - val_accuracy: 0.6429\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.8330 - val_loss: 1.0325 - val_accuracy: 0.6964\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.8340 - val_loss: 1.0196 - val_accuracy: 0.6429\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8387 - val_loss: 1.0296 - val_accuracy: 0.6786\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8378 - val_loss: 1.0041 - val_accuracy: 0.6786\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.8531 - val_loss: 0.9982 - val_accuracy: 0.6786\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.8511 - val_loss: 1.0068 - val_accuracy: 0.6964\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8550 - val_loss: 1.0230 - val_accuracy: 0.6786\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8550 - val_loss: 1.0079 - val_accuracy: 0.6964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8655 - val_loss: 0.9753 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8664 - val_loss: 1.0076 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8712 - val_loss: 1.0042 - val_accuracy: 0.6964\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8712 - val_loss: 1.0259 - val_accuracy: 0.6964\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8712 - val_loss: 0.9716 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8845 - val_loss: 0.9798 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8826 - val_loss: 0.9948 - val_accuracy: 0.6964\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8845 - val_loss: 0.9807 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8836 - val_loss: 1.0018 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8931 - val_loss: 0.9898 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8922 - val_loss: 0.9820 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.9046 - val_loss: 0.9916 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.9008 - val_loss: 0.9879 - val_accuracy: 0.7143\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.9027 - val_loss: 0.9833 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.9122 - val_loss: 0.9769 - val_accuracy: 0.7321\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.9103 - val_loss: 0.9746 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.9103 - val_loss: 0.9755 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9113 - val_loss: 0.9755 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.9170 - val_loss: 0.9794 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.9198 - val_loss: 0.9708 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.9218 - val_loss: 0.9683 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.9246 - val_loss: 0.9747 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.9265 - val_loss: 0.9655 - val_accuracy: 0.7143\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.9208 - val_loss: 0.9900 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.9218 - val_loss: 0.9805 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.9313 - val_loss: 0.9683 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.9256 - val_loss: 0.9865 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.9265 - val_loss: 0.9748 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9275 - val_loss: 0.9754 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.9294 - val_loss: 0.9843 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.9351 - val_loss: 0.9787 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.9323 - val_loss: 0.9746 - val_accuracy: 0.7679\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9370 - val_loss: 0.9726 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9380 - val_loss: 0.9787 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.9342 - val_loss: 0.9781 - val_accuracy: 0.7143\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9370 - val_loss: 0.9918 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.9408 - val_loss: 0.9730 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9427 - val_loss: 1.0050 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9408 - val_loss: 0.9827 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9370 - val_loss: 0.9834 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9447 - val_loss: 0.9776 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9408 - val_loss: 1.0031 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9437 - val_loss: 0.9838 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9466 - val_loss: 0.9953 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9475 - val_loss: 0.9888 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9447 - val_loss: 1.0048 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9504 - val_loss: 0.9909 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1999 - accuracy: 0.9532 - val_loss: 0.9894 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9494 - val_loss: 1.0031 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9456 - val_loss: 0.9979 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9542 - val_loss: 1.0096 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9552 - val_loss: 1.0144 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9599 - val_loss: 1.0094 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9599 - val_loss: 1.0189 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9498 - accuracy: 0.7935\n",
      "\n",
      "Test accuracy: 0.79347825050354\n",
      "var: 0.998\n",
      "(1380, 24)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 2.4676 - accuracy: 0.2223 - val_loss: 2.3146 - val_accuracy: 0.3393\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.1151 - accuracy: 0.4094 - val_loss: 2.1008 - val_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8700 - accuracy: 0.4656 - val_loss: 1.9180 - val_accuracy: 0.3393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.6699 - accuracy: 0.4905 - val_loss: 1.7794 - val_accuracy: 0.3929\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5138 - accuracy: 0.5315 - val_loss: 1.6721 - val_accuracy: 0.4107\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3986 - accuracy: 0.5639 - val_loss: 1.6056 - val_accuracy: 0.4286\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3155 - accuracy: 0.5763 - val_loss: 1.5479 - val_accuracy: 0.5179\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2483 - accuracy: 0.5992 - val_loss: 1.4982 - val_accuracy: 0.4643\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1946 - accuracy: 0.6155 - val_loss: 1.4551 - val_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1450 - accuracy: 0.6336 - val_loss: 1.4047 - val_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1033 - accuracy: 0.6412 - val_loss: 1.3762 - val_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0639 - accuracy: 0.6565 - val_loss: 1.3469 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0299 - accuracy: 0.6698 - val_loss: 1.3256 - val_accuracy: 0.6071\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9980 - accuracy: 0.6737 - val_loss: 1.2986 - val_accuracy: 0.6071\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9730 - accuracy: 0.6813 - val_loss: 1.2849 - val_accuracy: 0.6071\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9444 - accuracy: 0.6880 - val_loss: 1.2709 - val_accuracy: 0.5893\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9208 - accuracy: 0.6937 - val_loss: 1.2476 - val_accuracy: 0.6071\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8966 - accuracy: 0.7147 - val_loss: 1.2377 - val_accuracy: 0.6071\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8749 - accuracy: 0.7242 - val_loss: 1.2238 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8505 - accuracy: 0.7185 - val_loss: 1.2060 - val_accuracy: 0.6250\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8324 - accuracy: 0.7319 - val_loss: 1.1918 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8127 - accuracy: 0.7433 - val_loss: 1.1900 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.7424 - val_loss: 1.1692 - val_accuracy: 0.6429\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7755 - accuracy: 0.7529 - val_loss: 1.1550 - val_accuracy: 0.6429\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7591 - accuracy: 0.7548 - val_loss: 1.1499 - val_accuracy: 0.5893\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7586 - val_loss: 1.1345 - val_accuracy: 0.6071\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.7662 - val_loss: 1.1333 - val_accuracy: 0.6071\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.7739 - val_loss: 1.1348 - val_accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.7815 - val_loss: 1.0980 - val_accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7805 - val_loss: 1.0890 - val_accuracy: 0.6071\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7948 - val_loss: 1.0808 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7891 - val_loss: 1.0752 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7920 - val_loss: 1.0724 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7958 - val_loss: 1.0799 - val_accuracy: 0.6429\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.8034 - val_loss: 1.0275 - val_accuracy: 0.6607\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.8092 - val_loss: 1.0511 - val_accuracy: 0.6607\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.8111 - val_loss: 1.0346 - val_accuracy: 0.6607\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.8149 - val_loss: 1.0211 - val_accuracy: 0.6607\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.8139 - val_loss: 1.0089 - val_accuracy: 0.6607\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.8197 - val_loss: 0.9925 - val_accuracy: 0.6607\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.8254 - val_loss: 0.9823 - val_accuracy: 0.6786\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8292 - val_loss: 0.9946 - val_accuracy: 0.6786\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.8302 - val_loss: 0.9653 - val_accuracy: 0.6607\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8311 - val_loss: 0.9623 - val_accuracy: 0.6964\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.8340 - val_loss: 0.9707 - val_accuracy: 0.6786\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8359 - val_loss: 0.9411 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.8473 - val_loss: 0.9284 - val_accuracy: 0.6786\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8492 - val_loss: 0.9343 - val_accuracy: 0.6786\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.8569 - val_loss: 0.9318 - val_accuracy: 0.6964\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.8588 - val_loss: 0.9180 - val_accuracy: 0.7143\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8578 - val_loss: 0.9050 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8674 - val_loss: 0.8876 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8635 - val_loss: 0.8995 - val_accuracy: 0.7143\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8731 - val_loss: 0.8751 - val_accuracy: 0.7321\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8760 - val_loss: 0.8644 - val_accuracy: 0.6964\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8731 - val_loss: 0.8821 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8731 - val_loss: 0.8748 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8807 - val_loss: 0.8433 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8769 - val_loss: 0.8571 - val_accuracy: 0.7143\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8798 - val_loss: 0.8477 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8807 - val_loss: 0.8255 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8855 - val_loss: 0.8123 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8845 - val_loss: 0.8186 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8884 - val_loss: 0.8108 - val_accuracy: 0.7143\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8884 - val_loss: 0.8021 - val_accuracy: 0.6964\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8903 - val_loss: 0.8136 - val_accuracy: 0.6964\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8969 - val_loss: 0.8049 - val_accuracy: 0.7143\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8960 - val_loss: 0.7895 - val_accuracy: 0.7143\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.9036 - val_loss: 0.7973 - val_accuracy: 0.7679\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8979 - val_loss: 0.7808 - val_accuracy: 0.7143\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.9017 - val_loss: 0.7794 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.9017 - val_loss: 0.7924 - val_accuracy: 0.6964\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.9027 - val_loss: 0.7872 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.9113 - val_loss: 0.7631 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.9055 - val_loss: 0.7579 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.9084 - val_loss: 0.7678 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.9113 - val_loss: 0.7450 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.9141 - val_loss: 0.7583 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.9198 - val_loss: 0.7498 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.9132 - val_loss: 0.7516 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.9132 - val_loss: 0.7537 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.9189 - val_loss: 0.7242 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.9179 - val_loss: 0.7290 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.9237 - val_loss: 0.7427 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.9246 - val_loss: 0.7251 - val_accuracy: 0.7679\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.9227 - val_loss: 0.7114 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.9198 - val_loss: 0.7316 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.9284 - val_loss: 0.7199 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9323 - val_loss: 0.7308 - val_accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.9284 - val_loss: 0.7253 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9361 - val_loss: 0.7196 - val_accuracy: 0.8036\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9303 - val_loss: 0.7000 - val_accuracy: 0.7679\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.9351 - val_loss: 0.7336 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2382 - accuracy: 0.9408 - val_loss: 0.6998 - val_accuracy: 0.8036\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9389 - val_loss: 0.7196 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2275 - accuracy: 0.9427 - val_loss: 0.7280 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2275 - accuracy: 0.9342 - val_loss: 0.7155 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9389 - val_loss: 0.7026 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9380 - val_loss: 0.7058 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9447 - val_loss: 0.7160 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9545 - accuracy: 0.7681\n",
      "\n",
      "Test accuracy: 0.7681159377098083\n",
      "var: 0.999\n",
      "(1380, 26)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 2.6488 - accuracy: 0.0964 - val_loss: 2.4938 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.2753 - accuracy: 0.2615 - val_loss: 2.3078 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.0668 - accuracy: 0.4017 - val_loss: 2.1280 - val_accuracy: 0.3036\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8606 - accuracy: 0.4466 - val_loss: 1.9481 - val_accuracy: 0.3571\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6650 - accuracy: 0.4914 - val_loss: 1.7891 - val_accuracy: 0.4107\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.5084 - accuracy: 0.5200 - val_loss: 1.6511 - val_accuracy: 0.4464\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3902 - accuracy: 0.5563 - val_loss: 1.5609 - val_accuracy: 0.4643\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2981 - accuracy: 0.5821 - val_loss: 1.4661 - val_accuracy: 0.4821\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2224 - accuracy: 0.6078 - val_loss: 1.4131 - val_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1605 - accuracy: 0.6384 - val_loss: 1.3577 - val_accuracy: 0.5536\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1074 - accuracy: 0.6594 - val_loss: 1.3116 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0626 - accuracy: 0.6660 - val_loss: 1.2759 - val_accuracy: 0.6071\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.6803 - val_loss: 1.2540 - val_accuracy: 0.5893\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9812 - accuracy: 0.6918 - val_loss: 1.2214 - val_accuracy: 0.5536\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9482 - accuracy: 0.7052 - val_loss: 1.2009 - val_accuracy: 0.5536\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.9205 - accuracy: 0.7071 - val_loss: 1.1868 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8899 - accuracy: 0.7214 - val_loss: 1.1726 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8646 - accuracy: 0.7290 - val_loss: 1.1448 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8383 - accuracy: 0.7376 - val_loss: 1.1593 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8143 - accuracy: 0.7385 - val_loss: 1.1248 - val_accuracy: 0.5893\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7922 - accuracy: 0.7452 - val_loss: 1.1268 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.7529 - val_loss: 1.1059 - val_accuracy: 0.5893\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.7576 - val_loss: 1.0902 - val_accuracy: 0.6429\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7326 - accuracy: 0.7710 - val_loss: 1.0851 - val_accuracy: 0.6071\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.7777 - val_loss: 1.0897 - val_accuracy: 0.5893\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.7824 - val_loss: 1.0745 - val_accuracy: 0.6071\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.7853 - val_loss: 1.0576 - val_accuracy: 0.6071\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.7958 - val_loss: 1.0666 - val_accuracy: 0.5893\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.8044 - val_loss: 1.0303 - val_accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.7987 - val_loss: 1.0572 - val_accuracy: 0.6071\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.8168 - val_loss: 1.0255 - val_accuracy: 0.6607\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.8168 - val_loss: 1.0145 - val_accuracy: 0.6429\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.8177 - val_loss: 1.0097 - val_accuracy: 0.6429\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.8235 - val_loss: 1.0130 - val_accuracy: 0.6786\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.8273 - val_loss: 1.0109 - val_accuracy: 0.6607\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.8273 - val_loss: 0.9981 - val_accuracy: 0.6964\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.8426 - val_loss: 0.9710 - val_accuracy: 0.7143\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8387 - val_loss: 1.0007 - val_accuracy: 0.6964\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.8397 - val_loss: 1.0051 - val_accuracy: 0.6964\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8454 - val_loss: 0.9878 - val_accuracy: 0.6786\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.8492 - val_loss: 0.9964 - val_accuracy: 0.6964\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.8511 - val_loss: 0.9546 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8531 - val_loss: 0.9721 - val_accuracy: 0.7143\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8511 - val_loss: 0.9717 - val_accuracy: 0.6786\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8588 - val_loss: 0.9723 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8559 - val_loss: 0.9693 - val_accuracy: 0.6964\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8597 - val_loss: 0.9831 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8645 - val_loss: 0.9748 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8664 - val_loss: 0.9735 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8740 - val_loss: 0.9435 - val_accuracy: 0.7143\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8779 - val_loss: 0.9679 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8769 - val_loss: 0.9511 - val_accuracy: 0.6964\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8731 - val_loss: 0.9486 - val_accuracy: 0.6964\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8836 - val_loss: 0.9591 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8865 - val_loss: 0.9569 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8836 - val_loss: 0.9513 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8960 - val_loss: 0.9520 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8941 - val_loss: 0.9421 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8941 - val_loss: 0.9507 - val_accuracy: 0.7143\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8989 - val_loss: 0.9402 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8998 - val_loss: 0.9558 - val_accuracy: 0.7143\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.9113 - val_loss: 0.9339 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.9103 - val_loss: 0.9607 - val_accuracy: 0.7321\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.9151 - val_loss: 0.8991 - val_accuracy: 0.7143\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.9084 - val_loss: 0.9551 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.9218 - val_loss: 0.9386 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.9256 - val_loss: 0.9244 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9265 - val_loss: 0.9334 - val_accuracy: 0.7679\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.9218 - val_loss: 0.9397 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9284 - val_loss: 0.9161 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9332 - val_loss: 0.9350 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.9380 - val_loss: 0.9364 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9389 - val_loss: 0.9489 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9437 - val_loss: 0.9376 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9389 - val_loss: 0.9218 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.9389 - val_loss: 0.9390 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.9389 - val_loss: 0.9109 - val_accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9427 - val_loss: 0.9443 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9399 - val_loss: 0.9018 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9456 - val_loss: 0.9333 - val_accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9456 - val_loss: 0.9275 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9456 - val_loss: 0.9444 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9447 - val_loss: 0.9401 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9504 - val_loss: 0.9210 - val_accuracy: 0.7679\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9437 - val_loss: 0.9239 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9418 - val_loss: 0.9225 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.9504 - val_loss: 0.9505 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9475 - val_loss: 0.9262 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9542 - val_loss: 0.9116 - val_accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9590 - val_loss: 0.9507 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9504 - val_loss: 0.9236 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.9552 - val_loss: 0.9497 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9571 - val_loss: 0.9499 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9599 - val_loss: 0.9413 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9628 - val_loss: 0.9315 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9599 - val_loss: 0.9442 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9647 - val_loss: 0.9503 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9647 - val_loss: 0.9462 - val_accuracy: 0.7679\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9580 - val_loss: 0.9453 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9618 - val_loss: 0.9595 - val_accuracy: 0.8036\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8855 - accuracy: 0.8080\n",
      "\n",
      "Test accuracy: 0.8079710006713867\n",
      "Best Accuracy: 0.8079710006713867\n",
      "Trimmed x_d with Best Selected Features:\n",
      "(1380, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_pca_for_feature_selection(X, desired_variance_ratio):\n",
    "    pca = PCA(n_components=desired_variance_ratio)\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "    return reduced_features, pca\n",
    "\n",
    "def pca(X, y, test_size=0.2, random_state=42):\n",
    "\n",
    "    variance_ratios = [i / 1000 for i in range(990, 1000)]\n",
    "    max_accuracy = 0.0\n",
    "    best_selected_features = None\n",
    "    best_pca_model = None\n",
    "\n",
    "    for desired_variance_ratio in variance_ratios:\n",
    "        reduced_features, pca_model = apply_pca_for_feature_selection(X, desired_variance_ratio)\n",
    "        print(f\"var: {desired_variance_ratio}\")\n",
    "        print(np.shape(reduced_features))\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Build the ANN model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Update max accuracy and store corresponding features\n",
    "        if test_acc > max_accuracy:\n",
    "            max_accuracy = test_acc\n",
    "            best_selected_features = reduced_features.copy()\n",
    "            best_pca_model = pca_model\n",
    "\n",
    "    # Apply inverse_transform to the full dataset with the best selected features\n",
    "    trimmed_x_d = best_pca_model.inverse_transform(best_selected_features)\n",
    "\n",
    "    return best_selected_features, max_accuracy\n",
    "\n",
    "# Example usage:\n",
    "reduced_x_d, max_accuracy = pca(x_d, y_d)\n",
    "print(f\"Best Accuracy: {max_accuracy}\")\n",
    "print(\"Trimmed x_d with Best Selected Features:\")\n",
    "print(np.shape(reduced_x_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bcf09",
   "metadata": {},
   "source": [
    "## ANN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca19135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01, 0.1, 0.3, 0.5], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X = reduced_x_d\n",
    "y = y_d\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # Tune the number of layers.\n",
    "        for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "            model.add(\n",
    "                layers.Dense(\n",
    "                    # Tune number of units separately.\n",
    "                    units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model.add(layers.Dense(14, activation=\"softmax\"))\n",
    "\n",
    "        learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.01, 0.1, 0.3, 0.5])\n",
    "#         alpha = hp.Choice(\"alpha\", [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate), #, momentum=alpha\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create an instance of HyperParameters\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "# Build the model with default hyperparameters\n",
    "my_hypermodel = MyHyperModel()\n",
    "my_model = my_hypermodel.build(hp)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=my_hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    factor=2,\n",
    "    directory=\"Parameter Tuning\",\n",
    "    project_name=\"14 Classes - CM\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96f1d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.0892857164144516\n",
      "\n",
      "Best val_accuracy So Far: 0.8571428656578064\n",
      "Total elapsed time: 00h 12m 05s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.05, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02db1ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Parameter Tuning\\14 Classes - CM\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0149 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 384\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 480\n",
      "activation_1: tanh\n",
      "batch_size: 64\n",
      "units_2: 32\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0145\n",
      "Score: 0.8571428656578064\n",
      "\n",
      "Trial 0166 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 32\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 416\n",
      "activation_1: relu\n",
      "batch_size: 64\n",
      "units_2: 320\n",
      "activation_2: relu\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0161\n",
      "Score: 0.8571428656578064\n",
      "\n",
      "Trial 0067 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 352\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 128\n",
      "activation_1: tanh\n",
      "batch_size: 32\n",
      "units_2: 224\n",
      "activation_2: tanh\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0057\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0070 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 480\n",
      "activation_1: relu\n",
      "batch_size: 64\n",
      "units_2: 320\n",
      "activation_2: relu\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0061\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0073 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 480\n",
      "activation_1: relu\n",
      "batch_size: 64\n",
      "units_2: 320\n",
      "activation_2: relu\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 5\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0070\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0074 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 512\n",
      "activation_1: tanh\n",
      "batch_size: 32\n",
      "units_2: 384\n",
      "activation_2: relu\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 5\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0068\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0075 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 480\n",
      "activation_1: relu\n",
      "batch_size: 64\n",
      "units_2: 320\n",
      "activation_2: relu\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 5\n",
      "tuner/round: 5\n",
      "tuner/trial_id: 0073\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0076 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 512\n",
      "activation_1: tanh\n",
      "batch_size: 32\n",
      "units_2: 384\n",
      "activation_2: relu\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 5\n",
      "tuner/round: 5\n",
      "tuner/trial_id: 0074\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0118 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 320\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "batch_size: 32\n",
      "units_2: 448\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0112\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0122 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 448\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 64\n",
      "activation_1: tanh\n",
      "batch_size: 32\n",
      "units_2: 416\n",
      "activation_2: relu\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0120\n",
      "Score: 0.8392857313156128\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e38f980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 2s 15ms/step - loss: 1.9729 - accuracy: 0.3828 - val_loss: 1.4890 - val_accuracy: 0.5294\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.3681 - accuracy: 0.5663 - val_loss: 1.1783 - val_accuracy: 0.6516\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0773 - accuracy: 0.6636 - val_loss: 1.1208 - val_accuracy: 0.6425\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.9496 - accuracy: 0.6897 - val_loss: 0.9634 - val_accuracy: 0.7240\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8284 - accuracy: 0.7327 - val_loss: 1.0011 - val_accuracy: 0.6742\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.7947 - accuracy: 0.7486 - val_loss: 0.9951 - val_accuracy: 0.6787\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.7769 - val_loss: 0.9424 - val_accuracy: 0.7285\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.7973 - val_loss: 0.8929 - val_accuracy: 0.7195\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.5683 - accuracy: 0.8199 - val_loss: 0.8613 - val_accuracy: 0.7421\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.8414 - val_loss: 0.8191 - val_accuracy: 0.7511\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.8301 - val_loss: 0.8564 - val_accuracy: 0.7828\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.8324 - val_loss: 0.8041 - val_accuracy: 0.7511\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8562 - val_loss: 0.8617 - val_accuracy: 0.7647\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8596 - val_loss: 0.8543 - val_accuracy: 0.7647\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8834 - val_loss: 0.9737 - val_accuracy: 0.6968\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8664 - val_loss: 0.7952 - val_accuracy: 0.7873\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8981 - val_loss: 0.7752 - val_accuracy: 0.8009\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8981 - val_loss: 0.6893 - val_accuracy: 0.8054\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8981 - val_loss: 0.7115 - val_accuracy: 0.8190\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2764 - accuracy: 0.9037 - val_loss: 0.7633 - val_accuracy: 0.7873\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2203 - accuracy: 0.9343 - val_loss: 0.8218 - val_accuracy: 0.7783\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.9162 - val_loss: 0.8762 - val_accuracy: 0.7873\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2733 - accuracy: 0.9037 - val_loss: 0.8197 - val_accuracy: 0.8009\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2125 - accuracy: 0.9332 - val_loss: 0.8541 - val_accuracy: 0.8054\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9377 - val_loss: 0.8807 - val_accuracy: 0.7647\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2029 - accuracy: 0.9332 - val_loss: 0.9106 - val_accuracy: 0.7873\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2176 - accuracy: 0.9332 - val_loss: 0.8805 - val_accuracy: 0.7783\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2013 - accuracy: 0.9298 - val_loss: 0.8285 - val_accuracy: 0.7964\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1696 - accuracy: 0.9581 - val_loss: 0.9627 - val_accuracy: 0.7738\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2120 - accuracy: 0.9320 - val_loss: 0.8694 - val_accuracy: 0.7828\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9434 - val_loss: 0.8964 - val_accuracy: 0.7873\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.9445 - val_loss: 0.9470 - val_accuracy: 0.8009\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1640 - accuracy: 0.9422 - val_loss: 0.9216 - val_accuracy: 0.7919\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1869 - accuracy: 0.9275 - val_loss: 0.9623 - val_accuracy: 0.8054\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2310 - accuracy: 0.9139 - val_loss: 0.9702 - val_accuracy: 0.7783\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2347 - accuracy: 0.9173 - val_loss: 0.7993 - val_accuracy: 0.8054\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2213 - accuracy: 0.9230 - val_loss: 0.8983 - val_accuracy: 0.7873\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 0.9468 - val_loss: 0.9243 - val_accuracy: 0.8054\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9456 - val_loss: 0.8876 - val_accuracy: 0.8009\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.9445 - val_loss: 0.8856 - val_accuracy: 0.7964\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1264 - accuracy: 0.9626 - val_loss: 0.9626 - val_accuracy: 0.8009\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9536 - val_loss: 0.8447 - val_accuracy: 0.8054\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1425 - accuracy: 0.9536 - val_loss: 0.8947 - val_accuracy: 0.8009\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9502 - val_loss: 0.8972 - val_accuracy: 0.8145\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9536 - val_loss: 1.0133 - val_accuracy: 0.7873\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1816 - accuracy: 0.9343 - val_loss: 0.9830 - val_accuracy: 0.7647\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9411 - val_loss: 0.8356 - val_accuracy: 0.8190\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9445 - val_loss: 0.9131 - val_accuracy: 0.7873\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9672 - val_loss: 0.9280 - val_accuracy: 0.8009\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1149 - accuracy: 0.9547 - val_loss: 0.9390 - val_accuracy: 0.7647\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9388 - val_loss: 1.0678 - val_accuracy: 0.7738\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2574 - accuracy: 0.9083 - val_loss: 1.0565 - val_accuracy: 0.7964\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9230 - val_loss: 0.9459 - val_accuracy: 0.8145\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1886 - accuracy: 0.9354 - val_loss: 1.0884 - val_accuracy: 0.7873\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1904 - accuracy: 0.9320 - val_loss: 1.0580 - val_accuracy: 0.7873\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1797 - accuracy: 0.9354 - val_loss: 0.9354 - val_accuracy: 0.7964\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9434 - val_loss: 0.9166 - val_accuracy: 0.8190\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9524 - val_loss: 0.9521 - val_accuracy: 0.7647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1652 - accuracy: 0.9366 - val_loss: 1.0030 - val_accuracy: 0.7919\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9524 - val_loss: 0.9156 - val_accuracy: 0.7873\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.9694 - val_loss: 0.8720 - val_accuracy: 0.8100\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9706 - val_loss: 0.9274 - val_accuracy: 0.8100\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9751 - val_loss: 1.0328 - val_accuracy: 0.8100\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9694 - val_loss: 0.9702 - val_accuracy: 0.8145\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9717 - val_loss: 1.1508 - val_accuracy: 0.7873\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1362 - accuracy: 0.9479 - val_loss: 0.9956 - val_accuracy: 0.7783\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9592 - val_loss: 1.0323 - val_accuracy: 0.7964\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9728 - val_loss: 1.1056 - val_accuracy: 0.8009\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0887 - accuracy: 0.9683 - val_loss: 1.0812 - val_accuracy: 0.8054\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9830 - val_loss: 1.0604 - val_accuracy: 0.7919\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9785 - val_loss: 1.0178 - val_accuracy: 0.7873\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.9694 - val_loss: 1.0010 - val_accuracy: 0.7692\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9785 - val_loss: 1.0710 - val_accuracy: 0.7692\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 1.0115 - val_accuracy: 0.8145\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.9874 - val_accuracy: 0.8009\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9762 - val_loss: 1.0352 - val_accuracy: 0.8145\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1059 - accuracy: 0.9592 - val_loss: 1.0450 - val_accuracy: 0.7692\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.9513 - val_loss: 1.0317 - val_accuracy: 0.8009\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1246 - accuracy: 0.9513 - val_loss: 1.2285 - val_accuracy: 0.7828\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9547 - val_loss: 1.0890 - val_accuracy: 0.8054\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 1.0818 - val_accuracy: 0.7828\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9728 - val_loss: 1.0422 - val_accuracy: 0.8054\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9706 - val_loss: 0.9255 - val_accuracy: 0.8054\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9626 - val_loss: 0.9588 - val_accuracy: 0.7873\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.9615 - val_loss: 1.0033 - val_accuracy: 0.8190\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9728 - val_loss: 0.9698 - val_accuracy: 0.8145\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9751 - val_loss: 1.0732 - val_accuracy: 0.7873\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9762 - val_loss: 1.1348 - val_accuracy: 0.8054\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9875 - val_loss: 1.0609 - val_accuracy: 0.8009\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 1.0020 - val_accuracy: 0.8100\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9841 - val_loss: 1.0780 - val_accuracy: 0.7919\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9785 - val_loss: 0.9896 - val_accuracy: 0.8100\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9683 - val_loss: 1.2113 - val_accuracy: 0.7783\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.9513 - val_loss: 1.1678 - val_accuracy: 0.7873\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 0.9513 - val_loss: 1.2646 - val_accuracy: 0.7647\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2080 - accuracy: 0.9332 - val_loss: 1.2228 - val_accuracy: 0.7783\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2499 - accuracy: 0.9128 - val_loss: 1.3370 - val_accuracy: 0.7647\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.9105 - val_loss: 1.1579 - val_accuracy: 0.7557\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2454 - accuracy: 0.9207 - val_loss: 1.0652 - val_accuracy: 0.8100\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9468 - val_loss: 1.1020 - val_accuracy: 0.8009\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3407 - accuracy: 0.7609\n",
      "[test loss, test accuracy]: [1.3406565189361572, 0.760869562625885]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Check Result\n",
    "y_pred_a = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_a, axis=1)\n",
    "\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ded1ce49",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_list = set(y_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_pred, y_test)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_list, yticklabels=class_list)\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix[0])):\n",
    "        if i == j:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='white')\n",
    "        else:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='black')\n",
    "            \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d440e015",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions.csv', np.hstack((y_test.reshape(-1, 1), y_pred.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ada0d7e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Mapping:\n",
      "{'bacterial_leaf_blight': 0, 'bacterial_leaf_streak': 1, 'bakanae': 2, 'brown_spot': 3, 'grassy_stunt_virus': 4, 'healthy_rice_plant': 5, 'narrow_brown_spot': 6, 'ragged_stunt_virus': 7, 'rice_blast': 8, 'rice_false_smut': 9, 'sheath_blight': 10, 'sheath_rot': 11, 'stem_rot': 12, 'tungro_virus': 13}\n"
     ]
    }
   ],
   "source": [
    "# Display the mapping between class names and encoded numbers\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\nClass Mapping:\")\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3359008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
