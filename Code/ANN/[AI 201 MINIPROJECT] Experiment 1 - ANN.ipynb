{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64653a26-b164-4036-93b5-be0f7358a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxiliaries (Importing Datafile, Checking Time)\n",
    "import os \n",
    "import time\n",
    "\n",
    "# Calculations\n",
    "import numpy as np\n",
    "\n",
    "# For Importing Data Files\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from skimage import color\n",
    "\n",
    "# For Image Pre-Processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979b03d-2172-4465-999b-1e65d282be22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create dataframe\n",
    "\n",
    "3 columns\n",
    "1. Disease Classification\n",
    "2. Image Name\n",
    "3. Image RGB Values (RGB Converted from BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce4c625-de79-4861-b12a-56db5eb4203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def create_dataframe_from_folders(root_folder):\n",
    "    # Initialize empty lists to store data for each column\n",
    "    folder_names = []\n",
    "    photo_names = []\n",
    "    photos = []\n",
    "\n",
    "    # Traverse through the root folder and its subfolders\n",
    "    for folder_name in sorted(os.listdir(root_folder)):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if the entry in the root folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for photo_name in sorted(os.listdir(folder_path), key=natural_sort_key):\n",
    "                # Photos are in common image formats (e.g., jpg, png)\n",
    "                if photo_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    photo_path = os.path.join(folder_path, photo_name)\n",
    "\n",
    "                    # Read image data using cv2\n",
    "                    image_data = cv2.imread(photo_path)\n",
    "\n",
    "                    # Convert BGR to RGB\n",
    "                    image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Append data to the lists\n",
    "                    folder_names.append(folder_name)\n",
    "                    photo_names.append(photo_name)\n",
    "                    photos.append(image_data_rgb)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'class': folder_names,\n",
    "        'img_name': photo_names,\n",
    "        'rgb': photos\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af7bde-ac77-45fa-8c61-7a53363109b4",
   "metadata": {},
   "source": [
    "Get data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f698915-bb74-4ec7-8ff1-606c6471d686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   class                img_name  \\\n",
      "0  bacterial_leaf_blight  BLB_multi_leaf (1).jpg   \n",
      "1  bacterial_leaf_blight  BLB_multi_leaf (2).jpg   \n",
      "2  bacterial_leaf_blight  BLB_multi_leaf (3).jpg   \n",
      "3  bacterial_leaf_blight  BLB_multi_leaf (4).jpg   \n",
      "4  bacterial_leaf_blight  BLB_multi_leaf (5).jpg   \n",
      "\n",
      "                                                 rgb  \n",
      "0  [[[115, 152, 47], [78, 113, 9], [116, 147, 43]...  \n",
      "1  [[[198, 218, 97], [190, 210, 89], [189, 208, 9...  \n",
      "2  [[[137, 176, 51], [166, 203, 64], [165, 200, 3...  \n",
      "3  [[[192, 212, 143], [201, 222, 157], [187, 206,...  \n",
      "4  [[[132, 176, 27], [135, 180, 27], [161, 206, 4...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "extra_resized_folder_path = r\"C:\\Users\\Josh\\000 Files\\003 Mengg AI\\01a 201 (AI)\\03 Mini-Project\\resized_raw_images (14 Classes)\"\n",
    "extra_resized = create_dataframe_from_folders(extra_resized_folder_path)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(extra_resized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5426b9d-5fe5-470e-95cd-b9bd72e1875a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Class Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be65000-1849-48e3-b646-93efd2758afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "bakanae                  100\n",
      "brown_spot               100\n",
      "grassy_stunt_virus       100\n",
      "healthy_rice_plant       100\n",
      "ragged_stunt_virus       100\n",
      "stem_rot                 100\n",
      "tungro_virus             100\n",
      "bacterial_leaf_streak     99\n",
      "rice_false_smut           99\n",
      "narrow_brown_spot         98\n",
      "rice_blast                98\n",
      "sheath_blight             98\n",
      "bacterial_leaf_blight     97\n",
      "sheath_rot                91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = extra_resized['class'].value_counts()\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac8225-3fe7-4259-a715-381055cfb61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d99ab4-0a06-495a-8af2-2d2ca69d19a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Texture Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef73441b-106f-4a76-af4a-30d0192a58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mahotas\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def compute_glcm_features(df):\n",
    "    df['gray'] = df['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2GRAY))\n",
    "    def calculate_glcm(gray_image):\n",
    "        # Compute GLCM using mahotas\n",
    "        glcm = mahotas.features.haralick(gray_image.astype(np.uint8), ignore_zeros=True)\n",
    "        return glcm.mean(axis=0)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gray_image = row['gray']\n",
    "        glcm_features = calculate_glcm(gray_image)\n",
    "        features.append(glcm_features)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Define meaningful column names for GLCM features\n",
    "    glcm_columns = [\n",
    "        'Angular Second Moment',\n",
    "        'Contrast',\n",
    "        'Correlation',\n",
    "        'Sum of Squares: Variance',\n",
    "        'Inverse Difference Moment',\n",
    "        'Sum Average',\n",
    "        'Sum Variance',\n",
    "        'Sum Entropy',\n",
    "        'Entropy',\n",
    "        'Difference Variance',\n",
    "        'Difference Entropy',\n",
    "        'Informational Measure of Correlation 1',\n",
    "        'Informational Measure of Correlation 2'\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with the new GLCM features and meaningful column names\n",
    "    glcm_df = pd.DataFrame(features, columns=[f'GLCM_{col}' for col in glcm_columns])\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, glcm_df], axis=1)\n",
    "\n",
    "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2b059a-fa17-4742-a4e9-61286361606a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 21.04 seconds\n"
     ]
    }
   ],
   "source": [
    "glcm = compute_glcm_features(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564a00a9-a6ed-4d71-b79b-82ded4744d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the first n columns\n",
    "f_glcm = glcm.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3555e8-efe3-4a70-8258-9bf9d11a2d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_Angular Second Moment</th>\n",
       "      <th>GLCM_Contrast</th>\n",
       "      <th>GLCM_Correlation</th>\n",
       "      <th>GLCM_Sum of Squares: Variance</th>\n",
       "      <th>GLCM_Inverse Difference Moment</th>\n",
       "      <th>GLCM_Sum Average</th>\n",
       "      <th>GLCM_Sum Variance</th>\n",
       "      <th>GLCM_Sum Entropy</th>\n",
       "      <th>GLCM_Entropy</th>\n",
       "      <th>GLCM_Difference Variance</th>\n",
       "      <th>GLCM_Difference Entropy</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 1</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>1876.058313</td>\n",
       "      <td>0.693690</td>\n",
       "      <td>3062.090566</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>281.006018</td>\n",
       "      <td>10372.303952</td>\n",
       "      <td>8.629042</td>\n",
       "      <td>14.243405</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>6.206143</td>\n",
       "      <td>-0.154215</td>\n",
       "      <td>0.950487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>1334.884861</td>\n",
       "      <td>0.797998</td>\n",
       "      <td>3303.508641</td>\n",
       "      <td>0.077155</td>\n",
       "      <td>276.277140</td>\n",
       "      <td>11879.149702</td>\n",
       "      <td>8.601060</td>\n",
       "      <td>14.082083</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>6.006272</td>\n",
       "      <td>-0.160813</td>\n",
       "      <td>0.952879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000140</td>\n",
       "      <td>1340.143870</td>\n",
       "      <td>0.744815</td>\n",
       "      <td>2625.859569</td>\n",
       "      <td>0.091972</td>\n",
       "      <td>293.873154</td>\n",
       "      <td>9163.294405</td>\n",
       "      <td>8.446153</td>\n",
       "      <td>13.764957</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>5.900897</td>\n",
       "      <td>-0.165284</td>\n",
       "      <td>0.954139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>1293.754229</td>\n",
       "      <td>0.776222</td>\n",
       "      <td>2890.458305</td>\n",
       "      <td>0.071097</td>\n",
       "      <td>289.332162</td>\n",
       "      <td>10268.078990</td>\n",
       "      <td>8.648174</td>\n",
       "      <td>14.226573</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>6.040155</td>\n",
       "      <td>-0.157107</td>\n",
       "      <td>0.952233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000101</td>\n",
       "      <td>1076.703851</td>\n",
       "      <td>0.693791</td>\n",
       "      <td>1757.932426</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>284.620945</td>\n",
       "      <td>5955.025853</td>\n",
       "      <td>8.284213</td>\n",
       "      <td>13.795743</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>5.881877</td>\n",
       "      <td>-0.134893</td>\n",
       "      <td>0.923023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_Angular Second Moment  GLCM_Contrast  GLCM_Correlation  \\\n",
       "0                    0.000093    1876.058313          0.693690   \n",
       "1                    0.000090    1334.884861          0.797998   \n",
       "2                    0.000140    1340.143870          0.744815   \n",
       "3                    0.000071    1293.754229          0.776222   \n",
       "4                    0.000101    1076.703851          0.693791   \n",
       "\n",
       "   GLCM_Sum of Squares: Variance  GLCM_Inverse Difference Moment  \\\n",
       "0                    3062.090566                        0.086892   \n",
       "1                    3303.508641                        0.077155   \n",
       "2                    2625.859569                        0.091972   \n",
       "3                    2890.458305                        0.071097   \n",
       "4                    1757.932426                        0.082002   \n",
       "\n",
       "   GLCM_Sum Average  GLCM_Sum Variance  GLCM_Sum Entropy  GLCM_Entropy  \\\n",
       "0        281.006018       10372.303952          8.629042     14.243405   \n",
       "1        276.277140       11879.149702          8.601060     14.082083   \n",
       "2        293.873154        9163.294405          8.446153     13.764957   \n",
       "3        289.332162       10268.078990          8.648174     14.226573   \n",
       "4        284.620945        5955.025853          8.284213     13.795743   \n",
       "\n",
       "   GLCM_Difference Variance  GLCM_Difference Entropy  \\\n",
       "0                  0.000072                 6.206143   \n",
       "1                  0.000079                 6.006272   \n",
       "2                  0.000095                 5.900897   \n",
       "3                  0.000073                 6.040155   \n",
       "4                  0.000086                 5.881877   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 1  \\\n",
       "0                                    -0.154215   \n",
       "1                                    -0.160813   \n",
       "2                                    -0.165284   \n",
       "3                                    -0.157107   \n",
       "4                                    -0.134893   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 2  \n",
       "0                                     0.950487  \n",
       "1                                     0.952879  \n",
       "2                                     0.954139  \n",
       "3                                     0.952233  \n",
       "4                                     0.923023  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_glcm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ad4b-7eb0-4110-bcb4-6e592e28d837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94ca35f-9437-4b01-8009-1a0eed2ae870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354c8451-629c-447d-beef-076db3311418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def values(dataframe):\n",
    "    # Ensure the 'rgb' column exists in the dataframe\n",
    "    dataframe['hsv'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2HSV))\n",
    "    #dataframe['hsi'] = dataframe['rgb'].apply(lambda x: color.rgb2hsi(np.uint8(x)))\n",
    "    dataframe['lab'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    dataframe['red'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,0])\n",
    "    dataframe['green'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,1])\n",
    "    dataframe['blue'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,2])\n",
    "    \n",
    "    dataframe['hue_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,0])\n",
    "    dataframe['saturation_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,1])\n",
    "    dataframe['value_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,2])\n",
    "    \n",
    "    #dataframe['hue_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,0])\n",
    "    #dataframe['saturation_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,1])\n",
    "    #dataframe['intensity_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,2])\n",
    "    \n",
    "    dataframe['lightness'] = dataframe['lab'].apply(lambda lab: lab[:, :, 0])\n",
    "    dataframe['a'] = dataframe['lab'].apply(lambda lab: lab[:, :, 1])\n",
    "    dataframe['b'] = dataframe['lab'].apply(lambda lab: lab[:, :, 2])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5082c1-48a7-4a77-ae63-d276523f8173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_bins_to_dataframe(dataframe, column_name, num_bins):\n",
    "    # Extract the specified column\n",
    "    original_column = dataframe[column_name]\n",
    "\n",
    "    # Define bin edges based on the min and max values in the matrices\n",
    "    min_value = np.min([np.min(matrix) for matrix in original_column])\n",
    "    max_value = np.max([np.max(matrix) for matrix in original_column])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "    # Create column names for the bins\n",
    "    bin_column_names = [f'{column_name}_{i}' for i in range(num_bins)]\n",
    "\n",
    "    # Iterate through each matrix in the original column\n",
    "    for i, matrix in enumerate(original_column):\n",
    "        # Digitize each element in the matrix into the corresponding bin\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "\n",
    "        # Count the occurrences of each bin index\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        # Add new columns to the DataFrame for each bin\n",
    "        for j, bin_column_name in enumerate(bin_column_names):\n",
    "            dataframe.loc[i, bin_column_name] = bin_counts[j]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb1fba-0704-4f4b-b34a-2e2ef1cbd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = values(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ab83c9-fc0e-4cff-9869-3fa8c12e4469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_bins_dataframe(dataframe, col, num_bins):\n",
    "    bins_dataframe = pd.DataFrame()\n",
    "\n",
    "    #print(col)\n",
    "    min_value = np.min([np.min(matrix) for matrix in dataframe[col]])\n",
    "    max_value = np.max([np.max(matrix) for matrix in dataframe[col]])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "    bin_column_names = [f'{col}_{i}' for i in range(1, num_bins + 1)]\n",
    "\n",
    "    for matrix in dataframe[col]:\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        bins_dataframe = pd.concat([bins_dataframe, pd.DataFrame(bin_counts).transpose()], axis=0, ignore_index=True)\n",
    "\n",
    "    bins_dataframe.columns = bin_column_names\n",
    "        \n",
    "    return bins_dataframe\n",
    "\n",
    "def hist_features(df, cols, bins):\n",
    "    complete_bins = pd.DataFrame()\n",
    "\n",
    "    for col in cols:\n",
    "        col_bins = create_bins_dataframe(df, col, bins)\n",
    "        complete_bins = pd.concat([complete_bins, col_bins], axis=1)\n",
    "\n",
    "    return complete_bins\n",
    "\n",
    "cols = ['red', 'green', 'blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef1f4f2-7b29-4783-80bb-942502c3f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_histogram = hist_features(channels, cols, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200b7499-7dd8-4545-a930-7e28dd715d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>red_10</th>\n",
       "      <th>...</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "      <th>b_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>223</td>\n",
       "      <td>231</td>\n",
       "      <td>305</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>210</td>\n",
       "      <td>261</td>\n",
       "      <td>308</td>\n",
       "      <td>349</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>358</td>\n",
       "      <td>383</td>\n",
       "      <td>554</td>\n",
       "      <td>...</td>\n",
       "      <td>541</td>\n",
       "      <td>556</td>\n",
       "      <td>187</td>\n",
       "      <td>98</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>290</td>\n",
       "      <td>337</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>454</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>1417</td>\n",
       "      <td>1133</td>\n",
       "      <td>195</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_1  red_2  red_3  red_4  red_5  red_6  red_7  red_8  red_9  red_10  ...  \\\n",
       "0     19     47     93    143    223    231    305    314    330     432  ...   \n",
       "1    153    210    261    308    349    391    392    358    383     554  ...   \n",
       "2     14     35     62    145    205    290    337    325    338     454  ...   \n",
       "3     14     14     40     53     89    106    194    242    267     436  ...   \n",
       "4      0      1      3      4      1      6      6      9      8      31  ...   \n",
       "\n",
       "   b_73  b_74  b_75  b_76  b_77  b_78  b_79  b_80  b_81  b_82  \n",
       "0    73    27     0     0     0     0     0     0     0     0  \n",
       "1   541   556   187    98    47    33     0     0     0     0  \n",
       "2   157    51     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4  1417  1133   195    42     8     1     0     0     0     0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_histogram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58cb8f-65ac-44fc-99e6-58e42abfabfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Color Moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b0823e-3e5b-4f1c-95a6-8b8b4cc97e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "\n",
    "def color_moments(dataframe, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        mean_values = []\n",
    "        variance_values = []\n",
    "        kurtosis_values = []\n",
    "        skewness_values = []\n",
    "\n",
    "        for img in dataframe[col]:\n",
    "            # 'img' is a 3D numpy array representing an RGB image\n",
    "            # Calculate statistics for each image\n",
    "            mean_channel = np.mean(img, axis=(0, 1))\n",
    "            variance_channel = np.var(img, axis=(0, 1))\n",
    "            kurtosis_channel = kurtosis(img, axis=(0, 1))\n",
    "            skewness_channel = skew(img, axis=(0, 1))\n",
    "\n",
    "            # Append values to respective lists\n",
    "            mean_values.append(mean_channel)\n",
    "            variance_values.append(variance_channel)\n",
    "            kurtosis_values.append(kurtosis_channel)\n",
    "            skewness_values.append(skewness_channel)\n",
    "\n",
    "        # Add the new columns to the DataFrame with channel names\n",
    "        for i in range(img.shape[2]):  # 'img' has shape (height, width, channels)\n",
    "            dataframe[f'{col}_channel_{i}_mean'] = [x[i] for x in mean_values]\n",
    "            dataframe[f'{col}_channel_{i}_variance'] = [x[i] for x in variance_values]\n",
    "            dataframe[f'{col}_channel_{i}_kurtosis'] = [x[i] for x in kurtosis_values]\n",
    "            dataframe[f'{col}_channel_{i}_skewness'] = [x[i] for x in skewness_values]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cc9e6e-ddcb-41fe-aa4b-72e3f44afc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb\n",
      "hsv\n",
      "lab\n"
     ]
    }
   ],
   "source": [
    "color_df = color_moments(extra_resized, ['rgb','hsv','lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c245d80-93b2-4cc8-82a3-77f40ab9b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_color = color_df.drop(columns=['class','img_name','rgb','gray','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52a436e-88b8-43bc-b1d7-b17b428f0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>rgb_channel_2_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "      <th>lab_channel_2_skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.110013</td>\n",
       "      <td>3078.218207</td>\n",
       "      <td>-0.689453</td>\n",
       "      <td>-0.192670</td>\n",
       "      <td>157.315011</td>\n",
       "      <td>3449.301597</td>\n",
       "      <td>-0.484632</td>\n",
       "      <td>-0.518085</td>\n",
       "      <td>67.831274</td>\n",
       "      <td>2087.782836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296129</td>\n",
       "      <td>-0.606758</td>\n",
       "      <td>106.950853</td>\n",
       "      <td>61.335754</td>\n",
       "      <td>0.410354</td>\n",
       "      <td>0.917856</td>\n",
       "      <td>169.947226</td>\n",
       "      <td>203.966363</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>-0.576146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.208227</td>\n",
       "      <td>3961.755789</td>\n",
       "      <td>-1.130258</td>\n",
       "      <td>-0.302681</td>\n",
       "      <td>158.333586</td>\n",
       "      <td>3558.081163</td>\n",
       "      <td>-0.908913</td>\n",
       "      <td>-0.458059</td>\n",
       "      <td>50.368921</td>\n",
       "      <td>1453.704717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781886</td>\n",
       "      <td>-0.534726</td>\n",
       "      <td>103.516083</td>\n",
       "      <td>21.999662</td>\n",
       "      <td>2.755215</td>\n",
       "      <td>1.327478</td>\n",
       "      <td>177.711097</td>\n",
       "      <td>198.029258</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>-0.735196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143.534598</td>\n",
       "      <td>2684.064771</td>\n",
       "      <td>-0.122034</td>\n",
       "      <td>-0.726785</td>\n",
       "      <td>163.988122</td>\n",
       "      <td>3032.684210</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>-0.932985</td>\n",
       "      <td>67.333745</td>\n",
       "      <td>1393.034182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395657</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>106.869300</td>\n",
       "      <td>39.706570</td>\n",
       "      <td>1.180393</td>\n",
       "      <td>1.184484</td>\n",
       "      <td>173.509228</td>\n",
       "      <td>201.620730</td>\n",
       "      <td>0.534828</td>\n",
       "      <td>-0.842716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.806521</td>\n",
       "      <td>3150.853829</td>\n",
       "      <td>-0.752603</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>155.817223</td>\n",
       "      <td>2935.205771</td>\n",
       "      <td>-0.687641</td>\n",
       "      <td>-0.282174</td>\n",
       "      <td>112.783462</td>\n",
       "      <td>2356.163989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573437</td>\n",
       "      <td>-0.355013</td>\n",
       "      <td>112.668666</td>\n",
       "      <td>26.981995</td>\n",
       "      <td>2.443752</td>\n",
       "      <td>0.798156</td>\n",
       "      <td>148.112783</td>\n",
       "      <td>56.290194</td>\n",
       "      <td>1.918221</td>\n",
       "      <td>-0.305414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133.956593</td>\n",
       "      <td>1928.268962</td>\n",
       "      <td>-0.601913</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>165.174087</td>\n",
       "      <td>1995.183999</td>\n",
       "      <td>-0.653920</td>\n",
       "      <td>-0.250057</td>\n",
       "      <td>46.036372</td>\n",
       "      <td>1525.296728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566688</td>\n",
       "      <td>-0.252408</td>\n",
       "      <td>101.051419</td>\n",
       "      <td>77.759832</td>\n",
       "      <td>0.647577</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>180.711256</td>\n",
       "      <td>190.856598</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>-0.751957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgb_channel_0_mean  rgb_channel_0_variance  rgb_channel_0_kurtosis  \\\n",
       "0          135.110013             3078.218207               -0.689453   \n",
       "1          132.208227             3961.755789               -1.130258   \n",
       "2          143.534598             2684.064771               -0.122034   \n",
       "3          134.806521             3150.853829               -0.752603   \n",
       "4          133.956593             1928.268962               -0.601913   \n",
       "\n",
       "   rgb_channel_0_skewness  rgb_channel_1_mean  rgb_channel_1_variance  \\\n",
       "0               -0.192670          157.315011             3449.301597   \n",
       "1               -0.302681          158.333586             3558.081163   \n",
       "2               -0.726785          163.988122             3032.684210   \n",
       "3                0.011988          155.817223             2935.205771   \n",
       "4                0.189324          165.174087             1995.183999   \n",
       "\n",
       "   rgb_channel_1_kurtosis  rgb_channel_1_skewness  rgb_channel_2_mean  \\\n",
       "0               -0.484632               -0.518085           67.831274   \n",
       "1               -0.908913               -0.458059           50.368921   \n",
       "2                0.098623               -0.932985           67.333745   \n",
       "3               -0.687641               -0.282174          112.783462   \n",
       "4               -0.653920               -0.250057           46.036372   \n",
       "\n",
       "   rgb_channel_2_variance  ...  lab_channel_0_kurtosis  \\\n",
       "0             2087.782836  ...               -0.296129   \n",
       "1             1453.704717  ...               -0.781886   \n",
       "2             1393.034182  ...                0.395657   \n",
       "3             2356.163989  ...               -0.573437   \n",
       "4             1525.296728  ...               -0.566688   \n",
       "\n",
       "   lab_channel_0_skewness  lab_channel_1_mean  lab_channel_1_variance  \\\n",
       "0               -0.606758          106.950853               61.335754   \n",
       "1               -0.534726          103.516083               21.999662   \n",
       "2               -1.041771          106.869300               39.706570   \n",
       "3               -0.355013          112.668666               26.981995   \n",
       "4               -0.252408          101.051419               77.759832   \n",
       "\n",
       "   lab_channel_1_kurtosis  lab_channel_1_skewness  lab_channel_2_mean  \\\n",
       "0                0.410354                0.917856          169.947226   \n",
       "1                2.755215                1.327478          177.711097   \n",
       "2                1.180393                1.184484          173.509228   \n",
       "3                2.443752                0.798156          148.112783   \n",
       "4                0.647577                1.165816          180.711256   \n",
       "\n",
       "   lab_channel_2_variance  lab_channel_2_kurtosis  lab_channel_2_skewness  \n",
       "0              203.966363                0.049806               -0.576146  \n",
       "1              198.029258                0.350495               -0.735196  \n",
       "2              201.620730                0.534828               -0.842716  \n",
       "3               56.290194                1.918221               -0.305414  \n",
       "4              190.856598                0.315457               -0.751957  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_color.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374ff69-1bee-49c9-a127-38bf7b2154fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Zernike Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2e3d8b-9bcb-4314-8271-fbda88d99c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas.features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def zernike(df, zernike_order):\n",
    "    features_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        gray_img = row['gray']\n",
    "\n",
    "        # Check if the image is grayscale\n",
    "        if len(gray_img.shape) == 2:\n",
    "            # If grayscale, compute Zernike moments directly\n",
    "            moments = mahotas.features.zernike_moments(gray_img, radius=zernike_order)\n",
    "        else:\n",
    "            raise ValueError(\"Input image must be grayscale.\")\n",
    "\n",
    "        features_list.append(moments)\n",
    "\n",
    "    # Determine the number of features per image\n",
    "    num_features_per_image = len(features_list[0])\n",
    "\n",
    "    # Add features to the DataFrame\n",
    "    feature_columns = [f'feature_{i}' for i in range(num_features_per_image)]\n",
    "    df_features = pd.DataFrame(features_list, columns=feature_columns)\n",
    "    df_result = pd.concat([df, df_features], axis=1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2839e315-3874-4df5-9d76-5f159e11d6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.085352</td>\n",
       "      <td>0.096424</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>0.047294</td>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>0.021023</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.030770</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.047826</td>\n",
       "      <td>0.057547</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.035470</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.037121</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.044010</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>0.050413</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.056392</td>\n",
       "      <td>0.064779</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048771</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    0.31831   0.017224   0.085352   0.096424   0.007132   0.019454   \n",
       "1    0.31831   0.014304   0.028368   0.037181   0.013888   0.019413   \n",
       "2    0.31831   0.079290   0.030770   0.009481   0.047826   0.057547   \n",
       "3    0.31831   0.037962   0.004782   0.037121   0.070988   0.044010   \n",
       "4    0.31831   0.008223   0.041976   0.050413   0.029785   0.035719   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0   0.035195   0.047294   0.034389   0.012664  ...    0.021457    0.009277   \n",
       "1   0.032812   0.021023   0.036471   0.003854  ...    0.019798    0.021939   \n",
       "2   0.014013   0.021884   0.035470   0.021808  ...    0.028761    0.049967   \n",
       "3   0.004336   0.021578   0.015647   0.008096  ...    0.017136    0.012084   \n",
       "4   0.045422   0.056392   0.064779   0.029646  ...    0.025135    0.003060   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.024865    0.004817    0.017575    0.003713    0.003742    0.016868   \n",
       "1    0.024250    0.033492    0.027907    0.000967    0.009835    0.017213   \n",
       "2    0.039179    0.039791    0.023068    0.031944    0.021562    0.009072   \n",
       "3    0.020084    0.021049    0.013913    0.004487    0.017935    0.029116   \n",
       "4    0.024900    0.048771    0.041041    0.005773    0.034733    0.012531   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.031700    0.035992  \n",
       "1    0.006593    0.008411  \n",
       "2    0.019779    0.024128  \n",
       "3    0.023423    0.023256  \n",
       "4    0.014290    0.004188  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zernike_df = zernike(extra_resized, 10)\n",
    "f_zernike = zernike_df.iloc[:, 51:]\n",
    "f_zernike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f9f14-f5c1-49e8-bc81-0ff472678dd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Legendre Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c31faf-4303-4c2c-9116-db4207ca5f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extra_resized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11c6966-8fce-4fe6-b283-0ae5a249459b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_input = extra_resized.drop(columns=['class','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])\n",
    "l_input = l_input.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797a48fb-2cbb-4377-a2c7-c851bf96b9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>rgb</th>\n",
       "      <th>gray</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLB_multi_leaf (1).jpg</td>\n",
       "      <td>[[[115, 152, 47], [78, 113, 9], [116, 147, 43]...</td>\n",
       "      <td>[[129, 91, 126, 196, 208, 157, 175, 128, 114, ...</td>\n",
       "      <td>135.110013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLB_multi_leaf (2).jpg</td>\n",
       "      <td>[[[198, 218, 97], [190, 210, 89], [189, 208, 9...</td>\n",
       "      <td>[[198, 190, 189, 183, 189, 189, 187, 187, 189,...</td>\n",
       "      <td>132.208227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLB_multi_leaf (3).jpg</td>\n",
       "      <td>[[[137, 176, 51], [166, 203, 64], [165, 200, 3...</td>\n",
       "      <td>[[150, 176, 171, 177, 193, 187, 142, 136, 135,...</td>\n",
       "      <td>143.534598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLB_multi_leaf (4).jpg</td>\n",
       "      <td>[[[192, 212, 143], [201, 222, 157], [187, 206,...</td>\n",
       "      <td>[[198, 208, 194, 198, 196, 159, 143, 145, 165,...</td>\n",
       "      <td>134.806521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLB_multi_leaf (5).jpg</td>\n",
       "      <td>[[[132, 176, 27], [135, 180, 27], [161, 206, 4...</td>\n",
       "      <td>[[146, 149, 174, 126, 153, 153, 185, 201, 210,...</td>\n",
       "      <td>133.956593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 img_name                                                rgb  \\\n",
       "0  BLB_multi_leaf (1).jpg  [[[115, 152, 47], [78, 113, 9], [116, 147, 43]...   \n",
       "1  BLB_multi_leaf (2).jpg  [[[198, 218, 97], [190, 210, 89], [189, 208, 9...   \n",
       "2  BLB_multi_leaf (3).jpg  [[[137, 176, 51], [166, 203, 64], [165, 200, 3...   \n",
       "3  BLB_multi_leaf (4).jpg  [[[192, 212, 143], [201, 222, 157], [187, 206,...   \n",
       "4  BLB_multi_leaf (5).jpg  [[[132, 176, 27], [135, 180, 27], [161, 206, 4...   \n",
       "\n",
       "                                                gray  rgb_channel_0_mean  \n",
       "0  [[129, 91, 126, 196, 208, 157, 175, 128, 114, ...          135.110013  \n",
       "1  [[198, 190, 189, 183, 189, 189, 187, 187, 189,...          132.208227  \n",
       "2  [[150, 176, 171, 177, 193, 187, 142, 136, 135,...          143.534598  \n",
       "3  [[198, 208, 194, 198, 196, 159, 143, 145, 165,...          134.806521  \n",
       "4  [[146, 149, 174, 126, 153, 153, 185, 201, 210,...          133.956593  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac178d0-3ed3-4c52-a778-5ae124e3d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.special import legendre\n",
    "\n",
    "def compute_legendre_features(rgb_image, degree):\n",
    "    # Get V channel from RGB image\n",
    "    v_channel = rgb_image[:, :, 2]\n",
    "\n",
    "    # Define x and y coordinates\n",
    "    x_size, y_size = v_channel.shape\n",
    "    x = np.linspace(-1, 1, x_size)\n",
    "    y = np.linspace(-1, 1, y_size)\n",
    "\n",
    "    # Compute Legendre features for the V channel\n",
    "    legendre_features = np.zeros((degree + 1, degree + 1))\n",
    "\n",
    "    for j in range(degree + 1):\n",
    "        for k in range(degree + 1):\n",
    "            legendre_features[j, k] = np.sum(v_channel * legendre(j)(x) * legendre(k)(y))\n",
    "\n",
    "    return legendre_features.flatten()\n",
    "\n",
    "def add_legendre(df, degree):\n",
    "    # Create a new DataFrame for Legendre features\n",
    "    legendre_columns = [f'v_legendre_{i}_{j}' for i in range(degree + 1) for j in range(degree + 1)]\n",
    "    legendre_df = pd.DataFrame(df['rgb'].apply(lambda rgb: compute_legendre_features(rgb, degree)).values.tolist(), columns=legendre_columns)\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, legendre_df], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43846dc1-14e3-448d-adc4-a22e38c851ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "legendre_df = add_legendre(l_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74b7ce3-9c49-42a7-95d2-ea2df961247b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_legendre_0_0</th>\n",
       "      <th>v_legendre_0_1</th>\n",
       "      <th>v_legendre_0_2</th>\n",
       "      <th>v_legendre_0_3</th>\n",
       "      <th>v_legendre_0_4</th>\n",
       "      <th>v_legendre_0_5</th>\n",
       "      <th>v_legendre_0_6</th>\n",
       "      <th>v_legendre_0_7</th>\n",
       "      <th>v_legendre_0_8</th>\n",
       "      <th>v_legendre_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>v_legendre_10_1</th>\n",
       "      <th>v_legendre_10_2</th>\n",
       "      <th>v_legendre_10_3</th>\n",
       "      <th>v_legendre_10_4</th>\n",
       "      <th>v_legendre_10_5</th>\n",
       "      <th>v_legendre_10_6</th>\n",
       "      <th>v_legendre_10_7</th>\n",
       "      <th>v_legendre_10_8</th>\n",
       "      <th>v_legendre_10_9</th>\n",
       "      <th>v_legendre_10_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3403502.0</td>\n",
       "      <td>97362.493274</td>\n",
       "      <td>-48201.759416</td>\n",
       "      <td>-43493.535531</td>\n",
       "      <td>-7187.545250</td>\n",
       "      <td>-13629.967522</td>\n",
       "      <td>26794.954058</td>\n",
       "      <td>-16840.577069</td>\n",
       "      <td>-19979.273476</td>\n",
       "      <td>3169.619967</td>\n",
       "      <td>...</td>\n",
       "      <td>11979.555139</td>\n",
       "      <td>6950.403894</td>\n",
       "      <td>-1337.870389</td>\n",
       "      <td>10980.581080</td>\n",
       "      <td>-2731.321916</td>\n",
       "      <td>13832.668995</td>\n",
       "      <td>-4770.100418</td>\n",
       "      <td>6167.284262</td>\n",
       "      <td>4327.878377</td>\n",
       "      <td>171054.141659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2527311.0</td>\n",
       "      <td>103013.053812</td>\n",
       "      <td>-36361.603672</td>\n",
       "      <td>5917.770393</td>\n",
       "      <td>47863.129349</td>\n",
       "      <td>1575.078268</td>\n",
       "      <td>12099.674282</td>\n",
       "      <td>-3201.383018</td>\n",
       "      <td>18315.225460</td>\n",
       "      <td>1422.844543</td>\n",
       "      <td>...</td>\n",
       "      <td>-821.672825</td>\n",
       "      <td>16762.645859</td>\n",
       "      <td>2097.910709</td>\n",
       "      <td>12284.262029</td>\n",
       "      <td>195.439018</td>\n",
       "      <td>20480.883830</td>\n",
       "      <td>3132.492664</td>\n",
       "      <td>11516.628122</td>\n",
       "      <td>8400.271678</td>\n",
       "      <td>134299.780209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3378538.0</td>\n",
       "      <td>57117.757848</td>\n",
       "      <td>-80632.660661</td>\n",
       "      <td>-510.363287</td>\n",
       "      <td>11451.263244</td>\n",
       "      <td>-12619.841113</td>\n",
       "      <td>-28828.907259</td>\n",
       "      <td>-769.368737</td>\n",
       "      <td>27917.794633</td>\n",
       "      <td>-6883.608118</td>\n",
       "      <td>...</td>\n",
       "      <td>3963.350675</td>\n",
       "      <td>18954.699088</td>\n",
       "      <td>-2074.126958</td>\n",
       "      <td>8085.322444</td>\n",
       "      <td>1051.648198</td>\n",
       "      <td>8771.579378</td>\n",
       "      <td>-2117.981725</td>\n",
       "      <td>3647.296353</td>\n",
       "      <td>5448.970980</td>\n",
       "      <td>164009.682234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5659023.0</td>\n",
       "      <td>-217617.215247</td>\n",
       "      <td>39749.222928</td>\n",
       "      <td>-6034.575324</td>\n",
       "      <td>13640.673159</td>\n",
       "      <td>21378.007074</td>\n",
       "      <td>44068.112251</td>\n",
       "      <td>-24151.624353</td>\n",
       "      <td>14049.614456</td>\n",
       "      <td>-33151.322155</td>\n",
       "      <td>...</td>\n",
       "      <td>-4619.286498</td>\n",
       "      <td>15514.090473</td>\n",
       "      <td>-6651.294307</td>\n",
       "      <td>31327.480610</td>\n",
       "      <td>553.852950</td>\n",
       "      <td>28293.237294</td>\n",
       "      <td>-4090.823341</td>\n",
       "      <td>27115.154433</td>\n",
       "      <td>-18929.538381</td>\n",
       "      <td>296838.144091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2309921.0</td>\n",
       "      <td>-148810.686099</td>\n",
       "      <td>-37569.159223</td>\n",
       "      <td>52055.054845</td>\n",
       "      <td>44925.442955</td>\n",
       "      <td>-23770.114279</td>\n",
       "      <td>17043.186742</td>\n",
       "      <td>11900.041479</td>\n",
       "      <td>1297.065850</td>\n",
       "      <td>-35581.018742</td>\n",
       "      <td>...</td>\n",
       "      <td>-9263.364484</td>\n",
       "      <td>11693.901946</td>\n",
       "      <td>-7594.119586</td>\n",
       "      <td>7040.301359</td>\n",
       "      <td>-2945.920523</td>\n",
       "      <td>20936.096634</td>\n",
       "      <td>1642.000010</td>\n",
       "      <td>5613.007761</td>\n",
       "      <td>-10798.603049</td>\n",
       "      <td>122542.843959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v_legendre_0_0  v_legendre_0_1  v_legendre_0_2  v_legendre_0_3  \\\n",
       "0       3403502.0    97362.493274   -48201.759416   -43493.535531   \n",
       "1       2527311.0   103013.053812   -36361.603672     5917.770393   \n",
       "2       3378538.0    57117.757848   -80632.660661     -510.363287   \n",
       "3       5659023.0  -217617.215247    39749.222928    -6034.575324   \n",
       "4       2309921.0  -148810.686099   -37569.159223    52055.054845   \n",
       "\n",
       "   v_legendre_0_4  v_legendre_0_5  v_legendre_0_6  v_legendre_0_7  \\\n",
       "0    -7187.545250   -13629.967522    26794.954058   -16840.577069   \n",
       "1    47863.129349     1575.078268    12099.674282    -3201.383018   \n",
       "2    11451.263244   -12619.841113   -28828.907259     -769.368737   \n",
       "3    13640.673159    21378.007074    44068.112251   -24151.624353   \n",
       "4    44925.442955   -23770.114279    17043.186742    11900.041479   \n",
       "\n",
       "   v_legendre_0_8  v_legendre_0_9  ...  v_legendre_10_1  v_legendre_10_2  \\\n",
       "0   -19979.273476     3169.619967  ...     11979.555139      6950.403894   \n",
       "1    18315.225460     1422.844543  ...      -821.672825     16762.645859   \n",
       "2    27917.794633    -6883.608118  ...      3963.350675     18954.699088   \n",
       "3    14049.614456   -33151.322155  ...     -4619.286498     15514.090473   \n",
       "4     1297.065850   -35581.018742  ...     -9263.364484     11693.901946   \n",
       "\n",
       "   v_legendre_10_3  v_legendre_10_4  v_legendre_10_5  v_legendre_10_6  \\\n",
       "0     -1337.870389     10980.581080     -2731.321916     13832.668995   \n",
       "1      2097.910709     12284.262029       195.439018     20480.883830   \n",
       "2     -2074.126958      8085.322444      1051.648198      8771.579378   \n",
       "3     -6651.294307     31327.480610       553.852950     28293.237294   \n",
       "4     -7594.119586      7040.301359     -2945.920523     20936.096634   \n",
       "\n",
       "   v_legendre_10_7  v_legendre_10_8  v_legendre_10_9  v_legendre_10_10  \n",
       "0     -4770.100418      6167.284262      4327.878377     171054.141659  \n",
       "1      3132.492664     11516.628122      8400.271678     134299.780209  \n",
       "2     -2117.981725      3647.296353      5448.970980     164009.682234  \n",
       "3     -4090.823341     27115.154433    -18929.538381     296838.144091  \n",
       "4      1642.000010      5613.007761    -10798.603049     122542.843959  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_legendre = legendre_df.iloc[:, 4:]\n",
    "f_legendre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bb6a4-6f30-4f3c-8b50-0bad0e8b6c75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Complete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5931a6-4d94-44df-8c1a-82076732f0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with just the selected column\n",
    "classes = pd.DataFrame(extra_resized['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5002378-98b0-4b70-ba29-a07ba57764f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#complete_features = pd.concat([classes,f_color,f_histogram, f_glcm], axis=1)\n",
    "complete_features = pd.concat([classes,f_histogram, f_glcm, f_color, f_legendre, f_zernike], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3453770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_features.to_csv('complete_features.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "060e531f-0a6e-455b-8dbf-07ca777d8c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>223</td>\n",
       "      <td>231</td>\n",
       "      <td>305</td>\n",
       "      <td>314</td>\n",
       "      <td>330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>153</td>\n",
       "      <td>210</td>\n",
       "      <td>261</td>\n",
       "      <td>308</td>\n",
       "      <td>349</td>\n",
       "      <td>391</td>\n",
       "      <td>392</td>\n",
       "      <td>358</td>\n",
       "      <td>383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>290</td>\n",
       "      <td>337</td>\n",
       "      <td>325</td>\n",
       "      <td>338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.039791</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.048771</td>\n",
       "      <td>0.041041</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.004188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  red_1  red_2  red_3  red_4  red_5  red_6  red_7  \\\n",
       "0  bacterial_leaf_blight     19     47     93    143    223    231    305   \n",
       "1  bacterial_leaf_blight    153    210    261    308    349    391    392   \n",
       "2  bacterial_leaf_blight     14     35     62    145    205    290    337   \n",
       "3  bacterial_leaf_blight     14     14     40     53     89    106    194   \n",
       "4  bacterial_leaf_blight      0      1      3      4      1      6      6   \n",
       "\n",
       "   red_8  red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0    314    330  ...    0.021457    0.009277    0.024865    0.004817   \n",
       "1    358    383  ...    0.019798    0.021939    0.024250    0.033492   \n",
       "2    325    338  ...    0.028761    0.049967    0.039179    0.039791   \n",
       "3    242    267  ...    0.017136    0.012084    0.020084    0.021049   \n",
       "4      9      8  ...    0.025135    0.003060    0.024900    0.048771   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.017575    0.003713    0.003742    0.016868    0.031700    0.035992  \n",
       "1    0.027907    0.000967    0.009835    0.017213    0.006593    0.008411  \n",
       "2    0.023068    0.031944    0.021562    0.009072    0.019779    0.024128  \n",
       "3    0.013913    0.004487    0.017935    0.029116    0.023423    0.023256  \n",
       "4    0.041041    0.005773    0.034733    0.012531    0.014290    0.004188  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93653fd4-c7c1-4763-ab89-2102d2f29c4c",
   "metadata": {},
   "source": [
    "# Data Normalization and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80096471-c274-4870-bea1-05b14edc651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe(df):\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Extract numerical columns (only numerical columns need normalization)\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply normalization to each numerical column\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b235b92a-228e-4021-975a-b860cafec988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>0.071804</td>\n",
       "      <td>0.076584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.067411</td>\n",
       "      <td>0.171821</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.110094</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>0.102434</td>\n",
       "      <td>0.202999</td>\n",
       "      <td>0.182089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149359</td>\n",
       "      <td>0.163611</td>\n",
       "      <td>0.167420</td>\n",
       "      <td>0.250202</td>\n",
       "      <td>0.175125</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.104561</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>0.040017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>0.046317</td>\n",
       "      <td>0.074320</td>\n",
       "      <td>0.078440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217850</td>\n",
       "      <td>0.376573</td>\n",
       "      <td>0.274281</td>\n",
       "      <td>0.297571</td>\n",
       "      <td>0.144669</td>\n",
       "      <td>0.227274</td>\n",
       "      <td>0.103086</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.125273</td>\n",
       "      <td>0.120976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129016</td>\n",
       "      <td>0.088736</td>\n",
       "      <td>0.137602</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>0.031712</td>\n",
       "      <td>0.085532</td>\n",
       "      <td>0.177860</td>\n",
       "      <td>0.149036</td>\n",
       "      <td>0.116484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190142</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.172070</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.040872</td>\n",
       "      <td>0.166836</td>\n",
       "      <td>0.075724</td>\n",
       "      <td>0.089486</td>\n",
       "      <td>0.018264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class     red_1     red_2     red_3     red_4     red_5  \\\n",
       "0  bacterial_leaf_blight  0.000995  0.003872  0.009432  0.006509  0.034435   \n",
       "1  bacterial_leaf_blight  0.008011  0.017300  0.026471  0.014019  0.053891   \n",
       "2  bacterial_leaf_blight  0.000733  0.002883  0.006288  0.006600  0.031655   \n",
       "3  bacterial_leaf_blight  0.000733  0.001153  0.004057  0.002412  0.013743   \n",
       "4  bacterial_leaf_blight  0.000000  0.000082  0.000304  0.000182  0.000154   \n",
       "\n",
       "      red_6     red_7     red_8     red_9  ...  feature_15  feature_16  \\\n",
       "0  0.020301  0.041919  0.071804  0.076584  ...    0.162035    0.067411   \n",
       "1  0.034362  0.053876  0.081866  0.088884  ...    0.149359    0.163611   \n",
       "2  0.025486  0.046317  0.074320  0.078440  ...    0.217850    0.376573   \n",
       "3  0.009315  0.026663  0.055340  0.061963  ...    0.129016    0.088736   \n",
       "4  0.000527  0.000825  0.002058  0.001857  ...    0.190142    0.020170   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.171821    0.034570    0.110094    0.026200    0.016835    0.102434   \n",
       "1    0.167420    0.250202    0.175125    0.006643    0.046324    0.104561   \n",
       "2    0.274281    0.297571    0.144669    0.227274    0.103086    0.054425   \n",
       "3    0.137602    0.156629    0.087048    0.031712    0.085532    0.177860   \n",
       "4    0.172070    0.365101    0.257791    0.040872    0.166836    0.075724   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.202999    0.182089  \n",
       "1    0.039302    0.040017  \n",
       "2    0.125273    0.120976  \n",
       "3    0.149036    0.116484  \n",
       "4    0.089486    0.018264  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features = normalize_dataframe(complete_features)\n",
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b339da2-35a0-455d-8db7-266f056dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_features['class'] = label_encoder.fit_transform(normalized_features['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "097defd8-e917-45e2-a877-dfe178bfe066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>0.071804</td>\n",
       "      <td>0.076584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.067411</td>\n",
       "      <td>0.171821</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.110094</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>0.102434</td>\n",
       "      <td>0.202999</td>\n",
       "      <td>0.182089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149359</td>\n",
       "      <td>0.163611</td>\n",
       "      <td>0.167420</td>\n",
       "      <td>0.250202</td>\n",
       "      <td>0.175125</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.104561</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>0.040017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>0.025486</td>\n",
       "      <td>0.046317</td>\n",
       "      <td>0.074320</td>\n",
       "      <td>0.078440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217850</td>\n",
       "      <td>0.376573</td>\n",
       "      <td>0.274281</td>\n",
       "      <td>0.297571</td>\n",
       "      <td>0.144669</td>\n",
       "      <td>0.227274</td>\n",
       "      <td>0.103086</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.125273</td>\n",
       "      <td>0.120976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129016</td>\n",
       "      <td>0.088736</td>\n",
       "      <td>0.137602</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>0.031712</td>\n",
       "      <td>0.085532</td>\n",
       "      <td>0.177860</td>\n",
       "      <td>0.149036</td>\n",
       "      <td>0.116484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190142</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.172070</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.040872</td>\n",
       "      <td>0.166836</td>\n",
       "      <td>0.075724</td>\n",
       "      <td>0.089486</td>\n",
       "      <td>0.018264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class     red_1     red_2     red_3     red_4     red_5     red_6  \\\n",
       "0      0  0.000995  0.003872  0.009432  0.006509  0.034435  0.020301   \n",
       "1      0  0.008011  0.017300  0.026471  0.014019  0.053891  0.034362   \n",
       "2      0  0.000733  0.002883  0.006288  0.006600  0.031655  0.025486   \n",
       "3      0  0.000733  0.001153  0.004057  0.002412  0.013743  0.009315   \n",
       "4      0  0.000000  0.000082  0.000304  0.000182  0.000154  0.000527   \n",
       "\n",
       "      red_7     red_8     red_9  ...  feature_15  feature_16  feature_17  \\\n",
       "0  0.041919  0.071804  0.076584  ...    0.162035    0.067411    0.171821   \n",
       "1  0.053876  0.081866  0.088884  ...    0.149359    0.163611    0.167420   \n",
       "2  0.046317  0.074320  0.078440  ...    0.217850    0.376573    0.274281   \n",
       "3  0.026663  0.055340  0.061963  ...    0.129016    0.088736    0.137602   \n",
       "4  0.000825  0.002058  0.001857  ...    0.190142    0.020170    0.172070   \n",
       "\n",
       "   feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \\\n",
       "0    0.034570    0.110094    0.026200    0.016835    0.102434    0.202999   \n",
       "1    0.250202    0.175125    0.006643    0.046324    0.104561    0.039302   \n",
       "2    0.297571    0.144669    0.227274    0.103086    0.054425    0.125273   \n",
       "3    0.156629    0.087048    0.031712    0.085532    0.177860    0.149036   \n",
       "4    0.365101    0.257791    0.040872    0.166836    0.075724    0.089486   \n",
       "\n",
       "   feature_24  \n",
       "0    0.182089  \n",
       "1    0.040017  \n",
       "2    0.120976  \n",
       "3    0.116484  \n",
       "4    0.018264  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77638c94-04af-43fb-a1db-0548a9c497cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acc8851d-dc36-4634-8d2f-8a3016c14ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def custom_train_test_split(dataframe, target_column, test_size=0.2, random_state=None):\n",
    "    # Separate features and labels\n",
    "    X = dataframe.drop(target_column, axis=1)  # Features\n",
    "    y = dataframe[target_column]  # Labels\n",
    "\n",
    "    # Perform the train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53594f6d-e920-4b66-91d8-7ba1ad60e4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = custom_train_test_split(normalized_features, 'class', test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "165bd148-e43b-401d-94a1-24f08ca4ef46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features (all columns except the first)\n",
    "x_d = normalized_features.iloc[:, 1:].values\n",
    "\n",
    "# Extract target variable (first column)\n",
    "y_d = normalized_features.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b4890-0ac4-4c6d-b3c1-9acf0c770916",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "705fec05-d73e-470c-9a2b-d71b16d96f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "33/33 [==============================] - 1s 9ms/step - loss: 2.2489 - accuracy: 0.3168 - val_loss: 1.7180 - val_accuracy: 0.4821\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.2818 - accuracy: 0.6422 - val_loss: 1.2317 - val_accuracy: 0.5893\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.7548 - val_loss: 1.0543 - val_accuracy: 0.6607\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.8111 - val_loss: 0.9749 - val_accuracy: 0.7143\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.8502 - val_loss: 0.8526 - val_accuracy: 0.7321\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8931 - val_loss: 0.8416 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8989 - val_loss: 0.7403 - val_accuracy: 0.7857\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.9227 - val_loss: 0.7824 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9361 - val_loss: 0.7193 - val_accuracy: 0.7679\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9456 - val_loss: 0.7436 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9561 - val_loss: 0.7056 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.9656 - val_loss: 0.7279 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9704 - val_loss: 0.7493 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9809 - val_loss: 0.7386 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9828 - val_loss: 0.7374 - val_accuracy: 0.7857\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9895 - val_loss: 0.7604 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9914 - val_loss: 0.7671 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9943 - val_loss: 0.7529 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9914 - val_loss: 0.8230 - val_accuracy: 0.7679\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9933 - val_loss: 0.7870 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9943 - val_loss: 0.8098 - val_accuracy: 0.7857\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9981 - val_loss: 0.8175 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9981 - val_loss: 0.8142 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9990 - val_loss: 0.8293 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9990 - val_loss: 0.8326 - val_accuracy: 0.7857\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9981 - val_loss: 0.8351 - val_accuracy: 0.7857\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9990 - val_loss: 0.8542 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9990 - val_loss: 0.8712 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.8753 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9990 - val_loss: 0.8833 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.8808 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.8849 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9079 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9361 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9373 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9467 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9625 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9746 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.7857\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9854 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.7857\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.7857\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0209 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0266 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0300 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0349 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0439 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0323 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0345 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0550 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0642 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0684 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.6829e-04 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.5052e-04 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.1602e-04 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.7790e-04 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.6437e-04 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.2612e-04 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.0786e-04 - accuracy: 1.0000 - val_loss: 1.0949 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.7908e-04 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.5483e-04 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.4801e-04 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1851e-04 - accuracy: 1.0000 - val_loss: 1.1031 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9239e-04 - accuracy: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.8330e-04 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5746e-04 - accuracy: 1.0000 - val_loss: 1.1151 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3478e-04 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1258e-04 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0254e-04 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.7857\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2400 - accuracy: 0.8080\n",
      "\n",
      "Test accuracy: 0.8079710006713867\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data in x_d and y_d\n",
    "X = x_d\n",
    "y = y_d\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c715fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(X_test_scaled)\n",
    "# predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "# np.savetxt('test_predictions.csv', np.hstack((predicted_labels.reshape(-1, 1), y_test.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "# # np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157b35a",
   "metadata": {},
   "source": [
    "## Feature Selection PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9f8a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 0.99\n",
      "(1380, 216)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 7ms/step - loss: 2.1600 - accuracy: 0.3359 - val_loss: 1.7733 - val_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3438 - accuracy: 0.5983 - val_loss: 1.4816 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.7261 - val_loss: 1.2726 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.8044 - val_loss: 1.1556 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.8502 - val_loss: 1.1003 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8750 - val_loss: 1.0317 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8893 - val_loss: 0.9786 - val_accuracy: 0.6786\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.9151 - val_loss: 0.9346 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.9313 - val_loss: 0.9555 - val_accuracy: 0.7679\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9351 - val_loss: 0.9934 - val_accuracy: 0.7679\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9542 - val_loss: 0.9464 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9656 - val_loss: 0.9824 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9609 - val_loss: 1.0365 - val_accuracy: 0.7857\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9714 - val_loss: 1.0123 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9800 - val_loss: 1.0399 - val_accuracy: 0.8036\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9781 - val_loss: 1.0952 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9838 - val_loss: 1.1236 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9857 - val_loss: 1.1249 - val_accuracy: 0.7679\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9876 - val_loss: 1.1667 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9857 - val_loss: 1.1805 - val_accuracy: 0.8036\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9895 - val_loss: 1.2047 - val_accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9933 - val_loss: 1.2047 - val_accuracy: 0.8036\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9933 - val_loss: 1.2261 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9952 - val_loss: 1.2456 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9952 - val_loss: 1.2539 - val_accuracy: 0.8036\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9962 - val_loss: 1.2843 - val_accuracy: 0.7857\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9962 - val_loss: 1.2766 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9981 - val_loss: 1.2756 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9981 - val_loss: 1.3032 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9981 - val_loss: 1.3192 - val_accuracy: 0.8036\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9981 - val_loss: 1.3261 - val_accuracy: 0.8036\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9981 - val_loss: 1.3384 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9990 - val_loss: 1.3338 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9990 - val_loss: 1.3595 - val_accuracy: 0.8036\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 1.3588 - val_accuracy: 0.8036\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3666 - val_accuracy: 0.8036\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9990 - val_loss: 1.3766 - val_accuracy: 0.8036\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 1.3885 - val_accuracy: 0.8214\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3848 - val_accuracy: 0.8036\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.8036\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.8036\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4057 - val_accuracy: 0.8036\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4204 - val_accuracy: 0.8036\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4221 - val_accuracy: 0.8036\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.4339 - val_accuracy: 0.8036\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.8036\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4444 - val_accuracy: 0.8036\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.4516 - val_accuracy: 0.8036\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.8036\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.8214\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4666 - val_accuracy: 0.8214\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.8214\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4815 - val_accuracy: 0.8214\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5118 - val_accuracy: 0.8214\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5268 - val_accuracy: 0.8214\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5264 - val_accuracy: 0.8214\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5294 - val_accuracy: 0.8214\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5347 - val_accuracy: 0.8214\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.8214\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5462 - val_accuracy: 0.8214\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5539 - val_accuracy: 0.8214\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5582 - val_accuracy: 0.8214\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.8214\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5719 - val_accuracy: 0.8214\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5806 - val_accuracy: 0.8214\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.8214\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.8214\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5968 - val_accuracy: 0.8214\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.8214\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.8214\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6160 - val_accuracy: 0.8214\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6173 - val_accuracy: 0.8214\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6204 - val_accuracy: 0.8214\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6295 - val_accuracy: 0.8214\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6325 - val_accuracy: 0.8214\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6422 - val_accuracy: 0.8214\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.8214\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6493 - val_accuracy: 0.8214\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6596 - val_accuracy: 0.8214\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6660 - val_accuracy: 0.8214\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6674 - val_accuracy: 0.8214\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.8214\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.6795e-04 - accuracy: 1.0000 - val_loss: 1.6761 - val_accuracy: 0.8214\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.4418e-04 - accuracy: 1.0000 - val_loss: 1.6816 - val_accuracy: 0.8214\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.0361e-04 - accuracy: 1.0000 - val_loss: 1.6816 - val_accuracy: 0.8214\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.8016e-04 - accuracy: 1.0000 - val_loss: 1.6868 - val_accuracy: 0.8214\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.4868e-04 - accuracy: 1.0000 - val_loss: 1.6973 - val_accuracy: 0.8393\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.2812e-04 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.8214\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.0340e-04 - accuracy: 1.0000 - val_loss: 1.7020 - val_accuracy: 0.8214\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.7595e-04 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.8393\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.5030e-04 - accuracy: 1.0000 - val_loss: 1.7105 - val_accuracy: 0.8393\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.3567e-04 - accuracy: 1.0000 - val_loss: 1.7176 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9848e-04 - accuracy: 1.0000 - val_loss: 1.7227 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8248e-04 - accuracy: 1.0000 - val_loss: 1.7226 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6106e-04 - accuracy: 1.0000 - val_loss: 1.7310 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4530e-04 - accuracy: 1.0000 - val_loss: 1.7353 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1992e-04 - accuracy: 1.0000 - val_loss: 1.7369 - val_accuracy: 0.8393\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0469e-04 - accuracy: 1.0000 - val_loss: 1.7413 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8572e-04 - accuracy: 1.0000 - val_loss: 1.7498 - val_accuracy: 0.8393\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3131 - accuracy: 0.8188\n",
      "\n",
      "Test accuracy: 0.8188405632972717\n",
      "var: 0.991\n",
      "(1380, 225)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 7ms/step - loss: 2.1647 - accuracy: 0.3693 - val_loss: 1.8172 - val_accuracy: 0.4643\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.4438 - accuracy: 0.5897 - val_loss: 1.4593 - val_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.0805 - accuracy: 0.6947 - val_loss: 1.2375 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8335 - accuracy: 0.7672 - val_loss: 1.0956 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.8130 - val_loss: 0.9614 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.8578 - val_loss: 0.9277 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8626 - val_loss: 0.9117 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8922 - val_loss: 0.9090 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.9141 - val_loss: 0.8796 - val_accuracy: 0.7321\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.9256 - val_loss: 0.8703 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9504 - val_loss: 0.8564 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9494 - val_loss: 0.9274 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9647 - val_loss: 0.9149 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9714 - val_loss: 0.9285 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9771 - val_loss: 0.9593 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9809 - val_loss: 0.9054 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9847 - val_loss: 1.0302 - val_accuracy: 0.7679\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9866 - val_loss: 0.9804 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9933 - val_loss: 0.9464 - val_accuracy: 0.7679\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9943 - val_loss: 0.9983 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9952 - val_loss: 0.9845 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9971 - val_loss: 1.0205 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9990 - val_loss: 1.0086 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9962 - val_loss: 1.0437 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9962 - val_loss: 1.0316 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9990 - val_loss: 1.0308 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9990 - val_loss: 1.0532 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.0600 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.0930 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9990 - val_loss: 1.0829 - val_accuracy: 0.7679\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.7679\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.1214 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1560 - val_accuracy: 0.7321\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.7321\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1678 - val_accuracy: 0.7321\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1762 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.7321\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2110 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2078 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2263 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2419 - val_accuracy: 0.7321\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2396 - val_accuracy: 0.7321\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2762 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2755 - val_accuracy: 0.7321\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2841 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2890 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2922 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3118 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2991 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3100 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3178 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3215 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3375 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3477 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3573 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3622 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3656 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3755 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3871 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3815 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3843 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3985 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3961 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4070 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4205 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4233 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4346 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4322 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4350 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4454 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.7774e-04 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.4605e-04 - accuracy: 1.0000 - val_loss: 1.4552 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.1747e-04 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.9127e-04 - accuracy: 1.0000 - val_loss: 1.4675 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.6351e-04 - accuracy: 1.0000 - val_loss: 1.4686 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.2753e-04 - accuracy: 1.0000 - val_loss: 1.4703 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.1583e-04 - accuracy: 1.0000 - val_loss: 1.4826 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.8320e-04 - accuracy: 1.0000 - val_loss: 1.4787 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.5266e-04 - accuracy: 1.0000 - val_loss: 1.4852 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.3137e-04 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1025e-04 - accuracy: 1.0000 - val_loss: 1.4989 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8905e-04 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7536e-04 - accuracy: 1.0000 - val_loss: 1.5096 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5015e-04 - accuracy: 1.0000 - val_loss: 1.5025 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3804e-04 - accuracy: 1.0000 - val_loss: 1.5163 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0855e-04 - accuracy: 1.0000 - val_loss: 1.5165 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.9558e-04 - accuracy: 1.0000 - val_loss: 1.5186 - val_accuracy: 0.7500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.4280 - accuracy: 0.8116\n",
      "\n",
      "Test accuracy: 0.8115941882133484\n",
      "var: 0.992\n",
      "(1380, 234)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.0772 - accuracy: 0.3349 - val_loss: 1.7291 - val_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3172 - accuracy: 0.6031 - val_loss: 1.2958 - val_accuracy: 0.5536\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9486 - accuracy: 0.7357 - val_loss: 1.1091 - val_accuracy: 0.6786\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.8073 - val_loss: 0.9793 - val_accuracy: 0.6964\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.8445 - val_loss: 0.8991 - val_accuracy: 0.6964\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8874 - val_loss: 0.8646 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.9103 - val_loss: 0.8119 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.9275 - val_loss: 0.8471 - val_accuracy: 0.6964\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.9313 - val_loss: 0.8473 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9494 - val_loss: 0.8357 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9571 - val_loss: 0.8223 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9618 - val_loss: 0.8024 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9723 - val_loss: 0.8341 - val_accuracy: 0.7857\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9752 - val_loss: 0.8474 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9828 - val_loss: 0.8787 - val_accuracy: 0.7857\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9847 - val_loss: 0.8889 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9885 - val_loss: 0.8905 - val_accuracy: 0.7857\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9876 - val_loss: 0.9533 - val_accuracy: 0.7679\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9943 - val_loss: 0.9226 - val_accuracy: 0.7679\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9905 - val_loss: 0.9204 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9943 - val_loss: 0.9709 - val_accuracy: 0.8036\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9952 - val_loss: 0.9593 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9971 - val_loss: 0.9583 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9952 - val_loss: 1.0119 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9981 - val_loss: 0.9841 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9981 - val_loss: 1.0366 - val_accuracy: 0.7857\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9981 - val_loss: 1.0318 - val_accuracy: 0.7679\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9990 - val_loss: 1.0268 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9981 - val_loss: 1.0370 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9981 - val_loss: 1.0657 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9981 - val_loss: 1.0620 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9990 - val_loss: 1.0875 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 1.0881 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9990 - val_loss: 1.0948 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9981 - val_loss: 1.1128 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9981 - val_loss: 1.1169 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.1467 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1463 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1612 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1745 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.1851 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2277 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2441 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2372 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2505 - val_accuracy: 0.7857\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2542 - val_accuracy: 0.8036\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2962 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2988 - val_accuracy: 0.7857\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2987 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3122 - val_accuracy: 0.8036\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3058 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3261 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3316 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3569 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3697 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3734 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3802 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3844 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3836 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3986 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4014 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4105 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4056 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.8036\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4304 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4360 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4416 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4460 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4552 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4587 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.9643e-04 - accuracy: 1.0000 - val_loss: 1.4678 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.4925e-04 - accuracy: 1.0000 - val_loss: 1.4649 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.2988e-04 - accuracy: 1.0000 - val_loss: 1.4750 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.9032e-04 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.5916e-04 - accuracy: 1.0000 - val_loss: 1.4842 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.3676e-04 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.8036\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.1519e-04 - accuracy: 1.0000 - val_loss: 1.4939 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.8867e-04 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.8036\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.6688e-04 - accuracy: 1.0000 - val_loss: 1.4985 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.2725e-04 - accuracy: 1.0000 - val_loss: 1.5109 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1670e-04 - accuracy: 1.0000 - val_loss: 1.5115 - val_accuracy: 0.8036\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9811e-04 - accuracy: 1.0000 - val_loss: 1.5183 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.6915e-04 - accuracy: 1.0000 - val_loss: 1.5206 - val_accuracy: 0.8036\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2571 - accuracy: 0.8188\n",
      "\n",
      "Test accuracy: 0.8188405632972717\n",
      "var: 0.993\n",
      "(1380, 246)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.0833 - accuracy: 0.3540 - val_loss: 1.8828 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3506 - accuracy: 0.6107 - val_loss: 1.4829 - val_accuracy: 0.5536\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9852 - accuracy: 0.7281 - val_loss: 1.2741 - val_accuracy: 0.6071\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7490 - accuracy: 0.7891 - val_loss: 1.1398 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.8340 - val_loss: 1.0539 - val_accuracy: 0.6964\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8578 - val_loss: 0.9753 - val_accuracy: 0.6964\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8922 - val_loss: 1.0726 - val_accuracy: 0.6786\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.9094 - val_loss: 0.9415 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.9284 - val_loss: 0.9707 - val_accuracy: 0.6964\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9408 - val_loss: 0.9685 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9590 - val_loss: 0.9910 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9676 - val_loss: 0.9869 - val_accuracy: 0.7321\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9752 - val_loss: 0.9937 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9752 - val_loss: 0.9943 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9800 - val_loss: 0.9622 - val_accuracy: 0.7679\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9885 - val_loss: 1.0045 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9914 - val_loss: 1.0170 - val_accuracy: 0.7679\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9905 - val_loss: 1.0363 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9962 - val_loss: 1.0193 - val_accuracy: 0.7679\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9971 - val_loss: 1.0839 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9990 - val_loss: 1.1043 - val_accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9971 - val_loss: 1.1274 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9990 - val_loss: 1.1207 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9990 - val_loss: 1.1613 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9990 - val_loss: 1.1873 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9990 - val_loss: 1.1968 - val_accuracy: 0.7679\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9990 - val_loss: 1.1957 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9990 - val_loss: 1.1982 - val_accuracy: 0.7679\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2192 - val_accuracy: 0.7857\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2368 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9990 - val_loss: 1.3048 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3446 - val_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.3651 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.3815 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.7857\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4018 - val_accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4350 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4536 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.4584 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4762 - val_accuracy: 0.7857\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4915 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4901 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5242 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5172 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5193 - val_accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5265 - val_accuracy: 0.7857\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.7857\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5512 - val_accuracy: 0.7857\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5685 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 0.7857\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5869 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.7857\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6050 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6176 - val_accuracy: 0.7857\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6397 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6314 - val_accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6382 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6620 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6752 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6762 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6848 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6951 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7001 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7048 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7209 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7370 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7361 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7515 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7601 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7611 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7755 - val_accuracy: 0.7679\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7778 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7897 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7885 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.7627e-04 - accuracy: 1.0000 - val_loss: 1.7973 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.4277e-04 - accuracy: 1.0000 - val_loss: 1.8017 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.1518e-04 - accuracy: 1.0000 - val_loss: 1.8071 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.8675e-04 - accuracy: 1.0000 - val_loss: 1.8113 - val_accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.5972e-04 - accuracy: 1.0000 - val_loss: 1.8217 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.3408e-04 - accuracy: 1.0000 - val_loss: 1.8245 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.0493e-04 - accuracy: 1.0000 - val_loss: 1.8339 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.9053e-04 - accuracy: 1.0000 - val_loss: 1.8370 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.7723e-04 - accuracy: 1.0000 - val_loss: 1.8445 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.4410e-04 - accuracy: 1.0000 - val_loss: 1.8493 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.2150e-04 - accuracy: 1.0000 - val_loss: 1.8591 - val_accuracy: 0.7679\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9816e-04 - accuracy: 1.0000 - val_loss: 1.8675 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7625e-04 - accuracy: 1.0000 - val_loss: 1.8667 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5724e-04 - accuracy: 1.0000 - val_loss: 1.8770 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3886e-04 - accuracy: 1.0000 - val_loss: 1.8787 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3767 - accuracy: 0.8370\n",
      "\n",
      "Test accuracy: 0.8369565010070801\n",
      "var: 0.994\n",
      "(1380, 259)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.1260 - accuracy: 0.3082 - val_loss: 1.8430 - val_accuracy: 0.4107\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3473 - accuracy: 0.6422 - val_loss: 1.5183 - val_accuracy: 0.5893\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.7529 - val_loss: 1.3150 - val_accuracy: 0.6071\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.7996 - val_loss: 1.1323 - val_accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.8311 - val_loss: 1.0241 - val_accuracy: 0.6607\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8616 - val_loss: 1.0053 - val_accuracy: 0.6786\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8788 - val_loss: 0.9384 - val_accuracy: 0.7321\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8989 - val_loss: 0.9059 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.9227 - val_loss: 0.9080 - val_accuracy: 0.6786\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9418 - val_loss: 0.8473 - val_accuracy: 0.7321\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9437 - val_loss: 0.8964 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9552 - val_loss: 0.8893 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9609 - val_loss: 0.9033 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9704 - val_loss: 0.8858 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9781 - val_loss: 0.9640 - val_accuracy: 0.7679\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9809 - val_loss: 0.9157 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9828 - val_loss: 0.9719 - val_accuracy: 0.7321\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9876 - val_loss: 0.9751 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9885 - val_loss: 0.9902 - val_accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9914 - val_loss: 0.9826 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9952 - val_loss: 1.0428 - val_accuracy: 0.7321\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9962 - val_loss: 1.0847 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9981 - val_loss: 1.1029 - val_accuracy: 0.7321\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9981 - val_loss: 1.0914 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9990 - val_loss: 1.1467 - val_accuracy: 0.7321\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9981 - val_loss: 1.1714 - val_accuracy: 0.7321\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.1780 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.1926 - val_accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.2399 - val_accuracy: 0.7321\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.2407 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2615 - val_accuracy: 0.7321\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.2842 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.3040 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3294 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3601 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3434 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.7321\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4022 - val_accuracy: 0.7321\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.4126 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4202 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.4354 - val_accuracy: 0.7321\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4418 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.4658 - val_accuracy: 0.7321\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4717 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.4570 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4951 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.4867 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5070 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5265 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5168 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5499 - val_accuracy: 0.7321\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5401 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5540 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5698 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5535 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5793 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.6054 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5979 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6094 - val_accuracy: 0.7321\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6143 - val_accuracy: 0.7321\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6400 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6366 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6446 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6556 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6627 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6759 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6839 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6953 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6863 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7129 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7170 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7263 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7306 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7357 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7581 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7601 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7674 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7725 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7792 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7833 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7902 - val_accuracy: 0.7321\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 9.8222e-04 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 9.5842e-04 - accuracy: 1.0000 - val_loss: 1.8067 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.2348e-04 - accuracy: 1.0000 - val_loss: 1.8183 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.9413e-04 - accuracy: 1.0000 - val_loss: 1.8133 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.6338e-04 - accuracy: 1.0000 - val_loss: 1.8161 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.4068e-04 - accuracy: 1.0000 - val_loss: 1.8236 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.1960e-04 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.0040e-04 - accuracy: 1.0000 - val_loss: 1.8395 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.8106e-04 - accuracy: 1.0000 - val_loss: 1.8397 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.3983e-04 - accuracy: 1.0000 - val_loss: 1.8420 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.2266e-04 - accuracy: 1.0000 - val_loss: 1.8501 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0843e-04 - accuracy: 1.0000 - val_loss: 1.8567 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8157e-04 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3389 - accuracy: 0.7935\n",
      "\n",
      "Test accuracy: 0.79347825050354\n",
      "var: 0.995\n",
      "(1380, 275)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 7ms/step - loss: 2.2053 - accuracy: 0.3387 - val_loss: 1.8194 - val_accuracy: 0.3929\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3535 - accuracy: 0.6202 - val_loss: 1.4235 - val_accuracy: 0.5536\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9714 - accuracy: 0.7252 - val_loss: 1.1497 - val_accuracy: 0.6607\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.7844 - val_loss: 0.9907 - val_accuracy: 0.6607\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.8340 - val_loss: 0.9137 - val_accuracy: 0.6786\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8674 - val_loss: 0.9094 - val_accuracy: 0.7143\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8969 - val_loss: 0.8534 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.9065 - val_loss: 0.8722 - val_accuracy: 0.6964\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.9208 - val_loss: 0.8315 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9485 - val_loss: 0.8409 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9532 - val_loss: 0.8634 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9609 - val_loss: 0.8236 - val_accuracy: 0.7143\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9666 - val_loss: 0.8395 - val_accuracy: 0.6964\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.9733 - val_loss: 0.8222 - val_accuracy: 0.7321\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9761 - val_loss: 0.8820 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9809 - val_loss: 0.8274 - val_accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9828 - val_loss: 0.8568 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9857 - val_loss: 0.8714 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9895 - val_loss: 0.8677 - val_accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9924 - val_loss: 0.9550 - val_accuracy: 0.7321\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9905 - val_loss: 0.9479 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9962 - val_loss: 0.9507 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9971 - val_loss: 0.9976 - val_accuracy: 0.7143\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9981 - val_loss: 0.9517 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9981 - val_loss: 0.9601 - val_accuracy: 0.7143\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9990 - val_loss: 1.0478 - val_accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9990 - val_loss: 1.0017 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.7143\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.0337 - val_accuracy: 0.7143\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.0542 - val_accuracy: 0.7143\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.7143\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.0592 - val_accuracy: 0.7143\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.7143\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0484 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0845 - val_accuracy: 0.7143\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.7143\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0787 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1030 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1218 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1116 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1576 - val_accuracy: 0.7321\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1305 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1437 - val_accuracy: 0.7321\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1648 - val_accuracy: 0.7321\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.7321\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1743 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.7321\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.7321\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2051 - val_accuracy: 0.7321\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.7321\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2147 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2423 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2310 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2219 - val_accuracy: 0.7321\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2315 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.7321\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2611 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2475 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2641 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2599 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2787 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2789 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2947 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3029 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3104 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3260 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3187 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.9937e-04 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.6213e-04 - accuracy: 1.0000 - val_loss: 1.3317 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.3135e-04 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.0770e-04 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.7598e-04 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.7321\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.4202e-04 - accuracy: 1.0000 - val_loss: 1.3447 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.1757e-04 - accuracy: 1.0000 - val_loss: 1.3455 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.9213e-04 - accuracy: 1.0000 - val_loss: 1.3614 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.6634e-04 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.5162e-04 - accuracy: 1.0000 - val_loss: 1.3661 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.4237e-04 - accuracy: 1.0000 - val_loss: 1.3624 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 7.1961e-04 - accuracy: 1.0000 - val_loss: 1.3682 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.9166e-04 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.6050e-04 - accuracy: 1.0000 - val_loss: 1.3693 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.4513e-04 - accuracy: 1.0000 - val_loss: 1.3804 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.2271e-04 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.0535e-04 - accuracy: 1.0000 - val_loss: 1.3869 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.9088e-04 - accuracy: 1.0000 - val_loss: 1.3824 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4779 - accuracy: 0.8225\n",
      "\n",
      "Test accuracy: 0.8224637508392334\n",
      "var: 0.996\n",
      "(1380, 296)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.1934 - accuracy: 0.2891 - val_loss: 1.9890 - val_accuracy: 0.3929\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.4651 - accuracy: 0.5716 - val_loss: 1.6062 - val_accuracy: 0.5536\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0655 - accuracy: 0.6908 - val_loss: 1.4168 - val_accuracy: 0.5893\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8161 - accuracy: 0.7643 - val_loss: 1.2777 - val_accuracy: 0.6071\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.8187 - val_loss: 1.2189 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8397 - val_loss: 1.1744 - val_accuracy: 0.5893\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8760 - val_loss: 1.1852 - val_accuracy: 0.6250\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8950 - val_loss: 1.1105 - val_accuracy: 0.6429\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.9208 - val_loss: 1.2044 - val_accuracy: 0.6607\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9294 - val_loss: 1.1314 - val_accuracy: 0.6607\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9475 - val_loss: 1.0790 - val_accuracy: 0.6786\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9637 - val_loss: 1.0958 - val_accuracy: 0.6786\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9618 - val_loss: 1.1393 - val_accuracy: 0.6786\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9695 - val_loss: 1.0636 - val_accuracy: 0.6786\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9819 - val_loss: 1.0989 - val_accuracy: 0.6964\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9838 - val_loss: 1.1146 - val_accuracy: 0.6964\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9857 - val_loss: 1.1180 - val_accuracy: 0.6964\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9885 - val_loss: 1.1897 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9905 - val_loss: 1.1557 - val_accuracy: 0.6786\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9876 - val_loss: 1.1414 - val_accuracy: 0.6964\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9933 - val_loss: 1.1884 - val_accuracy: 0.6964\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9943 - val_loss: 1.1691 - val_accuracy: 0.6964\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9952 - val_loss: 1.1429 - val_accuracy: 0.6964\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9943 - val_loss: 1.2133 - val_accuracy: 0.6786\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9971 - val_loss: 1.2171 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9971 - val_loss: 1.2004 - val_accuracy: 0.7321\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9990 - val_loss: 1.2704 - val_accuracy: 0.6964\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 1.2531 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9990 - val_loss: 1.2687 - val_accuracy: 0.7321\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9990 - val_loss: 1.2871 - val_accuracy: 0.7321\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.7321\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9990 - val_loss: 1.3205 - val_accuracy: 0.6964\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2851 - val_accuracy: 0.7321\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9990 - val_loss: 1.3266 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3644 - val_accuracy: 0.7321\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 1.3678 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3660 - val_accuracy: 0.7679\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4051 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.7679\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.4402 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.4330 - val_accuracy: 0.7679\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4457 - val_accuracy: 0.7679\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4524 - val_accuracy: 0.7857\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4682 - val_accuracy: 0.7679\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.7679\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4907 - val_accuracy: 0.7679\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.4993 - val_accuracy: 0.7857\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.7679\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5153 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5376 - val_accuracy: 0.7679\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5350 - val_accuracy: 0.7679\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5572 - val_accuracy: 0.7679\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.7679\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.7857\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.7679\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5843 - val_accuracy: 0.7857\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.7679\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.7857\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6028 - val_accuracy: 0.7857\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6112 - val_accuracy: 0.7679\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6074 - val_accuracy: 0.7857\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6233 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6335 - val_accuracy: 0.7857\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6425 - val_accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6397 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6591 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6877 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6750 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6896 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6891 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6947 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7071 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7125 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7224 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7146 - val_accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7329 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7370 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7400 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7482 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7527 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7647 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7698 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.7367e-04 - accuracy: 1.0000 - val_loss: 1.7900 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.5259e-04 - accuracy: 1.0000 - val_loss: 1.7893 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.1488e-04 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.9496e-04 - accuracy: 1.0000 - val_loss: 1.7921 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.9394e-04 - accuracy: 1.0000 - val_loss: 1.8063 - val_accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.4216e-04 - accuracy: 1.0000 - val_loss: 1.8162 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.0568e-04 - accuracy: 1.0000 - val_loss: 1.8166 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.8542e-04 - accuracy: 1.0000 - val_loss: 1.8196 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.6449e-04 - accuracy: 1.0000 - val_loss: 1.8276 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.4788e-04 - accuracy: 1.0000 - val_loss: 1.8261 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1826e-04 - accuracy: 1.0000 - val_loss: 1.8345 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.9792e-04 - accuracy: 1.0000 - val_loss: 1.8385 - val_accuracy: 0.7857\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.4813 - accuracy: 0.8116\n",
      "\n",
      "Test accuracy: 0.8115941882133484\n",
      "var: 0.997\n",
      "(1380, 322)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.1395 - accuracy: 0.3006 - val_loss: 1.8864 - val_accuracy: 0.4643\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3570 - accuracy: 0.6002 - val_loss: 1.5044 - val_accuracy: 0.5179\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9766 - accuracy: 0.7147 - val_loss: 1.3166 - val_accuracy: 0.6071\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7432 - accuracy: 0.7948 - val_loss: 1.1568 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.8387 - val_loss: 1.0722 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8740 - val_loss: 1.0009 - val_accuracy: 0.6964\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.9055 - val_loss: 0.9748 - val_accuracy: 0.6964\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.9113 - val_loss: 0.8898 - val_accuracy: 0.7321\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.9294 - val_loss: 0.9238 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9475 - val_loss: 0.9130 - val_accuracy: 0.6964\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9485 - val_loss: 0.9504 - val_accuracy: 0.7321\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9532 - val_loss: 0.9516 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9666 - val_loss: 0.9466 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9742 - val_loss: 0.9893 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9819 - val_loss: 0.9851 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9733 - val_loss: 1.0532 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9819 - val_loss: 1.0611 - val_accuracy: 0.7321\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9838 - val_loss: 1.0938 - val_accuracy: 0.7321\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9885 - val_loss: 1.0655 - val_accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9905 - val_loss: 1.0939 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9933 - val_loss: 1.1068 - val_accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9905 - val_loss: 1.1211 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9971 - val_loss: 1.1664 - val_accuracy: 0.7321\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9952 - val_loss: 1.1502 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9962 - val_loss: 1.1915 - val_accuracy: 0.7321\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9990 - val_loss: 1.2194 - val_accuracy: 0.7321\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9990 - val_loss: 1.2338 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9981 - val_loss: 1.2225 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9990 - val_loss: 1.2878 - val_accuracy: 0.7321\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9990 - val_loss: 1.2620 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.7321\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9990 - val_loss: 1.2947 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.3220 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.3437 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9981 - val_loss: 1.3602 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.4237 - val_accuracy: 0.7321\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.7321\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4167 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4524 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.4773 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5055 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.5321 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.5421 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.5320 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5694 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5693 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5780 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.6007 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6277 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6281 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6452 - val_accuracy: 0.7679\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6388 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6599 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6616 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6729 - val_accuracy: 0.7679\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6861 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6794 - val_accuracy: 0.7679\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6962 - val_accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7144 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7184 - val_accuracy: 0.7679\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7267 - val_accuracy: 0.7679\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7287 - val_accuracy: 0.7679\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7502 - val_accuracy: 0.7679\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7532 - val_accuracy: 0.7679\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7569 - val_accuracy: 0.7679\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7673 - val_accuracy: 0.7679\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7718 - val_accuracy: 0.7679\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7752 - val_accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7843 - val_accuracy: 0.7679\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7958 - val_accuracy: 0.7679\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8067 - val_accuracy: 0.7679\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8066 - val_accuracy: 0.7679\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8191 - val_accuracy: 0.7679\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8221 - val_accuracy: 0.7679\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8264 - val_accuracy: 0.7679\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8430 - val_accuracy: 0.7679\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8355 - val_accuracy: 0.7679\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8446 - val_accuracy: 0.7679\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8541 - val_accuracy: 0.7679\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8641 - val_accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.7258e-04 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.7679\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.4111e-04 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.7679\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.1582e-04 - accuracy: 1.0000 - val_loss: 1.8816 - val_accuracy: 0.7679\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.8704e-04 - accuracy: 1.0000 - val_loss: 1.8865 - val_accuracy: 0.7679\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.5090e-04 - accuracy: 1.0000 - val_loss: 1.8955 - val_accuracy: 0.7679\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.3079e-04 - accuracy: 1.0000 - val_loss: 1.8955 - val_accuracy: 0.7679\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.0280e-04 - accuracy: 1.0000 - val_loss: 1.9012 - val_accuracy: 0.7679\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 7.7663e-04 - accuracy: 1.0000 - val_loss: 1.9150 - val_accuracy: 0.7679\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.5528e-04 - accuracy: 1.0000 - val_loss: 1.9182 - val_accuracy: 0.7679\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.4961e-04 - accuracy: 1.0000 - val_loss: 1.9240 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1168e-04 - accuracy: 1.0000 - val_loss: 1.9253 - val_accuracy: 0.7679\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5144 - accuracy: 0.8116\n",
      "\n",
      "Test accuracy: 0.8115941882133484\n",
      "var: 0.998\n",
      "(1380, 360)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.2456 - accuracy: 0.3177 - val_loss: 1.9171 - val_accuracy: 0.4107\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3905 - accuracy: 0.5763 - val_loss: 1.5150 - val_accuracy: 0.4821\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9927 - accuracy: 0.7128 - val_loss: 1.2275 - val_accuracy: 0.5536\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7333 - accuracy: 0.7910 - val_loss: 1.0489 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.8521 - val_loss: 0.9873 - val_accuracy: 0.6607\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8817 - val_loss: 0.9196 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.9036 - val_loss: 0.9796 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.9218 - val_loss: 0.9396 - val_accuracy: 0.6786\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.9380 - val_loss: 0.9249 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9475 - val_loss: 0.9033 - val_accuracy: 0.6964\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9590 - val_loss: 0.8586 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9666 - val_loss: 0.9963 - val_accuracy: 0.6786\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9733 - val_loss: 0.9535 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9828 - val_loss: 0.9607 - val_accuracy: 0.7321\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9857 - val_loss: 1.0276 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9866 - val_loss: 1.0185 - val_accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9847 - val_loss: 1.0816 - val_accuracy: 0.7321\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9981 - val_loss: 1.1461 - val_accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9952 - val_loss: 1.1667 - val_accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9981 - val_loss: 1.1658 - val_accuracy: 0.7321\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 1.1573 - val_accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9962 - val_loss: 1.1943 - val_accuracy: 0.7679\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.2221 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9990 - val_loss: 1.2341 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9990 - val_loss: 1.2575 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9990 - val_loss: 1.2794 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.3311 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3556 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3953 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3892 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3844 - val_accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.7321\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.4399 - val_accuracy: 0.7321\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4640 - val_accuracy: 0.7321\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.7321\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.4780 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.4844 - val_accuracy: 0.7321\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5094 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5142 - val_accuracy: 0.7321\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.5082 - val_accuracy: 0.7321\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5231 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.7321\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5440 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5608 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.7321\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.7321\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6090 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6089 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6072 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6269 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.6379 - val_accuracy: 0.7321\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6351 - val_accuracy: 0.7321\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6522 - val_accuracy: 0.7321\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6653 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6722 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6860 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6799 - val_accuracy: 0.7321\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7102 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7016 - val_accuracy: 0.7321\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7170 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7227 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7295 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7441 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7483 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7544 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7673 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7816 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7891 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7941 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7922 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8123 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8060 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8140 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8217 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8335 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.7619e-04 - accuracy: 1.0000 - val_loss: 1.8366 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.4028e-04 - accuracy: 1.0000 - val_loss: 1.8391 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.0868e-04 - accuracy: 1.0000 - val_loss: 1.8573 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.8361e-04 - accuracy: 1.0000 - val_loss: 1.8637 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.6469e-04 - accuracy: 1.0000 - val_loss: 1.8720 - val_accuracy: 0.7321\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.4196e-04 - accuracy: 1.0000 - val_loss: 1.8768 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.1567e-04 - accuracy: 1.0000 - val_loss: 1.8670 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.8410e-04 - accuracy: 1.0000 - val_loss: 1.8762 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.5723e-04 - accuracy: 1.0000 - val_loss: 1.8901 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.3104e-04 - accuracy: 1.0000 - val_loss: 1.8931 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.1332e-04 - accuracy: 1.0000 - val_loss: 1.9000 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8720e-04 - accuracy: 1.0000 - val_loss: 1.8986 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.7917e-04 - accuracy: 1.0000 - val_loss: 1.9134 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.5825e-04 - accuracy: 1.0000 - val_loss: 1.9211 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.3271e-04 - accuracy: 1.0000 - val_loss: 1.9246 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.1865e-04 - accuracy: 1.0000 - val_loss: 1.9272 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.9984e-04 - accuracy: 1.0000 - val_loss: 1.9276 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8657e-04 - accuracy: 1.0000 - val_loss: 1.9400 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2338 - accuracy: 0.8152\n",
      "\n",
      "Test accuracy: 0.8152173757553101\n",
      "var: 0.999\n",
      "(1380, 426)\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 6ms/step - loss: 2.1715 - accuracy: 0.3187 - val_loss: 1.8016 - val_accuracy: 0.3929\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3564 - accuracy: 0.5945 - val_loss: 1.4351 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9768 - accuracy: 0.7385 - val_loss: 1.1899 - val_accuracy: 0.6071\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.7401 - accuracy: 0.7996 - val_loss: 1.0655 - val_accuracy: 0.6607\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.8426 - val_loss: 0.9670 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8702 - val_loss: 0.9080 - val_accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8912 - val_loss: 0.8254 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.9189 - val_loss: 0.9012 - val_accuracy: 0.7321\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.9275 - val_loss: 0.8459 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9447 - val_loss: 0.8714 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9513 - val_loss: 0.8855 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9609 - val_loss: 0.8963 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9695 - val_loss: 0.8626 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9742 - val_loss: 0.9134 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9809 - val_loss: 0.9799 - val_accuracy: 0.7321\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9828 - val_loss: 0.9650 - val_accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9876 - val_loss: 1.0082 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9924 - val_loss: 1.0165 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9895 - val_loss: 0.9856 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9952 - val_loss: 1.0013 - val_accuracy: 0.7857\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9990 - val_loss: 1.0993 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9952 - val_loss: 1.0719 - val_accuracy: 0.7321\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9981 - val_loss: 1.0814 - val_accuracy: 0.7321\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9990 - val_loss: 1.1548 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.1281 - val_accuracy: 0.7679\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9981 - val_loss: 1.1045 - val_accuracy: 0.7321\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9981 - val_loss: 1.1862 - val_accuracy: 0.7321\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.2125 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1882 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.7321\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2412 - val_accuracy: 0.7679\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 0.7143\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.2810 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3049 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.7321\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3222 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3098 - val_accuracy: 0.7321\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.7321\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3611 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.3612 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3736 - val_accuracy: 0.7321\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.7321\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.4067 - val_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.4166 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4509 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4512 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4622 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4622 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4818 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4916 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4912 - val_accuracy: 0.7143\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5124 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5183 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5257 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5360 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5477 - val_accuracy: 0.7143\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5621 - val_accuracy: 0.7143\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5650 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 0.7143\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6062 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6203 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6311 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6422 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6515 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6654 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6607 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6809 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6773 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6898 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7093 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7200 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7368 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7424 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7428 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7684 - val_accuracy: 0.7321\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7627 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.6736e-04 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.5245e-04 - accuracy: 1.0000 - val_loss: 1.7831 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.1749e-04 - accuracy: 1.0000 - val_loss: 1.7902 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.9163e-04 - accuracy: 1.0000 - val_loss: 1.7895 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.5168e-04 - accuracy: 1.0000 - val_loss: 1.8029 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.4159e-04 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.1345e-04 - accuracy: 1.0000 - val_loss: 1.8138 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.8364e-04 - accuracy: 1.0000 - val_loss: 1.8152 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.5512e-04 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.4425e-04 - accuracy: 1.0000 - val_loss: 1.8290 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.2535e-04 - accuracy: 1.0000 - val_loss: 1.8349 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0178e-04 - accuracy: 1.0000 - val_loss: 1.8423 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3841 - accuracy: 0.8007\n",
      "\n",
      "Test accuracy: 0.8007246255874634\n",
      "Best Accuracy: 0.8369565010070801\n",
      "Trimmed x_d with Best Selected Features:\n",
      "(1380, 246)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_pca_for_feature_selection(X, desired_variance_ratio):\n",
    "    pca = PCA(n_components=desired_variance_ratio)\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "    return reduced_features, pca\n",
    "\n",
    "def pca(X, y, test_size=0.2, random_state=42):\n",
    "\n",
    "    variance_ratios = [i / 1000 for i in range(990, 1000)]\n",
    "    max_accuracy = 0.0\n",
    "    best_selected_features = None\n",
    "    best_pca_model = None\n",
    "\n",
    "    for desired_variance_ratio in variance_ratios:\n",
    "        reduced_features, pca_model = apply_pca_for_feature_selection(X, desired_variance_ratio)\n",
    "        print(f\"var: {desired_variance_ratio}\")\n",
    "        print(np.shape(reduced_features))\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Build the ANN model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dense(14, activation='softmax')  # 14 output classes\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Update max accuracy and store corresponding features\n",
    "        if test_acc > max_accuracy:\n",
    "            max_accuracy = test_acc\n",
    "            best_selected_features = reduced_features.copy()\n",
    "            best_pca_model = pca_model\n",
    "\n",
    "    # Apply inverse_transform to the full dataset with the best selected features\n",
    "    trimmed_x_d = best_pca_model.inverse_transform(best_selected_features)\n",
    "\n",
    "    return best_selected_features, max_accuracy\n",
    "\n",
    "# Example usage:\n",
    "reduced_x_d, max_accuracy = pca(x_d, y_d)\n",
    "print(f\"Best Accuracy: {max_accuracy}\")\n",
    "print(\"Trimmed x_d with Best Selected Features:\")\n",
    "print(np.shape(reduced_x_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bcf09",
   "metadata": {},
   "source": [
    "## ANN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca19135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01, 0.1, 0.3, 0.5], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X = reduced_x_d\n",
    "y = y_d\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # Tune the number of layers.\n",
    "        for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "            model.add(\n",
    "                layers.Dense(\n",
    "                    # Tune number of units separately.\n",
    "                    units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model.add(layers.Dense(14, activation=\"softmax\"))\n",
    "\n",
    "        learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.01, 0.1, 0.3, 0.5])\n",
    "#         alpha = hp.Choice(\"alpha\", [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate), #, momentum=alpha\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create an instance of HyperParameters\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "# Build the model with default hyperparameters\n",
    "my_hypermodel = MyHyperModel()\n",
    "my_model = my_hypermodel.build(hp)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=my_hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    factor=2,\n",
    "    directory=\"Parameter Tuning\",\n",
    "    project_name=\"14 Classes - Raw\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96f1d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.7857142686843872\n",
      "\n",
      "Best val_accuracy So Far: 0.8392857313156128\n",
      "Total elapsed time: 00h 06m 35s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.05, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02db1ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Parameter Tuning\\14 Classes - Raw\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0070 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: tanh\n",
      "batch_size: 32\n",
      "units_2: 480\n",
      "activation_2: relu\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0062\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0076 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: tanh\n",
      "batch_size: 32\n",
      "units_2: 480\n",
      "activation_2: relu\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 5\n",
      "tuner/round: 5\n",
      "tuner/trial_id: 0072\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0080 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 192\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 32\n",
      "activation_1: tanh\n",
      "batch_size: 16\n",
      "units_2: 512\n",
      "activation_2: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0106 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 480\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 352\n",
      "activation_1: tanh\n",
      "batch_size: 16\n",
      "units_2: 224\n",
      "activation_2: tanh\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 4\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0094\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0119 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 64\n",
      "activation_0: tanh\n",
      "learning_rate: 0.1\n",
      "units_1: 512\n",
      "activation_1: tanh\n",
      "batch_size: 128\n",
      "units_2: 64\n",
      "activation_2: tanh\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0114\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0165 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 384\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.3\n",
      "units_1: 384\n",
      "activation_1: relu\n",
      "batch_size: 16\n",
      "units_2: 320\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 50\n",
      "tuner/initial_epoch: 25\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0164\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0172 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 192\n",
      "activation_0: tanh\n",
      "learning_rate: 0.5\n",
      "units_1: 96\n",
      "activation_1: sigmoid\n",
      "batch_size: 128\n",
      "units_2: 512\n",
      "activation_2: relu\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8392857313156128\n",
      "\n",
      "Trial 0066 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 128\n",
      "activation_1: sigmoid\n",
      "batch_size: 128\n",
      "units_2: 320\n",
      "activation_2: tanh\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 5\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0055\n",
      "Score: 0.8214285969734192\n",
      "\n",
      "Trial 0067 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 128\n",
      "activation_1: sigmoid\n",
      "batch_size: 128\n",
      "units_2: 320\n",
      "activation_2: tanh\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 5\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0066\n",
      "Score: 0.8214285969734192\n",
      "\n",
      "Trial 0073 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "activation_0: sigmoid\n",
      "learning_rate: 0.1\n",
      "units_1: 128\n",
      "activation_1: sigmoid\n",
      "batch_size: 128\n",
      "units_2: 320\n",
      "activation_2: tanh\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 13\n",
      "tuner/bracket: 5\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0067\n",
      "Score: 0.8214285969734192\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e38f980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 3.4472 - accuracy: 0.5506 - val_loss: 1.5958 - val_accuracy: 0.6071\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.3541 - accuracy: 0.7777 - val_loss: 2.1821 - val_accuracy: 0.7321\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.5994 - accuracy: 0.8597 - val_loss: 4.7425 - val_accuracy: 0.7857\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.3091 - accuracy: 0.8845 - val_loss: 4.3685 - val_accuracy: 0.7857\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.8138 - accuracy: 0.9189 - val_loss: 3.7051 - val_accuracy: 0.8036\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.8947 - accuracy: 0.9256 - val_loss: 6.4563 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.4533 - accuracy: 0.9094 - val_loss: 10.1158 - val_accuracy: 0.7321\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.6670 - accuracy: 0.9027 - val_loss: 8.2895 - val_accuracy: 0.8036\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3335 - accuracy: 0.9046 - val_loss: 12.2227 - val_accuracy: 0.7679\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5367 - accuracy: 0.9294 - val_loss: 17.7671 - val_accuracy: 0.7321\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.5329 - accuracy: 0.9437 - val_loss: 23.0039 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.2751 - accuracy: 0.9656 - val_loss: 15.5148 - val_accuracy: 0.7679\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0199 - accuracy: 0.9676 - val_loss: 19.8669 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7393 - accuracy: 0.9742 - val_loss: 21.8342 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5400 - accuracy: 0.9676 - val_loss: 22.0687 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.4369 - accuracy: 0.9704 - val_loss: 26.2047 - val_accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.4597 - accuracy: 0.9656 - val_loss: 32.3241 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.1270 - accuracy: 0.9561 - val_loss: 33.2014 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.6991 - accuracy: 0.9656 - val_loss: 26.8079 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.4210 - accuracy: 0.9666 - val_loss: 26.2058 - val_accuracy: 0.8036\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0785 - accuracy: 0.9714 - val_loss: 26.4847 - val_accuracy: 0.8036\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.9847 - val_loss: 26.6049 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.9905 - val_loss: 25.3168 - val_accuracy: 0.7679\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2048 - accuracy: 0.9933 - val_loss: 25.6747 - val_accuracy: 0.7857\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9943 - val_loss: 29.1135 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9914 - val_loss: 29.8965 - val_accuracy: 0.7321\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9952 - val_loss: 36.5651 - val_accuracy: 0.6964\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9962 - val_loss: 29.9078 - val_accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9990 - val_loss: 28.7553 - val_accuracy: 0.7321\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 28.6553 - val_accuracy: 0.7321\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9990 - val_loss: 28.5096 - val_accuracy: 0.7321\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.5471e-05 - accuracy: 1.0000 - val_loss: 28.2289 - val_accuracy: 0.7321\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4006e-06 - accuracy: 1.0000 - val_loss: 28.2210 - val_accuracy: 0.7321\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.3959e-06 - accuracy: 1.0000 - val_loss: 28.2214 - val_accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7128e-06 - accuracy: 1.0000 - val_loss: 28.2217 - val_accuracy: 0.7321\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3556e-06 - accuracy: 1.0000 - val_loss: 28.2220 - val_accuracy: 0.7321\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0025e-06 - accuracy: 1.0000 - val_loss: 28.2223 - val_accuracy: 0.7321\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.7639e-06 - accuracy: 1.0000 - val_loss: 28.2225 - val_accuracy: 0.7321\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5903e-06 - accuracy: 1.0000 - val_loss: 28.2226 - val_accuracy: 0.7321\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4853e-06 - accuracy: 1.0000 - val_loss: 28.2228 - val_accuracy: 0.7321\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3390e-06 - accuracy: 1.0000 - val_loss: 28.2229 - val_accuracy: 0.7321\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.2357e-06 - accuracy: 1.0000 - val_loss: 28.2229 - val_accuracy: 0.7321\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.1571e-06 - accuracy: 1.0000 - val_loss: 28.2231 - val_accuracy: 0.7321\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0868e-06 - accuracy: 1.0000 - val_loss: 28.2232 - val_accuracy: 0.7321\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.0154e-06 - accuracy: 1.0000 - val_loss: 28.2232 - val_accuracy: 0.7321\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 9.6558e-07 - accuracy: 1.0000 - val_loss: 28.2233 - val_accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 9.0531e-07 - accuracy: 1.0000 - val_loss: 28.2233 - val_accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.6074e-07 - accuracy: 1.0000 - val_loss: 28.2234 - val_accuracy: 0.7321\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 8.2060e-07 - accuracy: 1.0000 - val_loss: 28.2234 - val_accuracy: 0.7321\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.7977e-07 - accuracy: 1.0000 - val_loss: 28.2235 - val_accuracy: 0.7321\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.4418e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 7.0960e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.8356e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.5308e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 6.2238e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.0202e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.7495e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.5164e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 5.3321e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 5.1229e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.9944e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 4.7783e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.6099e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.4678e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.3188e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 4.1789e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 4.0504e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.9218e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.8047e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.6819e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.5772e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.4737e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.3816e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.2792e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.1973e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 3.1052e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 3.0188e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.9414e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.8675e-07 - accuracy: 1.0000 - val_loss: 28.2238 - val_accuracy: 0.7321\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7890e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.7219e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.6491e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.5809e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.5172e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 2.4512e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.3921e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3352e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2772e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.2215e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.1623e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.1111e-07 - accuracy: 1.0000 - val_loss: 28.2237 - val_accuracy: 0.7321\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.0542e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 2.0076e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.9815e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.9109e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8654e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.8256e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.7801e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.7426e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.7051e-07 - accuracy: 1.0000 - val_loss: 28.2236 - val_accuracy: 0.7321\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 24.0160 - accuracy: 0.8333\n",
      "[test loss, test accuracy]: [24.016021728515625, 0.8333333134651184]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
    "\n",
    "# Check Result\n",
    "y_pred_a = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_a, axis=1)\n",
    "\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ded1ce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIhCAYAAABpMPNPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8c0lEQVR4nO3deVxU5f4H8M+wDQiCIIGggLjlhgq4gZK7XVLU2y/33JcsS9HcsShNUW+pWW64p5Vamqll5VZJaqmomZoriimIoIKAbMP5/dF1bgMDDHYO5zz2eb9e87rNc84858Nzn5n5zvHMMzpJkiQQEREREWmQldoBiIiIiIhKwmKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWINOvXX3/FsGHD4O/vD3t7ezg5OSEoKAgLFizA3bt3FT32yZMn0a5dO7i4uECn02Hx4sWyH0On0+Gtt96Svd+yrF+/HjqdDjqdDt9//32x7ZIkoU6dOtDpdGjfvv1jHWPZsmVYv359uR7z/fffl5iJiP65bNQOQERkzqpVq/DKK6/g6aefxuTJk9GwYUPk5+fj+PHjWLFiBY4cOYIvvvhCseMPHz4cWVlZ2Lx5M1xdXVGzZk3Zj3HkyBHUqFFD9n4tVblyZaxZs6ZYQfrDDz/gypUrqFy58mP3vWzZMri7u2Po0KEWPyYoKAhHjhxBw4YNH/u4RPTkYbFKRJpz5MgRvPzyy+jSpQt27NgBvV5v3NalSxe8/vrr+OabbxTN8Ntvv2HUqFEIDw9X7BitW7dWrG9L9O3bFx9//DGWLl0KZ2dnY/uaNWsQEhKCjIyMCsmRn58PnU4HZ2dn1ceEiLSHlwEQkebMnTsXOp0OsbGxJoXqI3Z2dujRo4fxfmFhIRYsWID69etDr9fDw8MDgwcPxh9//GHyuPbt26Nx48Y4duwYwsLCUKlSJdSqVQvz5s1DYWEhgP/9E3lBQQGWL19u/OdyAHjrrbeM//1Xjx5z7do1Y9uBAwfQvn17VK1aFQ4ODvD19cX//d//ITs727iPucsAfvvtN/Ts2ROurq6wt7dHs2bNsGHDBpN9Hv1z+aeffoqoqCh4e3vD2dkZnTt3xoULFywbZAD9+/cHAHz66afGtvT0dGzbtg3Dhw83+5i3334brVq1gpubG5ydnREUFIQ1a9ZAkiTjPjVr1sTZs2fxww8/GMfv0ZnpR9k3btyI119/HdWrV4der8fly5eLXQaQmpoKHx8fhIaGIj8/39j/uXPn4OjoiEGDBln8txKRuFisEpGmGAwGHDhwAMHBwfDx8bHoMS+//DKmTp2KLl26YOfOnZg9eza++eYbhIaGIjU11WTf5ORkDBw4EC+++CJ27tyJ8PBwTJ8+HZs2bQIAdOvWDUeOHAEAvPDCCzhy5IjxvqWuXbuGbt26wc7ODmvXrsU333yDefPmwdHREXl5eSU+7sKFCwgNDcXZs2exZMkSbN++HQ0bNsTQoUOxYMGCYvvPmDED169fx+rVqxEbG4tLly4hIiICBoPBopzOzs544YUXsHbtWmPbp59+CisrK/Tt27fEv+2ll17C1q1bsX37djz//PN47bXXMHv2bOM+X3zxBWrVqoXAwEDj+BW9ZGP69OlITEzEihUrsGvXLnh4eBQ7lru7OzZv3oxjx45h6tSpAIDs7Gz07t0bvr6+WLFihUV/JxEJTiIi0pDk5GQJgNSvXz+L9j9//rwEQHrllVdM2n/++WcJgDRjxgxjW7t27SQA0s8//2yyb8OGDaVnn33WpA2ANHbsWJO26OhoydzL5rp16yQAUkJCgiRJkvT5559LAKRTp06Vmh2AFB0dbbzfr18/Sa/XS4mJiSb7hYeHS5UqVZLu378vSZIkHTx4UAIgPffccyb7bd26VQIgHTlypNTjPsp77NgxY1+//fabJEmS1KJFC2no0KGSJElSo0aNpHbt2pXYj8FgkPLz86VZs2ZJVatWlQoLC43bSnrso+M988wzJW47ePCgSfv8+fMlANIXX3whDRkyRHJwcJB+/fXXUv9GInpy8MwqEQnt4MGDAFDsizwtW7ZEgwYNsH//fpP2atWqoWXLliZtTZo0wfXr12XL1KxZM9jZ2WH06NHYsGEDrl69atHjDhw4gE6dOhU7ozx06FBkZ2cXO8P710shgD//DgDl+lvatWuH2rVrY+3atThz5gyOHTtW4iUAjzJ27twZLi4usLa2hq2tLd58802kpaUhJSXF4uP+3//9n8X7Tp48Gd26dUP//v2xYcMGfPDBBwgICLD48UQkNharRKQp7u7uqFSpEhISEizaPy0tDQDg5eVVbJu3t7dx+yNVq1Yttp9er8fDhw8fI615tWvXxr59++Dh4YGxY8eidu3aqF27Nt5///1SH5eWllbi3/Fo+18V/VseXd9bnr9Fp9Nh2LBh2LRpE1asWIF69eohLCzM7L6//PILunbtCuDP1Rp++uknHDt2DFFRUeU+rrm/s7SMQ4cORU5ODqpVq8ZrVYn+YVisEpGmWFtbo1OnTjhx4kSxL0iZ86hgS0pKKrbt1q1bcHd3ly2bvb09ACA3N9ekveh1sQAQFhaGXbt2IT09HUePHkVISAgiIyOxefPmEvuvWrVqiX8HAFn/lr8aOnQoUlNTsWLFCgwbNqzE/TZv3gxbW1vs3r0bffr0QWhoKJo3b/5YxzT3RbWSJCUlYezYsWjWrBnS0tIwadKkxzomEYmJxSoRac706dMhSRJGjRpl9gtJ+fn52LVrFwCgY8eOAGD8gtQjx44dw/nz59GpUyfZcj36Rvuvv/5q0v4oiznW1tZo1aoVli5dCgCIj48vcd9OnTrhwIEDxuL0kY8++giVKlVSbFmn6tWrY/LkyYiIiMCQIUNK3E+n08HGxgbW1tbGtocPH2Ljxo3F9pXrbLXBYED//v2h0+mwZ88exMTE4IMPPsD27dv/dt9EJAaus0pEmhMSEoLly5fjlVdeQXBwMF5++WU0atQI+fn5OHnyJGJjY9G4cWNERETg6aefxujRo/HBBx/AysoK4eHhuHbtGt544w34+PhgwoQJsuV67rnn4ObmhhEjRmDWrFmwsbHB+vXrcePGDZP9VqxYgQMHDqBbt27w9fVFTk6O8Rv3nTt3LrH/6Oho7N69Gx06dMCbb74JNzc3fPzxx/jqq6+wYMECuLi4yPa3FDVv3rwy9+nWrRsWLlyIAQMGYPTo0UhLS8O7775rdnmxgIAAbN68GVu2bEGtWrVgb2//WNeZRkdH49ChQ/juu+9QrVo1vP766/jhhx8wYsQIBAYGwt/fv9x9EpFYWKwSkSaNGjUKLVu2xKJFizB//nwkJyfD1tYW9erVw4ABA/Dqq68a912+fDlq166NNWvWYOnSpXBxccG//vUvxMTEmL1G9XE5Ozvjm2++QWRkJF588UVUqVIFI0eORHh4OEaOHGncr1mzZvjuu+8QHR2N5ORkODk5oXHjxti5c6fxmk9znn76aRw+fBgzZszA2LFj8fDhQzRo0ADr1q0r1y9BKaVjx45Yu3Yt5s+fj4iICFSvXh2jRo2Ch4cHRowYYbLv22+/jaSkJIwaNQoPHjyAn5+fyTq0lti7dy9iYmLwxhtvmJwhX79+PQIDA9G3b1/ExcXBzs5Ojj+PiDRKJ0l/WcmZiIiIiEhDeM0qEREREWkWi1UiIiIi0iwWq0RERESkWSxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERESa9UT+KED7xYfVjlBuX4xupXaEcnGwsy57Jw25m1n8Jzu1zM1JvEXOH+YZ1I5QLqLNYRGJNidEwzlMorO3sArlmVUiIiIi0iwWq0RERESkWSxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaL+HfTatg+qjn2jwvB95GhGNXGt8R91w9qhu8jQzG7+9MVmLBsG9asQtP6teBZxQFujjZYMHeW2pHKNHrEULhWdkAlOytUc3fF2jWr1I5UohEv9kZDf0/4VHWA31OOCGn2NA79sF/tWGUSaYxFnMOAWGMMiJVXtDkhWt5HRJoTAPNWBC1kZrFahJPeBjfvP8TWEzdL3W9UG194uehhKJQqKJnl0jPuo3bdeoh8faraUSwyc8Y0bPzoI7w4aAi+3L0HDRo0wGuvjMHxY8fUjmbW6ZMn8Hzv/li/+QusXPcpDAYDhvT9N9LS7qgdrUSijbFocxgQb4xFyyvanBAtLyDenGBe5Wkls06SJO1VW39T+8WHZenn+8hQfHzsD6z6KdGkvd5Tjljevwne2PU7ZkfUx+Grd/HG7gt/61hfjG71tx5fEjdHG0yLehNTZrwpa78Odtay9eXt4Qb/WrXw09Hjxjb3Kk5o0bIV9nwnzxnLu5l5svRjztXLFxHWIgDzFy3Fi0NHytKnm5OdLP08UhFj/DDPIEs/RYkwh4GKGWM5cU5UHM5hZTCv8pTObG9j2X6qnln9448/EBUVhQ4dOqBBgwZo2LAhOnTogKioKNy4cUPNaCWyAvDe/zXCT1fu4nDCPbXjCC8rMxP37t3Dv8K7mbQ3DgjA2bO/qZSqfFJu3wYAeHl5q5zEvCdhjLVOtDEWLS8pT7Q5wbzK01Jm1YrVuLg4NGjQAF988QWaNm2KwYMH48UXX0TTpk2xY8cONGrUCD/99FOZ/eTm5iIjI8PkVlig3Fm0eb0aoFCS8OZXf+9MKv3p6tUrAAC/mjVN2p96ygNZmZkqJCqfwsJCRL4yHFXd3dHp2efUjmOW6GMsAtHGWLS8pDzR5gTzKk9LmS08ASu/CRMmYOTIkVi0aFGJ2yMjI3GsjOsiYmJi8Pbbb5u0+T07HDX/NUK2rI90ftodzX2rYPSnp2Xv+5/OSqczuS9JElCkTYsiuoQh5fZt7Pz2B7WjlEnUMRaJaGMsWl5SnmhzgnmVp4XMqp1Z/e233zBmzJgSt7/00kv47beyTzNPnz4d6enpJjffzoPkjGrUrm5V6HTAqgFNcXB8CA6OD4G1lQ5ta7th/7gQRY75pKtVqzYAICEhwaQ9NfUOHB0d1YhksYgubXHut1+xdee3aNw0UO04JRJ5jEUh2hiLlpeUJ9qcYF7laSmzasWql5cXDh8u+YtQR44cgZeXV5n96PV6ODs7m9ysbOT9csojKw5dxxu7L5jcDIUSziU/wLQvzylyzCedo5MTXF1d8e2er03afztzBo0aNVYpVekKCwvRvXNb/PbraXz8+W40b6ntDyoijrFoRBtj0fKS8kSbE8yrPC1lVq1YnTRpEsaMGYNXX30VX375JY4ePYqff/4ZX375JV599VW8/PLLmDJlSoXncq1kgw71qqJDvaoAAF9XB3SoVxUNqjnhZnoO4q7cNbkBwN2sfBy7nl7hWUtyJ+U2du/8Art3fgEAuHTxAnbv/ALxJ7S5PMbwkaNx4sQJjH/tFez97lt0fKYNHj58iFnvzFU7mlndO7fFr6fiMWvee3B/6ilc/P0cLv5+Dun3tPuFO9HGWLQ5DIg3xqLlFW1OiJYXEG9OMK/ytJJZ1aWrtmzZgkWLFuHEiRMwGP5c4sTa2hrBwcGYOHEi+vTp81j9/p2lq14I9MKr7fyLtd+8/xAD158s1r5/XIjmlq5au2oFJkW+Wqy9QaPG+OmXU7IcQ+4lU0aPGIqtW7YgLy8Xzs4umBMzDyNGvSRb/3IuXVXdVW+2fdiol/HOgsWyHEPupasA5cdYzmWKRJzDgPJjLDfOCeVwDlcM5lWekpktXbpKE+us5ufnIzU1FQDg7u4OW1vbv9WfXOusViSl1llVihIvkkpScp1VJShRrCpNqTU1lSLaHBaRaHNCNJzDJDpLi1XVVgP4K1tbW4uuTyUiIiKifxb+3CoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIsnSRJktoh5JZToHaC8uuz9pjaEcpl6/AWakcol7uZeWpHKBc3Jzu1I5SbaL8Dz99VVx7nBBGVxt7Gsv14ZpWIiIiINIvFKhERERFpFotVIiIiItIsFqtEREREpFksVomIiIhIs1isEhEREZFmsVglIiIiIs1isUpEREREmsVilYiIiIg0i8UqEREREWkWi1ULrVy+DPXr+qOKkz1CWwYjLu6Q2pEAAI2qOWHms3WxbmBT7BzdAq38qphs7x/sjWV9GmPrsCB8MiQQs56rh3pPOaoTthRaHV9zPli4AM91DEU9n6poUrcGhg98AZcvXVA7VplEGuPDcT+i/ws90bC2D9wcbfDVri/VjmQRkcYYECuviHNCpPF9RLTMzKs8LWRmsWqBz7ZuweTXIzF1WhSOHjuJ0LZh6NU9HImJiWpHg97WGglp2Yj9yXyWm/dzsPKnRLz2+VlM3XkeKZl5eLtbPThb+oO8FUDL42vO0cM/YsjIMdj13SF8uv1rFBQUYMDz3ZGdlaV2tBKJNsZZWVloHNAE8xcuUTuKxUQbY9HyijYnRBtfQLzMzKs8rWTWSZIkVegRK0BOgbz9hYW2QmBgEJYsXW5saxbQABE9emH2nBhZjtFn7bG/3cfO0S0w59tL+Pn6/RL3cbC1wpZhwZi5+3f8euvBYx9r6/AWj/3YoipifO9m5snSjzlpqXfQpG4NbNu9D63bhMnSp5uTnSz9PFIRY/wwzyBLP0W5Odpg4+Zt6BbRU9Z+HeysZe2vIsZYTpwTxck5J0SbD4B4mZlXeUpntvS8Gc+sliEvLw8n40+gU5euJu2dOnfF0SOHVUr1eGysdHi2gQcycwuQkPZQ7TgAnozxzchIBwBUcXVTOYl5T8IYa51oYyxaXtGIOL6iZWZe5Wkps3b+LdiMGzduIDo6GmvXri1xn9zcXOTm5pq0SdZ66PV6WTKkpqbCYDDAw8PTpN3T0xO3byfLcgylNfd1weROtaG3scK97Hy8+fVFPMiV+fTzYxJ9fCVJwttRU9CydRvUb9hI7ThmiT7GIhBtjEXLKxoRx1e0zMyrPC1l1vSZ1bt372LDhg2l7hMTEwMXFxeT23/my386XafTmdyXJKlYm1adufUAkdvOYuqX5xF/Ix1TO9WGi4auWQXEHd+oyeNx/uxvWLr6I7WjlEnUMRaJaGMsWl7RiDi+omVmXuVpIbOqFcvOnTtL3X716tUy+5g+fTomTpxo0iZZy3NWFQDc3d1hbW1d7FNESkpKsU8bWpVbUIikjFwkZeTiQkoWVvQNQJf6T+HzU0lqRxN6fGdOicR3e77C9q/3wbt6DbXjlEjkMRaFaGMsWl7RiDi+omVmXuVpKbOqZ1Z79eqFf//73+jVq5fZW9Ei1By9Xg9nZ2eTm1yXAACAnZ0dAoOCcWDfXpP2A/v3onVIqGzHqUg6ALbW2vgkJ+L4SpKEqMnjsWf3l9i68xv4+vmrHalUIo6xaEQbY9HyikbE8RUtM/MqT0uZVT2z6uXlhaVLl6JXr15mt586dQrBwcEVG8qMcZETMWLoIAQFN0er1iFYszoWNxITMXL0GLWjwd7GCl4u/yvOPZ318K/qgAc5BjzILUCfQC/8cv0+7mbno7LeBs818kBVRzvEXb2rYmpTWh5fc2ZMGocdn2/B2k8+h5NTZaT891NnZWcXODg4qJzOPNHGODMzEwlXLhvvX7+WgDOnT8HVzQ01fHxVTFYy0cZYtLyizQnRxhcQLzPzKk8rmVUtVoODgxEfH19isarT6aCFlbV69+mLu2lpmDtnFpKTktCoUWPs2PU1/Pz81I6GOk85Ym5EfeP9kSF/vmjvv5CKZXHXUKOKAzrWc4ezvQ0ycgpw+U4Wpu36HTfu5agVuRgtj685H62NBQC80L2LSfvCpavQd8BgNSKVSbQxPhV/HD3COxvvz5w2CQDQf+BgLI0t+QuXahJtjEXLK9qcEG18AfEyM6/ytJJZ1XVWDx06hKysLPzrX/8yuz0rKwvHjx9Hu3btytWv3OusVgQ51lmtSHKus1oRlFxnVQlyr7NaEZRaU1Mpcq+zSsVxThBRaSz9rreqZ1bDwkpfQN3R0bHchSoRERERPTk0vXQVEREREf2zsVglIiIiIs1isUpEREREmsVilYiIiIg0i8UqEREREWkWi1UiIiIi0iwWq0RERESkWSxWiYiIiEizWKwSERERkWaxWCUiIiIizdJJkiSpHUJuOQVqJ3jyubZ4Ve0I5XLrp/fVjlAu/I1yIiJ60tnbWLYfz6wSERERkWaxWCUiIiIizWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFqoZXLl6F+XX9UcbJHaMtgxMUdUjtSqbSad9LwrojbNBkpce/i+v4YbF04CnX9PIzbbWys8M64nji2dQZSD7+Hq9/NwerZg+D1lIuKqU0djvsR/V/oiYa1feDmaIOvdn2pdiSLaHVOlES0vIB4mZlXWaLlBcTLzLzK00JmFqsW+GzrFkx+PRJTp0Xh6LGTCG0bhl7dw5GYmKh2NLO0nDcsqA5WbPkR7Qa/i+4vfwhra2vsXv4qKtnbAQAq2duhWQMfzFu1ByH956Pf66tQ19cDny1+SeXk/5OVlYXGAU0wf+EStaNYTMtzwhzR8gLiZWZeZYmWFxAvM/MqTyuZdZIkSRV6xAqQUyBvf2GhrRAYGIQlS5cb25oFNEBEj16YPSdG3oPJoCLyurZ4VZZ+3F2dcOPAPHQesQg/xV8xu09wQ1/EfTwF9cLfwI3ke491nFs/vf93YpbIzdEGGzdvQ7eInrL262BnLWt/nMPKEy0z8ypLtLyAeJmZV3lKZ7a3sWw/nlktQ15eHk7Gn0CnLl1N2jt17oqjRw6rlKpkouV1drIHANxLzy55n8oOKCwsxP0HDysq1hNFtDkhWl5AvMzMqyzR8gLiZWZe5Wkps+rF6sOHDxEXF4dz584V25aTk4OPPvqo1Mfn5uYiIyPD5JabmytbvtTUVBgMBnh4eJq0e3p64vbtZNmOIxfR8s5//f/wU/xlnLuSZHa73s4Gs8f1xJY9x/EgK6eC0z0ZRJsTouUFxMvMvMoSLS8gXmbmVZ6WMqtarF68eBENGjTAM888g4CAALRv3x5JSf8rWtLT0zFs2LBS+4iJiYGLi4vJ7T/z5T+drtPpTO5LklSsTUtEyLtoWh8E1PXGkOnrzW63sbHCxnnDYKXTYXzM1ooN9wQSYU78lWh5AfEyM6+yRMsLiJeZeZWnhcyqFqtTp05FQEAAUlJScOHCBTg7O6NNmzblunB3+vTpSE9PN7lNnjpdtozu7u6wtrYu9ikiJSWl2KcNLRAl78KpvdG9XQCeHbUEN1PuF9tuY2OFj+ePgF/1quj+8oc8q/o3iDInHhEtLyBeZuZVlmh5AfEyM6/ytJRZ1WL18OHDmDt3Ltzd3VGnTh3s3LkT4eHhCAsLw9WrVy3qQ6/Xw9nZ2eSm1+tly2hnZ4fAoGAc2LfXpP3A/r1oHRIq23HkIkLeRVN7o2fHpvjXS0tw/VZase2PCtXavk+h25gPcTc9S4WUTw4R5sRfiZYXEC8z8ypLtLyAeJmZV3laymzh97CU8fDhQ9jYmEZYunQprKys0K5dO3zyyScqJTM1LnIiRgwdhKDg5mjVOgRrVsfiRmIiRo4eo3Y0s7Scd/H0Pugb3hy9J8QiMysHnlUrAwDSM3OQk5sPa2srfPKfkQis74Pnx6+AtZXOuM/d9GzkFxjUjA8AyMzMRMKVy8b7168l4MzpU3B1c0MNH18Vk5VMy3PCHNHyAuJlZl5liZYXEC8z8ypPK5lVLVbr16+P48ePo0GDBibtH3zwASRJQo8ePVRKZqp3n764m5aGuXNmITkpCY0aNcaOXV/Dz89P7WhmaTnvS32eAQDsXR1p0j7qzY3YtOtnVPeogoj2TQAAv2wxvZyj68j3cejEpQrJWZpT8cfRI7yz8f7MaZMAAP0HDsbS2LVqxSqVlueEOaLlBcTLzLzKEi0vIF5m5lWeVjKrus5qTEwMDh06hK+//trs9ldeeQUrVqxAYWFhufqVe51VKk6udVYrilLrrCpF7nVWiYiItMbSdVb5owD0WFisKovFKhERPen4owBEREREJDwWq0RERESkWSxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZT+TPrd7LNqgdodz485rKGrXltNoRymVV36ZqRyi3h3liPe/4nFOeaHNCNJzDVJRozznXSpbNYZ5ZJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIsFqtEREREpFksVomIiIhIs1isEhEREZFmsVglIiIiIs1isUpEREREmsVi1QKH435E/xd6omFtH7g52uCrXV+qHalMK5cvQ/26/qjiZI/QlsGIizukdqRSaTnv0x6OmNiuJpb8uyE2DmyK4BrOxm3WOqBvMy/M7VYPq/s2xpJ/N8RLIT6o4mCjYmLztDzGRYn4nAPEGmNArLyizQnR8j4i0pwAmFdJWprDLFYtkJWVhcYBTTB/4RK1o1jks61bMPn1SEydFoWjx04itG0YenUPR2JiotrRzNJ6Xr2NFRLv5+Cj4zeLbbOzsUJNNwfsOHMbM7++hPd/vIZqznpMaOevQtKSaX2MixLtOQeIN8ai5RVtToiWFxBvTjCvsrQ0h3WSJElqh5DbvWyDYn27Odpg4+Zt6BbRU9Z+HeysZesrLLQVAgODsGTpcmNbs4AGiOjRC7PnxMh2HLlURN5RW07L0s/GgU2x+IcEnPgjo8R9/N0cMCu8HiK/OIe07PzHOs6qvk0fN6JZFTHGD/OUed6J8JwD+LwzR7Q5oRTOYWUwb3GiPedcK1k2h3lm9QmTl5eHk/En0KlLV5P2Tp274uiRwyqlKploeS1Ryc4ahZKELIVeNMrrSRxjrRFtjEXLS8oTbU4w7z+L6hfWnT9/HkePHkVISAjq16+P33//He+//z5yc3Px4osvomPHjqU+Pjc3F7m5uaZtBhvo9XolY2tWamoqDAYDPDw8Tdo9PT1x+3aySqlKJlrestha6dCnmReOXLuPnIJCteMAePLGWItEG2PR8pLyRJsTzPvPouqZ1W+++QbNmjXDpEmTEBgYiG+++QbPPPMMLl++jMTERDz77LM4cOBAqX3ExMTAxcXF5Lbo3XkV9Bdol06nM7kvSVKxNi0RLa851jpgbFs/WOmA9b/8oXacYp6EMdY60cZYtLykPNHmBPP+M6harM6aNQuTJ09GWloa1q1bhwEDBmDUqFHYu3cv9u3bhylTpmDevNILz+nTpyM9Pd3kNmHStAr6C7TH3d0d1tbWxT6ppaSkFPtEpwWi5S2JtQ54NawmnnKyw/z9VzVzVhV4csZYy0QbY9HykvJEmxPM+8+iarF69uxZDB06FADQp08fPHjwAP/3f/9n3N6/f3/8+uuvpfah1+vh7OxscvunXgIAAHZ2dggMCsaBfXtN2g/s34vWIaEqpSqZaHnNeVSoVqtsh3n7ryBTI9eqPvIkjLHWiTbGouUl5Yk2J5j3n0X1a1YfsbKygr29PapUqWJsq1y5MtLT09UL9V+ZmZlIuHLZeP/6tQScOX0Krm5uqOHjq2Iy88ZFTsSIoYMQFNwcrVqHYM3qWNxITMTI0WPUjmaW1vPqbazgWdnOeP8pJzv4utojK9eAew/z8VpYTdR0c8DC7xNgpdPBxf7Pp1VmngGGQm0stqH1MS5KtOccIN4Yi5ZXtDkhWl5AvDnBvMrS0hxWtVitWbMmLl++jDp16gAAjhw5Al/f/w3AjRs34OXlpVY8o1Pxx9EjvLPx/sxpkwAA/QcOxtLYtWrFKlHvPn1xNy0Nc+fMQnJSEho1aowdu76Gn5+f2tHM0npefzcHRHWpY7w/MLg6AODQlbvYfiYZwT4uAIA53Z42edycvZfxe0pWxQUthdbHuCjRnnOAeGMsWl7R5oRoeQHx5gTzKktLc1jVdVZXrFgBHx8fdOvWzez2qKgo3L59G6tXry5Xv0qus6oUudfLI1NyrbNaUeReZ7UiKLW+n1L4nFOeaHNCNJzDVJRozzlL11nljwJoBF90lMViVXmivUjyOac80eaEaDiHqSjRnnP8UQAiIiIiEh6LVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIs/tyqRvBn85Ql2k/Qef/fErUjlNu9XRPUjvBEE20OA3xdI6LS2dtYth/PrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIsFqtEREREpFksVomIiIhIs1isEhEREZFmsVglIiIiIs1isWqBw3E/ov8LPdGwtg/cHG3w1a4v1Y5UppXLl6F+XX9UcbJHaMtgxMUdUjtSqUTKq/X5MKlPC8S93x8p28bi+qcvYesbEahb3bXYflEDW+PqplG4u+M1fDv/BTTwrapC2pKJNCceESmz1uexOSKNLyBeXkC8zMyrPC1kZrFqgaysLDQOaIL5C8X4vfbPtm7B5NcjMXVaFI4eO4nQtmHo1T0ciYmJakczS7S8Wp8PYQE1sGLXabSbsBndZ2yDtbUVds95HpX0//sR5td7N8e454MwYdlBtB3/CW7fy8ZXc5+Hk4Otisn/R7Q5AYiXWevzuCjRxle0vIB4mZlXeVrJrJMkSarQI5ZBkiTodLq/1ce9bINMaYpzc7TBxs3b0C2ip6z9OthZy9ZXWGgrBAYGYcnS5ca2ZgENENGjF2bPiZHtOHKpiLwP85SZE0rNB+//k6+AcHdxwI3NY9B58lb89NtNAMDVj0dj6Y54vPfZcQCAna01rn8yGjPXxmHNnjOPdZx7uybIllm0OQwon1mpOQzwdU0JouUFxMvMvMpTOrO9Tdn7ABo8s6rX63H+/Hm1YwgrLy8PJ+NPoFOXribtnTp3xdEjh1VKVTLR8orIuZIdAODegxwAQM1qLvByc8S++OvGffLyDTh05iZaN/RWJeNfiTgnRMwsEtHGV7S8gHiZmVd5WspsYU0rv4kTJ5ptNxgMmDdvHqpW/fP6uYULF5baT25uLnJzc03bDDbQ6/XyBBVMamoqDAYDPDw8Tdo9PT1x+3aySqlKJlpeEc0f3Q4//XYT566nAQCquVYCAKTcyzbZL+V+Nnw9Kld4vqJEnBMiZhaJaOMrWl5AvMzMqzwtZVatWF28eDGaNm2KKlWqmLRLkoTz58/D0dHRossBYmJi8Pbbb5u0TZnxBqZFRcsZVzhFx06OyyuUJFpeUSx6pQMC/N3RadLWYtuKXgCkM9OmJhHnhIiZRSLa+IqWFxAvM/MqTwuZVStW58yZg1WrVuG9995Dx44dje22trZYv349GjZsaFE/06dPL3aWNtug2p+lOnd3d1hbWxf71JOSklLs05EWiJZXJAtfbo/urWuj8+StuJmaaWxP/u8ZVU+3Ski+l2Vsf6pKJaTczy7WT0UTcU6ImFkkoo2vaHkB8TIzr/K0lFm1a1anT5+OLVu24OWXX8akSZOQn5//WP3o9Xo4Ozub3P6plwAAgJ2dHQKDgnFg316T9gP796J1SKhKqUomWl5RLHq5A3qG1sW/pn2O67czTLZdS05H0t0sdAr0M7bZ2lghLKA6jp67VdFRixFxToiYWSSija9oeQHxMjOv8rSUWdVTkC1atMCJEycwduxYNG/eHJs2bdLk6fDMzEwkXLlsvH/9WgLOnD4FVzc31PDxVTGZeeMiJ2LE0EEICm6OVq1DsGZ1LG4kJmLk6DFqRzNLtLxanw+Lx3ZE3/ZPo/esnch8mAfP/16jmp6Vi5z/fqN86Y54TO7bApdv3cPlm/cxpW9LPMwtwJbvf1czupFocwIQL7PW53FRoo2vaHkB8TIzr/K0kln1fy93cnLChg0bsHnzZnTp0gUGg3LLszyuU/HH0SO8s/H+zGmTAAD9Bw7G0ti1asUqUe8+fXE3LQ1z58xCclISGjVqjB27voafn1/ZD1aBaHm1Ph9e6t4UALB3QR+T9lHvfYtN+84BAN777Djs7WyweGwnuDrpcexCMrpHbUfmw8f7Fw65iTYnAPEya30eFyXa+IqWFxAvM/MqTyuZNbXO6h9//IETJ06gc+fOcHR0fOx+lFxnVSlyrkdIxSm5RqUS5FxntaLIuc4qFSfaHAb4ukZEpbN0nVXVz6z+VY0aNVCjRg21YxARERGRRmjuRwGIiIiIiB5hsUpEREREmsVilYiIiIg0i8UqEREREWkWi1UiIiIi0iwWq0RERESkWSxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERESapZMkSVI7hNzuZfM3tIkqWtt5B9WOUC5x0zqoHeGJ9zBPrNdivg4TVSx7G8v245lVIiIiItIsFqtEREREpFksVomIiIhIs1isEhEREZFmsVglIiIiIs1isUpEREREmsVilYiIiIg0i8UqEREREWkWi1UiIiIi0iwWq0RERESkWSxWLXA47kf0f6EnGtb2gZujDb7a9aXakcq0cvky1K/rjypO9ghtGYy4uENqRyqVaHkB8TJrOW+grwsW9gnAnvGhOD6zA9rVczfZHh1RH8dndjC5rRsapFLakml5jM0RKS9fhyuGaJmZV3layMxi1QJZWVloHNAE8xcuUTuKRT7bugWTX4/E1GlROHrsJELbhqFX93AkJiaqHc0s0fIC4mXWel4HW2tcSsnEgm8ulrjPT5fT8Oyin4y38Zt/rcCEZdP6GBclWl6+DitPtMzMqzytZNZJkiRV6BErwL1sg2J9uznaYOPmbegW0VPWfh3srGXrKyy0FQIDg7Bk6XJjW7OABojo0Quz58TIdhy5iJYXEC9zReRtO++gLP0cn9kBr289gx8uphrboiPqo7K9DSZ99pssxwCAuGkdZOsL4Jww52GeMq/FfB1WhmiZmVd5Sme2t7FsP55ZfcLk5eXhZPwJdOrS1aS9U+euOHrksEqpSiZaXkC8zKLlLUmwXxV8N6ENtr3cClHdnoZrJVu1IxmJNsai5RWNiOMrWmbmVZ6WMltY01aMe/fuYcOGDbh06RK8vLwwZMgQ+Pj4lPqY3Nxc5ObmmrYZbKDX65WMqlmpqakwGAzw8PA0aff09MTt28kqpSqZaHkB8TKLltecw1fuYt/5O0hOz4F3FXuMaeePFS82w4trjiPfoP4/Dok2xqLlFY2I4ytaZuZVnpYyq3pm1dvbG2lpaQCAhIQENGzYEPPnz8elS5ewcuVKBAQE4Pfffy+1j5iYGLi4uJjcFr07ryLia5pOpzO5L0lSsTYtES0vIF5m0fL+1d5zKfjpchqu3MnCoUtpGLf5V/hWrYS2daqqHc2EaGMsWl7RiDi+omVmXuVpIbOqxWpycjIMhj+vaZoxYwbq16+PK1eu4LvvvsPly5cRFhaGN954o9Q+pk+fjvT0dJPbhEnTKiK+Jrm7u8Pa2rrYp56UlJRin460QLS8gHiZRctribTMPCSl58DXrZLaUQCIN8ai5RWNiOMrWmbmVZ6WMmvmmtWff/4Zb7zxBipV+vPNR6/XY+bMmTh69Gipj9Pr9XB2dja5/VMvAQAAOzs7BAYF48C+vSbtB/bvReuQUJVSlUy0vIB4mUXLawkXBxt4OuuRmplb9s4VQLQxFi2vaEQcX9EyM6/ytJRZ9WtWH51Kzs3Nhadn8esi7ty5o0YsE5mZmUi4ctl4//q1BJw5fQqubm6o4eOrYjLzxkVOxIihgxAU3BytWodgzepY3EhMxMjRY9SOZpZoeQHxMms9r4OtNXzcHIz3q1exRz1PJ6Q/zEfGwwKMfqYmDvx+B6mZefCuYo9X2tfC/ex8HLyQWkqvFUvrY1yUaHn5Oqw80TIzr/K0kln1YrVTp06wsbFBRkYGLl68iEaNGhm3JSYmwt3dvZRHV4xT8cfRI7yz8f7MaZMAAP0HDsbS2LVqxSpR7z59cTctDXPnzEJyUhIaNWqMHbu+hp+fn9rRzBItLyBeZq3nbehdGSsHBRrvT+xaFwCw63QS5u25iDoeTujWpBoq29sgNTMPx6/dw4wvziJboaWRHofWx7go0fLydVh5omVmXuVpJbOq66y+/fbbJvdbt26NZ5991nh/8uTJ+OOPP/Dpp5+Wq18l11lVipzr+xGpQa51ViuK3OusUnFKrbOqFL4OE1UsS9dZ5Y8CaARfJEl0LFapKBarRFQa/igAEREREQmPxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINMui3w7YuXOnxR326NHjscMQEREREf2VRT+3amVl2QlYnU4Hg0H9n9fLKVA7ARFpnWvEIrUjlMu9XRPUjkBEJCtLf27Vot0KCwv/ThYiIiIiosfyt65ZzcnJkSsHEREREVEx5S5WDQYDZs+ejerVq8PJyQlXr14FALzxxhtYs2aN7AGJiIiI6J+r3MXqnDlzsH79eixYsAB2dnbG9oCAAKxevVrWcERERET0z1buYvWjjz5CbGwsBg4cCGtra2N7kyZN8Pvvv8sajoiIiIj+2cpdrN68eRN16tQp1l5YWIj8/HxZQhERERERAY9RrDZq1AiHDh0q1v7ZZ58hMDBQllBERERERICFS1f9VXR0NAYNGoSbN2+isLAQ27dvx4ULF/DRRx9h9+7dSmQkIiIion+ocp9ZjYiIwJYtW/D1119Dp9PhzTffxPnz57Fr1y506dJFiYxERERE9A9V7jOrAPDss8/i2WeflTsLEREREZGJx/5RgOPHj2Pjxo3YtGkTTpw4IWcmTVq5fBnq1/VHFSd7hLYMRlxc8et2tYR5lSdaZuaVx6Q+LRD3fn+kbBuL65++hK1vRKBudddi+0UNbI2rm0bh7o7X8O38F9DAt6oKaUun1TEuCfMqT7TMzKs8LWQud7H6xx9/ICwsDC1btsT48eMxbtw4tGjRAm3btsWNGzeUyKi6z7ZuweTXIzF1WhSOHjuJ0LZh6NU9HImJiWpHM4t5lSdaZuaVT1hADazYdRrtJmxG9xnbYG1thd1znkcl/f/+oer13s0x7vkgTFh2EG3Hf4Lb97Lx1dzn4eRgq2JyU1oeY3OYV3miZWZe5Wkls06SJKk8D+jatSsyMjKwYcMGPP300wCACxcuYPjw4XB0dMR3332nSNDyyCmQt7+w0FYIDAzCkqXLjW3NAhogokcvzJ4TI+/BZMC8yhMtM/MW5xqxSJZ+3F0ccGPzGHSevBU//XYTAHD149FYuiMe7312HABgZ2uN65+Mxsy1cViz58xjHefergmy5H2Ec0JZouUFxMvMvMpTOrO9hRejlvvM6qFDh7B8+XJjoQoATz/9ND744AOzS1qJLi8vDyfjT6BTl64m7Z06d8XRI4dVSlUy5lWeaJmZV1nOlf78Jb97D3IAADWrucDLzRH74q8b98nLN+DQmZto3dBblYxFiTbGzKs80TIzr/K0lLncxaqvr6/Zxf8LCgpQvXr1cvV18uRJJCQkGO9v2rQJbdq0gY+PD9q2bYvNmzeX2Udubi4yMjJMbrm5ueXKUZrU1FQYDAZ4eHiatHt6euL27WTZjiMX5lWeaJmZV1nzR7fDT7/dxLnraQCAaq6VAAAp97JN9ku5nw3P/25Tm2hjzLzKEy0z8ypPS5nLXawuWLAAr732Go4fP45HVxAcP34c48ePx7vvvluuvkaMGIFr164BAFavXo3Ro0ejefPmiIqKQosWLTBq1CisXbu21D5iYmLg4uJicvvPfPlPp+t0OpP7kiQVa9MS5lWeaJmZV36LXumAAH93DJn/dbFtRS+w0plpU5sIY/xXzKs80TIzr/K0kNmiqwVcXV1NgmVlZaFVq1awsfnz4QUFBbCxscHw4cPRq1cviw9+4cIF1K5dGwCwbNkyLF68GKNHjzZub9GiBebMmYPhw4eX2Mf06dMxceJEkzbJWm9xhrK4u7vD2tq62KeIlJSUYp82tIB5lSdaZuZVxsKX26N769roPHkrbqZmGtuT/3tG1dOtEpLvZRnbn6pSCSn3s4v1owZRxvgR5lWeaJmZV3laymzRmdXFixdj0aJFxltsbCzWrl2L2NhYk/9etKh8X1hwcHDAnTt3AAA3b95Eq1atTLa3atXK5DIBc/R6PZydnU1uer18xaqdnR0Cg4JxYN9ek/YD+/eidUiobMeRC/MqT7TMzCu/RS93QM/QuvjXtM9x/XaGybZryelIupuFToF+xjZbGyuEBVTH0XO3KjqqWSKM8V8xr/JEy8y8ytNSZovOrA4ZMkSRg4eHh2P58uVYvXo12rVrh88//xxNmzY1bt+6dSvq1KmjyLHLY1zkRIwYOghBwc3RqnUI1qyOxY3ERIwcPUbtaGYxr/JEy8y88lk8tiP6tn8avWftRObDPON1qOlZucjJMwAAlu6Ix+S+LXD51j1cvnkfU/q2xMPcAmz5/nc1o5vQ8hibw7zKEy0z8ypPK5kf6xesHnn48GGxL1s5Oztb/Pj58+ejTZs2aNeuHZo3b4733nsP33//PRo0aIALFy7g6NGj+OKLL/5ORFn07tMXd9PSMHfOLCQnJaFRo8bYsetr+Pn5lf1gFTCv8kTLzLzyean7nx+o9y7oY9I+6r1vsWnfOQDAe58dh72dDRaP7QRXJz2OXUhG96jtyHxY/MupatHyGJvDvMoTLTPzKk8rmcu9zmpWVhamTp2KrVu3Ii0trdh2g8FQrgD379/HvHnzsGvXLly9ehWFhYXw8vJCmzZtMGHCBDRv3rxc/QHyr7NKRE8eudZZrShyr7NKRKQ2S9dZLXexOnbsWBw8eBCzZs3C4MGDsXTpUty8eRMrV67EvHnzMHDgwMfJKysWq0RUFharRETqsrRYLfdlALt27cJHH32E9u3bY/jw4QgLC0OdOnXg5+eHjz/+WBPFKhERERE9Gcq9zurdu3fh7+8P4M/rU+/evQsAaNu2LX788Ud50xERERHRP1q5i9VatWoZF/Jv2LAhtm7dCuDPM65VqlSRMxsRERER/cOVu1gdNmwYTp8+DeDPBfmXLVsGvV6PCRMmYPLkybIHJCIiIqJ/rnJ/waqoxMREHD9+HLVr1zZZI1VN/IIVEZWFX7AiIlKXpV+wKveZ1aJ8fX3x/PPPw83NrdSfRSUiIiIiKq+/Xaw+cvfuXWzYsEGu7oiIiIiI5CtWiYiIiIjkxmKViIiIiDSLxSoRERERaZbFv2D1/PPPl7r9/v37fzcLkWIe5hnUjlAuDnbWakcot7uZeWpHKBfRvl1ftd86tSOUW9rmYWpHKBfR5rCbk53aEcpFtNdhQMzX4ieRxcWqi4tLmdsHDx78twMRERERET1icbG6bp14n+qJiIiISGy8ZpWIiIiINIvFKhERERFpFotVIiIiItIsFqtEREREpFksVomIiIhIsx6rWN24cSPatGkDb29vXL9+HQCwePFifPnll7KGIyIiIqJ/tnIXq8uXL8fEiRPx3HPP4f79+zAY/lzkt0qVKli8eLHc+YiIiIjoH6zcxeoHH3yAVatWISoqCtbW//tlh+bNm+PMmTOyhiMiIiKif7ZyF6sJCQkIDAws1q7X65GVlSVLKC1auXwZ6tf1RxUne4S2DEZc3CG1I5WKeZVzOO5H9H+hJxrW9oGbow2+2iXG5S+ijPEHCxfguY6hqOdTFU3q1sDwgS/g8qULaseyiFbHuE0DT3w2rRMux/ZF1ufD0L2Fr8l2Dxd7rBzbFpdj++LOx4OwI6oLaldzViltybQ6vuaIOo9FGmMRX4tFGt9HtJC53MWqv78/Tp06Vax9z549aNiwoRyZNOezrVsw+fVITJ0WhaPHTiK0bRh6dQ9HYmKi2tHMYl5lZWVloXFAE8xfuETtKBYTaYyPHv4RQ0aOwa7vDuHT7V+joKAAA57vjmyNfxjW8hg72tvgzLV7mLjmqNntm6d0Qk3Pyugzfz9CJ3+JxDtZ2B39LCrpLf6RQ8VpeXzNEXEeizbGor0Wiza+gHYy6yRJksrzgHXr1uGNN97Ae++9hxEjRmD16tW4cuUKYmJisHr1avTr10+prBbLKZC3v7DQVggMDMKSpcuNbc0CGiCiRy/MnhMj78FkwLzFPcwzyNJPUW6ONti4eRu6RfSUtV8HO+uydyqHihjju5l5svRTVFrqHTSpWwPbdu9D6zZhsvXr5mQnW1+A8mNctZ88P3md9fkw9J2/H7uP/flmU8fLGac/+D80j/wC5/+4DwCwstLh2pp+eGPTcWzYf+mxj5W2eZgckQGIPYcBZeaxaHNYqddhQIzXYtHemwHlM9tb+Hm43GdWhw0bhujoaEyZMgXZ2dkYMGAAVqxYgffff18Tharc8vLycDL+BDp16WrS3qlzVxw9clilVCVjXipK9DHOyEgHAFRxdVM5SclEHmO97Z9vxjn5/yskCgsl5BcUIrS+p1qxTIg8vo9ofR4/CWOsZSKOr5YyP9bSVaNGjcL169eRkpKC5ORk3LhxAyNGjCh3P6+99hoOHfp71z7k5uYiIyPD5Jabm/u3+vyr1NRUGAwGeHiYvmh7enri9u1k2Y4jF+alokQeY0mS8HbUFLRs3Qb1GzZSO06JRB7jCzfv43rKA7w9MBhVHO1ga2OF13sFoJprJVRzraR2PABijy8gxjwWfYy1TsTx1VLmv/WjAO7u7vDw8Hjsxy9duhTt27dHvXr1MH/+fCQnl/+Pj4mJgYuLi8ntP/PlP52u0+lM7kuSVKxNS5iXihJxjKMmj8f5s79h6eqP1I5iERHHuMAgYcC7B1HXyxk3NwxE6seDENaoGr6N/wOGwnJdJaY4EccXEGseizrGohBxfLWQudxXz/v7+5ca8urVq+Xq77vvvsOuXbvw7rvv4o033kB4eDhGjRqF5557DlZWZdfS06dPx8SJE03aJGt9uTKUxt3dHdbW1sU+RaSkpBT7tKEFzEtFiTrGM6dE4rs9X2H71/vgXb2G2nFKJeoYP3LqahpCJu+EcyVb2NlYITUjF9/HdEf8lVS1owEQe3xFmccij7EIRBxfLWUu95nVyMhIjB8/3nh75ZVXEBISgvT0dIwePbrcAQICArB48WLcunULmzZtQm5uLnr16gUfHx9ERUXh8uXLpT5er9fD2dnZ5KbXy1es2tnZITAoGAf27TVpP7B/L1qHhMp2HLkwLxUl2hhLkoSoyeOxZ/eX2LrzG/j6+asdqUyijXFJMrLzkZqRi9rVnBFUqyq+OqaNbymLOL6izWMRx1gkIo6vljKX+8zq+PHjzbYvXboUx48ff+wgtra26NOnD/r06YPExESsXbsW69evx7x584y/kqWWcZETMWLoIAQFN0er1iFYszoWNxITMXL0GFVzlYR5lZWZmYmEK//7EHX9WgLOnD4FVzc31PDxLeWR6hFpjGdMGocdn2/B2k8+h5NTZaT891N9ZWcXODg4qJyuZFoeY0d7G5N1U2t6OqFJTTfczczFH6lZ+HdITaRm5ODGnUw08nPDf4a1xK5jidh/+paKqU1peXzNEXEeizbGor0Wiza+gHYyl3vpqpJcvXoVzZo1Q0ZGhsWPsbKyQnJyconXvUqShH379qFLly7lyiL30lXAn4viLnxvAZKTktCoUWMseG8R2oY9I/+BZMK8puRcMiXux+/RI7xzsfb+AwdjaexaWY4h99JVgPJjLNeyP9Vdzf/LyMKlq9B3wGBZjgHIv+wPoOwY/52lq8IaVcM3b4cXa9908BJeWhqHl59rgMgeAfBwsUfy/Yf45IfLmPf5aeQXFP6dyLIuXQWIM4eBipnHos1huZeuEvG1WLT3ZkDZzJYuXSVbsbpgwQIsW7YM165ds/gx/v7+OH78OKpWrSpHBCMlilUSm5Lr+ylBiWJVaUquUakEJd7olSTXOqsVSe5iVWmcw8oS7XUYEPO1WCSWFqvlvgwgMDDQ5AtWkiQhOTkZd+7cwbJly8rVV0JCQnkPT0RERET/IOUuVnv16mVy38rKCk899RTat2+P+vXry5WLiIiIiKh8xWpBQQFq1qyJZ599FtWqVVMqExERERERgHIuXWVjY4OXX35Z1l+IIiIiIiIqSbnXWW3VqhVOnjypRBYiIiIiIhPlvmb1lVdeweuvv44//vgDwcHBcHR0NNnepEkT2cIRERER0T+bxcXq8OHDsXjxYvTt2xcAMG7cOOM2nU5n/K1YtRfwJyIiIqInh8XF6oYNGzBv3jwuN0VEREREFcbiYvXRbwf4+fkpFoaIiIiI6K/K9QWrv/4YABERERGR0sr1Bat69eqVWbDevXv3bwUiIiIiInqkXMXq22+/DRcXF6WyyIa/P0xFcXyVJ9rvlIsmbfMwtSOUW9t5B9WOUC5x0zqoHYGIzChXsdqvXz94eHgolYWIiIiIyITF16zyelUiIiIiqmgWF6uPVgMgIiIiIqooFl8GUFhYqGQOIiIiIqJiyrV0FRERERFRRWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFYtcDjuR/R/oSca1vaBm6MNvtr1pdqRyrRy+TLUr+uPKk72CG0ZjLi4Q2pHKpVoeQHxMjOv8kTLrNW8gb4uWNgnAHvGh+L4zA5oV8/dZHt0RH0cn9nB5LZuaJBKaUum1fEtjUiZ+d5cMbSQmcWqBbKystA4oAnmL1yidhSLfLZ1Cya/Homp06Jw9NhJhLYNQ6/u4UhMTFQ7mlmi5QXEy8y8yhMts5bzOtha41JKJhZ8c7HEfX66nIZnF/1kvI3f/GsFJiyblse3JKJl5nuz8rSSWSc9gT9NdS/boFjfbo422Lh5G7pF9JS1Xwc7a9n6CgtthcDAICxZutzY1iygASJ69MLsOTGyHUcuouUFxMvMvMoTLXNF5G077+Df7uP4zA54fesZ/HAx1dgWHVEfle1tMOmz3/52/38VN62DbH2JNh8A5TM/zON7M+eEKXsLf5qKZ1afMHl5eTgZfwKdunQ1ae/UuSuOHjmsUqqSiZYXEC8z8ypPtMyi5TUn2K8KvpvQBtteboWobk/DtZKt2pGMRBxfETOLRMTx1VJm1YvVDz74AEOGDMHWrVsBABs3bkTDhg1Rv359zJgxAwUFBaU+Pjc3FxkZGSa33NzcioiuSampqTAYDPDw8DRp9/T0xO3bySqlKploeQHxMjOv8kTLLFreog5fuYuZO87j5U2nsHjfZTT0qowVLzaDrbVO7WgAxBxfETOLRMTx1VJmVYvV2bNnIyoqCllZWRg/fjzmz5+PCRMmYODAgRgyZAhWr16N2bNnl9pHTEwMXFxcTG6L3p1XQX+Bdul0pi/akiQVa9MS0fIC4mVmXuWJllm0vI/sPZeCny6n4cqdLBy6lIZxm3+Fb9VKaFunqtrRTIg4viJmFomI46uFzBZeLaCM9evXY/369Xj++edx+vRpBAcHY8OGDRg4cCAAoH79+pgyZQrefvvtEvuYPn06Jk6caNKWbVD1z1KVu7s7rK2ti33qSUlJKfbpSAtEywuIl5l5lSdaZtHyliUtMw9J6TnwdaukdhQAYo6viJlFIuL4aimzqmdWk5KS0Lx5cwBA06ZNYWVlhWbNmhm3BwUF4datW6X2odfr4ezsbHLT6/VKxtY0Ozs7BAYF48C+vSbtB/bvReuQUJVSlUy0vIB4mZlXeaJlFi1vWVwcbODprEdqpjYuARNxfEXMLBIRx1dLmVU9BVmtWjWcO3cOvr6+uHTpEgwGA86dO4dGjRoBAM6ePQsPDw81IwIAMjMzkXDlsvH+9WsJOHP6FFzd3FDDx1fFZOaNi5yIEUMHISi4OVq1DsGa1bG4kZiIkaPHqB3NLNHyAuJlZl7liZZZy3kdbK3h4+ZgvF+9ij3qeToh/WE+Mh4WYPQzNXHg9ztIzcyDdxV7vNK+Fu5n5+PghdRSeq1YWh7fkoiWme/NytNKZlWL1QEDBmDw4MHo2bMn9u/fj6lTp2LSpElIS0uDTqfDnDlz8MILL6gZEQBwKv44eoR3Nt6fOW0SAKD/wMFYGrtWrVgl6t2nL+6mpWHunFlITkpCo0aNsWPX1/Dz81M7mlmi5QXEy8y8yhMts5bzNvSujJWDAo33J3atCwDYdToJ8/ZcRB0PJ3RrUg2V7W2QmpmH49fuYcYXZ5Gt4NJI5aXl8S2JaJn53qw8rWRWdZ1Vg8GAefPm4ejRo2jbti2mTp2KzZs3Y8qUKcjOzkZERAQ+/PBDODo6lqtfJddZVYqca7kREWmBHOusViQ511ml4pRcZ1UpfG9WlqXrrPJHATSCTwgietKwWKW/YrFKRfFHAYiIiIhIeCxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLOeyJ9bzSlQOwERad3dzDy1I5SLiD/7KFrmplHfqh2hXI5Gd1Y7QrmINh8A8X4iVrQx5s+tEhEREZHwWKwSERERkWaxWCUiIiIizWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYtdDK5ctQv64/qjjZI7RlMOLiDqkdqVTMqzzRMjOvcj5YuADPdQxFPZ+qaFK3BoYPfAGXL11QO1apDsf9iP4v9ETD2j5wc7TBV7u+VDtSmbQ8J5r7u2L5kEAcimqHC/OfRaeGHsX2qeXhiOVDAnH87Y6In9UJW8a2glcVexXSFififAC0PSeK4hg/PharFvhs6xZMfj0SU6dF4eixkwhtG4Ze3cORmJiodjSzmFd5omVmXmUdPfwjhowcg13fHcKn279GQUEBBjzfHdlZWWpHK1FWVhYaBzTB/IVL1I5iEa3PiUp21riQ9ACzdpw3u93HzQGfjGmJqylZGLTyGHosPoxl+68gN7+wgpOaJ9p8ALQ/J4riGD8+nSRJUoUesQLkFMjbX1hoKwQGBmHJ0uXGtmYBDRDRoxdmz4mR92AyYF7liZaZeYu7m5knSz/mpKXeQZO6NbBt9z60bhMmS58Odtay9GOOm6MNNm7ehm4RPWXtV87MFTEnmkZ9K0s/F+Y/i1c2nMT+cynGtoUDmqDAIGHKljOyHAMAjkZ3lq2vvxJhPgAVMyce5hlk6acojvGf7G0s20/VM6tJSUl488030bFjRzRo0ACNGzdGREQE1qxZA4NBmQlSXnl5eTgZfwKdunQ1ae/UuSuOHjmsUqqSMa/yRMvMvBUvIyMdAFDF1U3lJE8G0eeETge0r/8UrqVmYfWIYBx+oz22jm1l9lIBsozoc0IEWhpj1YrV48ePo0GDBti1axdycnJw8eJFBAUFwdHREZMmTUJYWBgePHhQZj+5ubnIyMgwueXm5sqWMzU1FQaDAR4enibtnp6euH07WbbjyIV5lSdaZuatWJIk4e2oKWjZug3qN2ykdpwnguhzoqqjHRz1NhjV3h+HLqRi+OoT2Hs2BR8OaoYW/q5qxxOS6HNCBFoaY9WK1cjISEyYMAEnT57E4cOHsWHDBly8eBGbN2/G1atX8fDhQ8ycObPMfmJiYuDi4mJy+898+f9ZU6fTmdyXJKlYm5Ywr/JEy8y8FSNq8nicP/sblq7+SO0oTxxR54TVfzPuP3sHG+Ku4/ekB1j1fQK+//0O+rX2UTmd2ESdEyLRwhirVqzGx8dj0KBBxvsDBgxAfHw8bt++DVdXVyxYsACff/55mf1Mnz4d6enpJrfJU6fLltPd3R3W1tbFPkWkpKQU+7ShBcyrPNEyM2/FmTklEt/t+Qqf7foW3tVrqB3niSHynACAe9l5yDcU4kpKpkn7lZQseGtkNQDRiD4nRKClMVatWPXw8EBSUpLx/u3bt1FQUABnZ2cAQN26dXH37t0y+9Hr9XB2dja56fV62XLa2dkhMCgYB/btNWk/sH8vWoeEynYcuTCv8kTLzLzKkyQJUZPHY8/uL7F15zfw9fNXO9ITRcQ58Vf5Bgln/kiH/1OOJu013Svh5r0clVKJTfQ5IQItjbGF38OSX69evTBmzBj85z//gV6vx+zZs9GuXTs4ODgAAC5cuIDq1aurFc/EuMiJGDF0EIKCm6NV6xCsWR2LG4mJGDl6jNrRzGJe5YmWmXmVNWPSOOz4fAvWfvI5nJwqI+W/ZyIqO7sYX9O0JjMzEwlXLhvvX7+WgDOnT8HVzQ01fHxVTGae1udEJTtr+FatZLxfw80B9b0qI/1hPpLu52DND9ewaEBTHEu4h5+v3EVYPXd0aPAUBsceUzH1/4g2HwDtz4miOMaPT7Vi9Z133kFSUhIiIiJgMBgQEhKCTZs2GbfrdDrExGhjSZ3effribloa5s6ZheSkJDRq1Bg7dn0NPz8/taOZxbzKEy0z8yrro7WxAIAXuncxaV+4dBX6DhisRqQynYo/jh7h/1v6aOa0SQCA/gMHY2nsWrVilUjrc6JxDWdsfKml8f6MiPoAgO3Hb2L6Z79h39kUvPXFOYzu4I+ZPeoj4U4Wxm06hRPX7quU2JRo8wHQ/pwoimP8+FRfZzUnJwcFBQVwcnKSr0+Z11kloiePkuusKkHJdVaVIlpmudZZrShKrbOqFNHmA6DcOqtKEW2MLV1nVbUzq4/Y2/PiciIiIiIyjz+3SkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINEsnSZKkdgi55RSonYC0hr/vTFTx+LxTVo2Rm9WOUC5/rO6ndoRy4xxWlr2NZfvxzCoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIsFqsWWrl8GerX9UcVJ3uEtgxGXNwhtSOVinmVczjuR/R/oSca1vaBm6MNvtr1pdqRLCLSGAPi5QXEyyxSXhGfd1oe35B6T+HjyDD8tqgnUtf3Q3hQdZPtjnobzHsxCL8u7IEbsS/g8NxwDOtQR6W0JdPyGBcl4hwGtDHGqherWVlZWLVqFYYNG4bw8HA899xzGDZsGFavXo2srCy14wEAPtu6BZNfj8TUaVE4euwkQtuGoVf3cCQmJqodzSzmVVZWVhYaBzTB/IVL1I5iMdHGWLS8gHiZRcsr2vNO6+NbSW+D3xLvY+qmE2a3vzMgEB0DvPBy7FGEztiDFd9eRMyLQQgPrG52fzVofYyLEm0OA9oZY50kSVKFHvEvzp07hy5duiA7Oxvt2rWDp6cnJElCSkoKfvjhBzg6OuK7775Dw4YNy9VvToG8OcNCWyEwMAhLli43tjULaICIHr0we06MvAeTAfMW9zDPIEs/Rbk52mDj5m3oFtFT1n4d7Kxl7Y9zQnmiZebzrjg5n3cVMb41Rm6WpZ/U9f0waMkh7Im/aWw79M6/sOOXG3hv51lj2/63umLvr0mYt/3MYx3nj9X9/nbWv+IcLk609w57G8v2U/XM6tixY/HMM8/g9u3b2LFjB1auXInY2Fjs2LEDt2/fxjPPPIOxY8eqGRF5eXk4GX8Cnbp0NWnv1Lkrjh45rFKqkjEvFSXaGIuWFxAvs2h5RfMkjO/Pl1Lxr2beqFbFAQDQtr4HantWxsEzSSon+9OTMMZap6UxtrCmVcbPP/+M48ePw87Ortg2Ozs7zJgxAy1btiy1j9zcXOTm5pq0SdZ66PV6WTKmpqbCYDDAw8PTpN3T0xO3byfLcgw5MS8VJdoYi5YXEC+zaHlF8ySM7/RN8Vg0rAV+W9wT+QWFKJQkRK47hp8vpaodDcCTMcZap6UxVvXMqqurKy5dulTi9suXL8PV1bXUPmJiYuDi4mJy+898+f/JTafTmdyXJKlYm5YwLxUl2hiLlhcQL7NoeUUj8viO7lIXzWtXxcDFP6LTW9/izc2n8J9BwXimoWfZD65AIo+xKLQwxqqeWR01ahSGDBmCmTNnokuXLvD09IROp0NycjL27t2LuXPnIjIystQ+pk+fjokTJ5q0SdbynFUFAHd3d1hbWxf7FJGSklLs04YWMC8VJdoYi5YXEC+zaHlFI/r42ttaI+qFJhjyQRz2nv7zn/3P/ZGOAN8qGBteHz+eu61yQvHHWARaGmNVz6y+9dZbmD59OhYuXIjAwEBUr14d3t7eCAwMxMKFCzFt2jS8+eabpfah1+vh7OxscpPrEgDgz8sRAoOCcWDfXpP2A/v3onVIqGzHkQvzUlGijbFoeQHxMouWVzSij6+NtQ52NtYoLDRtNxRKsNLIWUvRx1gEWhpjVc+sAsDUqVMxdepUJCQkIDn5z+q9WrVq8Pf3VznZ/4yLnIgRQwchKLg5WrUOwZrVsbiRmIiRo8eoHc0s5lVWZmYmEq5cNt6/fi0BZ06fgqubG2r4+KqYrGSijbFoeQHxMouWV7TnndbH11FvA39PJ+N9P3dHNPatgnuZebh5Nxs//Z6Ct/o2RU6+ATdSsxBa3wN92tTEm5+eUi90EVof46JEm8OAdsZY9WL1EX9//2IF6o0bNxAdHY21a9eqlOpPvfv0xd20NMydMwvJSUlo1Kgxduz6Gn5+fqrmKgnzKutU/HH0CO9svD9z2iQAQP+Bg7E0Vt25WhLRxli0vIB4mUXLK9rzTuvj28zfDV9O62i8/86AIADAp3EJeG31zxi1/DBmvtAEK15qjSqOdvgjLRtzt53BuoOXS+qywml9jIsSbQ4D2hljVddZLcvp06cRFBQEg6F865zJvc4qiU+ptfKUIvdaeURq4PNOWXKts1pR5F5ntSJwDivL0nVWVT2zunPnzlK3X716tYKSEBEREZEWqVqs9urVCzqdDqWd3OUSFERERET/XKquBuDl5YVt27ahsLDQ7C0+Pl7NeERERESkMlWL1eDg4FIL0rLOuhIRERHRk03VywAmT56MrKysErfXqVMHBw8erMBERERERKQlqharYWFhpW53dHREu3btKigNEREREWmNqpcBEBERERGVhsUqEREREWkWi1UiIiIi0iwWq0RERESkWSxWiYiIiEizdNITuJBpToHaCUhr+PvORETq6rP2mNoRym3r8BZqR3ii2Vu4JhXPrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIsFqtEREREpFksVomIiIhIs1isEhEREZFmsVglIiIiIs1isWqhlcuXoX5df1Rxskdoy2DExR1SO1KpmFc5h+N+RP8XeqJhbR+4Odrgq11fqh3JIiKNMSBeXkC8zMyrLNHyAtrN3KiaE2Y+WxfrBjbFztEt0Mqvisn2/sHeWNanMbYOC8InQwIx67l6qPeUozphS6HV8S2NFjJruli9ffs2Zs2apXYMfLZ1Cya/Homp06Jw9NhJhLYNQ6/u4UhMTFQ7mlnMq6ysrCw0DmiC+QuXqB3FYqKNsWh5AfEyM6+yRMsLaDuz3tYaCWnZiP3JfJab93Ow8qdEvPb5WUzdeR4pmXl4u1s9OFv64/MVQMvjWxKtZNZJkiRV6BHL4fTp0wgKCoLBYCjX43IK5M0RFtoKgYFBWLJ0ubGtWUADRPTohdlzYuQ9mAyYt7iHeeWbQ5Zyc7TBxs3b0C2ip6z9OthZy9of54TyRMvMvMoSLS+gfOY+a4/97T4AYOfoFpjz7SX8fP1+ifs42Fphy7BgzNz9O3699eCxj7V1eIvHfmxRnBPFWfpZQtUzq7/++muptwsXLqgZDwCQl5eHk/En0KlLV5P2Tp274uiRwyqlKhnzUlGijbFoeQHxMjOvskTLC4iZuSQ2Vjo828ADmbkFSEh7qHYcAGKOr5Yyq3p+vFmzZtDpdDB3cvdRu06nK7WP3Nxc5ObmmrRJ1nro9XpZMqampsJgMMDDw9Ok3dPTE7dvJ8tyDDkxLxUl2hiLlhcQLzPzKku0vICYmYtq7uuCyZ1qQ29jhXvZ+Xjz64t4kCvzP7U+JhHHV0uZVT2zWrVqVaxatQoJCQnFblevXsXu3bvL7CMmJgYuLi4mt//Ml/90etGi2ZJCWk3MS0WJNsai5QXEy8y8yhItLyBm5kfO3HqAyG1nMfXL84i/kY6pnWrDRUPXrAJijq8WMqv6/2JwcDBu3boFPz8/s9vv379v9qzrX02fPh0TJ040aZOs5TmrCgDu7u6wtrYu9ikiJSWl2KcNLWBeKkq0MRYtLyBeZuZVlmh5ATEzF5VbUIikjFwkZeTiQkoWVvQNQJf6T+HzU0lqRxNyfLWUWdUzqy+99BJq1qxZ4nZfX1+sW7eu1D70ej2cnZ1NbnJdAgAAdnZ2CAwKxoF9e03aD+zfi9YhobIdRy7MS0WJNsai5QXEy8y8yhItLyBm5rLoANhaa+OspYjjq6XMqp5Z/fe//13qdldXVwwZMqSC0pRsXOREjBg6CEHBzdGqdQjWrI7FjcREjBw9Ru1oZjGvsjIzM5Fw5bLx/vVrCThz+hRc3dxQw8dXxWQlE22MRcsLiJeZeZUlWl5A25ntbazg5fK/E1Geznr4V3XAgxwDHuQWoE+gF365fh93s/NRWW+D5xp5oKqjHeKu3lUxtSktj29JtJJZWxdzFHHjxg1ER0dj7dq1qubo3acv7qalYe6cWUhOSkKjRo2xY9fXJV6+oDbmVdap+OPoEd7ZeH/mtEkAgP4DB2NprLpztSSijbFoeQHxMjOvskTLC2g7c52nHDE3or7x/siQP08M7L+QimVx11CjigM61nOHs70NMnIKcPlOFqbt+h037uWoFbkYLY9vSbSSmeus0j+CUuusKkXudVaJiNQm1zqrFUnOdVapOEu//6bqmdWdO3eWuv3q1asVlISIiIiItEjVYrVXr14lrrP6iNaXdCAiIiIi5ai6GoCXlxe2bduGwsJCs7f4+Hg14xERERGRylQtVoODg0stSMs660pERERETzZVLwOYPHkysrKyStxep04dHDx4sAITEREREZGWqFqshoWFlbrd0dER7dq1q6A0RERERKQ1ql4GQERERERUGharRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLN0klP4EKm97LF+h14gL8Fr7S7mXlqRygXNyc7tSOU28M8sZ53fM6R6PicU16ftcfUjlAuW4e3UDtCudhbuCYVz6wSERERkWaxWCUiIiIizWKxSkRERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFqgcNxP6L/Cz3RsLYP3Bxt8NWuL9WOVKaVy5ehfl1/VHGyR2jLYMTFHVI7UqlEyvvBwgV4rmMo6vlURZO6NTB84Au4fOmC2rHKJNIYi/icA8QaY4B5lSZSXj7n5NeomhNmPlsX6wY2xc7RLdDKr4rJ9v7B3ljWpzG2DgvCJ0MCMeu5eqj3lKM6YUuhhTHWRLH6xx9/IDMzs1h7fn4+fvzxRxUSmcrKykLjgCaYv3CJ2lEs8tnWLZj8eiSmTovC0WMnEdo2DL26hyMxMVHtaGaJlvfo4R8xZOQY7PruED7d/jUKCgow4PnuyM7KUjtaiUQbY9Gec4B4Y8y8yhItL59z8tPbWiMhLRuxP5nPc/N+Dlb+lIjXPj+LqTvPIyUzD293qwdne5sKTloyrYyxTpIkqUKP+BdJSUno2bMnTpw4AZ1Oh4EDB2Lp0qVwcnICANy+fRve3t4wGAzl6vdedvn2Lw83Rxts3LwN3SJ6ytqvg521bH2FhbZCYGAQlixdbmxrFtAAET16YfacGNmOI5eKyHs3M0+WfsxJS72DJnVrYNvufWjdJkyWPt2c7GTp55GKGOOHeco870R4zgF83imNeYvjc075Me6z9pgs/ewc3QJzvr2En6/fL3EfB1srbBkWjJm7f8evtx481nG2Dm/xmAnNU3qMLa3LVT2zOm3aNFhbW+Pnn3/GN998g3PnzqF9+/a4d++ecR8Va2kh5eXl4WT8CXTq0tWkvVPnrjh65LBKqUomWl5zMjLSAQBVXN1UTmLekzDGWifaGDOvskTLK6InbYxtrHR4toEHMnMLkJD2UO04ALQ1xqqea963bx+++OILNG/eHAAQFhaGvn37omPHjti/fz8AQKfTldpHbm4ucnNzTdsMNtDr9cqE1rjU1FQYDAZ4eHiatHt6euL27WSVUpVMtLxFSZKEt6OmoGXrNqjfsJHaccwSfYxFINoYM6+yRMsroidljJv7umByp9rQ21jhXnY+3vz6Ih7kFqgdC4C2xljVM6vp6elwdXU13tfr9fj8889Rs2ZNdOjQASkpKWX2ERMTAxcXF5PbonfnKRlbCEWLfEmSyiz81SRa3keiJo/H+bO/Yenqj9SOUiZRx1gkoo0x8ypLtLwiEn2Mz9x6gMhtZzH1y/OIv5GOqZ1qw0VD16wC2hhjVYvVWrVq4ddffzVps7GxwWeffYZatWqhe/fuZfYxffp0pKenm9wmTJqmVGTNc3d3h7W1dbFPPSkpKcU+HWmBaHn/auaUSHy35yt8tutbeFevoXacEok8xqIQbYyZV1mi5RXRkzLGuQWFSMrIxYWULHzw4zUYJAld6j+ldiwA2hpjVYvV8PBwxMbGFmt/VLA2a9aszGtW9Xo9nJ2dTW7/1EsAAMDOzg6BQcE4sG+vSfuB/XvROiRUpVQlEy0v8OenyqjJ47Fn95fYuvMb+Pr5qx2pVCKOsWhEG2PmVZZoeUX0pI6xDoCttTbODGtpjFU91zxnzhxkZ2eb3WZjY4Pt27fjjz/+qOBUxWVmZiLhymXj/evXEnDm9Cm4urmhho+visnMGxc5ESOGDkJQcHO0ah2CNatjcSMxESNHj1E7mlmi5Z0xaRx2fL4Faz/5HE5OlZHy30+dlZ1d4ODgoHI680QbY9Gec4B4Y8y8yhItL59z8rO3sYKXy/9Onnk66+Ff1QEPcgx4kFuAPoFe+OX6fdzNzkdlvQ2ea+SBqo52iLt6V8XUprQyxqoWqzY2NnB2di5x+61bt/D2229j7dq1FZiquFPxx9EjvLPx/sxpkwAA/QcOxtJYdbOZ07tPX9xNS8PcObOQnJSERo0aY8eur+Hn56d2NLNEy/vR2j//NeCF7l1M2hcuXYW+AwarEalMoo2xaM85QLwxZl5liZaXzzn51XnKEXMj6hvvjwz5s+jffyEVy+KuoUYVB3Ss5w5nextk5BTg8p0sTNv1O27cy1ErcjFaGWNV11kty+nTpxEUFKSpdVaVIvf6c2RKyXVWlSD3OqsVQak1H5XC5xyJjs855cm1zmpFkXudVaVZ+l0yVc+s7ty5s9TtV69eraAkRERERKRFqharvXr1gk6nK/VLVCItQUFERERE8lJ1NQAvLy9s27YNhYWFZm/x8fFqxiMiIiIilalarAYHB5dakJZ11pWIiIiInmyqXgYwefJkZGVllbi9Tp06OHjwYAUmIiIiIiItUbVYDQsLK3W7o6Mj2rVrV0FpiIiIiEhrVL0MgIiIiIioNCxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERESapZOewIVMcwrUTkBaw9/QJqp4oj3vRMPXCSrKNWKR2hHK5eGeCRbtxzOrRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIiIiItIsFqtEREREpFksVomIiIhIs1isWmjl8mWoX9cfVZzsEdoyGHFxh9SOVCrmVc7huB/R/4WeaFjbB26ONvhq15dqR7KISGMMiJcXEC+zSHlFe96JlvcRkeYEwLxymdSnBeLe74+UbWNx/dOXsPWNCNSt7lpsv6iBrXF10yjc3fEavp3/Ahr4Vq2QfKoXq2lpaTh48CDu3r0LAEhNTcX8+fMxa9YsnD9/XuV0f/ps6xZMfj0SU6dF4eixkwhtG4Ze3cORmJiodjSzmFdZWVlZaBzQBPMXLlE7isVEG2PR8gLiZRYtr2jPO9HyAuLNCeaVT1hADazYdRrtJmxG9xnbYG1thd1znkclvY1xn9d7N8e454MwYdlBtB3/CW7fy8ZXc5+Hk4Ot4vl0kiRJih+lBL/88gu6du2KjIwMVKlSBXv37kXv3r1hY2MDSZJw8+ZNxMXFISgoqFz95hTImzMstBUCA4OwZOlyY1uzgAaI6NELs+fEyHswGTBvcQ/zDLL0U5Sbow02bt6GbhE9Ze3Xwc5a1v44J5QnWmY+7yoOXyeUwbzFuUYskqUfdxcH3Ng8Bp0nb8VPv90EAFz9eDSW7ojHe58dBwDY2Vrj+iejMXNtHNbsOfNYx3m4Z4JF+6l6ZjUqKgq9e/dGeno6ZsyYgV69eqFTp064ePEiLl26hAEDBmD27NlqRkReXh5Oxp9Apy5dTdo7de6Ko0cOq5SqZMxLRYk2xqLlBcTLLFpeUp5oc4J5leVcyQ4AcO9BDgCgZjUXeLk5Yl/8deM+efkGHDpzE60beiueR9Vi9cSJE5g4cSIqV66M8ePH49atWxg1apRx+9ixY3Hs2LFS+8jNzUVGRobJLTc3V7aMqampMBgM8PDwNGn39PTE7dvJsh1HLsxLRYk2xqLlBcTLLFpeUp5oc4J5lTV/dDv89NtNnLueBgCo5loJAJByL9tkv5T72fD87zYlqVqs5uXlwcHBAQBga2uLSpUqwd3d3bi9atWqSEtLK7WPmJgYuLi4mNz+M1/+0/86nc7kviRJxdq0hHmpKNHGWLS8gHiZRctLyhNtTjCv/Ba90gEB/u4YMv/rYtuKXjiqM9OmBJuyd1GOj48Prl69ipo1awIANm/eDC8vL+P2pKQkk+LVnOnTp2PixIkmbZK1XraM7u7usLa2LvbJJyUlpdgnJC1gXipKtDEWLS8gXmbR8pLyRJsTzKuMhS+3R/fWtdF58lbcTM00tif/94yqp1slJN/LMrY/VaUSUu5nF+tHbqqeWe3Xrx9SUlKM97t162Y80woAO3fuRMuWLUvtQ6/Xw9nZ2eSm18tXrNrZ2SEwKBgH9u01aT+wfy9ah4TKdhy5MC8VJdoYi5YXEC+zaHlJeaLNCeaV36KXO6BnaF38a9rnuH47w2TbteR0JN3NQqdAP2ObrY0VwgKq4+i5W4pnU/XManR0dKnbo6KiYG0t77cdH8e4yIkYMXQQgoKbo1XrEKxZHYsbiYkYOXqM2tHMYl5lZWZmIuHKZeP969cScOb0Kbi6uaGGj6+KyUom2hiLlhcQL7NoeUV73omWFxBvTjCvfBaP7Yi+7Z9G71k7kfkwz3gdanpWLnL+u6rH0h3xmNy3BS7fuofLN+9jSt+WeJhbgC3f/654PlWL1bKkpaUhOjoaa9euVTVH7z59cTctDXPnzEJyUhIaNWqMHbu+hp+fX9kPVgHzKutU/HH0CO9svD9z2iQAQP+Bg7E0Vt25WhLRxli0vIB4mUXLK9rzTrS8gHhzgnnl81L3pgCAvQv6mLSPeu9bbNp3DgDw3mfHYW9ng8VjO8HVSY9jF5LRPWo7Mh/mK55P1XVWy3L69GkEBQXBYCjfWn1yr7NK4lNqvUelyL1+IpEaRHveiYavE1SUXOusVhRL11lV9czqzp07S91+9erVCkpCRERERFqkarHaq1cv6HQ6lHZyV2tLOhARERFRxVF1NQAvLy9s27YNhYWFZm/x8fFqxiMiIiIilalarAYHB5dakJZ11pWIiIiInmyqXgYwefJkZGVllbi9Tp06OHjwYAUmIiIiIiItUbVYDQsLK3W7o6Mj2rVrV0FpiIiIiEhrVL0MgIiIiIioNCxWiYiIiEizWKwSERERkWaxWCUiIiIizWKxSkRERETaJZFFcnJypOjoaCknJ0ftKBYTLTPzKk+0zMyrLNHySpJ4mZlXeaJlZt7y00kSV923REZGBlxcXJCeng5nZ2e141hEtMzMqzzRMjOvskTLC4iXmXmVJ1pm5i0/XgZARERERJrFYpWIiIiINIvFKhERERFpFotVC+n1ekRHR0Ov16sdxWKiZWZe5YmWmXmVJVpeQLzMzKs80TIzb/nxC1ZEREREpFk8s0pEREREmsVilYiIiIg0i8UqEREREWkWi1UiIiIi0iwWqxZatmwZ/P39YW9vj+DgYBw6dEjtSCX68ccfERERAW9vb+h0OuzYsUPtSKWKiYlBixYtULlyZXh4eKBXr164cOGC2rFKtHz5cjRp0gTOzs5wdnZGSEgI9uzZo3Ysi8XExECn0yEyMlLtKGa99dZb0Ol0Jrdq1aqpHatMN2/exIsvvoiqVauiUqVKaNasGU6cOKF2LLNq1qxZbIx1Oh3Gjh2rdjSzCgoKMHPmTPj7+8PBwQG1atXCrFmzUFhYqHa0Ej148ACRkZHw8/ODg4MDQkNDcezYMbVjGZX1PiFJEt566y14e3vDwcEB7du3x9mzZ9UJi7Lzbt++Hc8++yzc3d2h0+lw6tQpVXL+VWmZ8/PzMXXqVAQEBMDR0RHe3t4YPHgwbt26pcm8wJ+vzfXr14ejoyNcXV3RuXNn/PzzzxWSjcWqBbZs2YLIyEhERUXh5MmTCAsLQ3h4OBITE9WOZlZWVhaaNm2KDz/8UO0oFvnhhx8wduxYHD16FHv37kVBQQG6du2KrKwstaOZVaNGDcybNw/Hjx/H8ePH0bFjR/Ts2VPVF3JLHTt2DLGxsWjSpInaUUrVqFEjJCUlGW9nzpxRO1Kp7t27hzZt2sDW1hZ79uzBuXPn8N5776FKlSpqRzPr2LFjJuO7d+9eAEDv3r1VTmbe/PnzsWLFCnz44Yc4f/48FixYgP/85z/44IMP1I5WopEjR2Lv3r3YuHEjzpw5g65du6Jz5864efOm2tEAlP0+sWDBAixcuBAffvghjh07hmrVqqFLly548OBBBSf9U1l5s7Ky0KZNG8ybN6+Ck5WstMzZ2dmIj4/HG2+8gfj4eGzfvh0XL15Ejx49VEj6p7LGuF69evjwww9x5swZxMXFoWbNmujatSvu3LmjfDiJytSyZUtpzJgxJm3169eXpk2bplIiywGQvvjiC7VjlEtKSooEQPrhhx/UjmIxV1dXafXq1WrHKNWDBw+kunXrSnv37pXatWsnjR8/Xu1IZkVHR0tNmzZVO0a5TJ06VWrbtq3aMR7b+PHjpdq1a0uFhYVqRzGrW7du0vDhw03ann/+eenFF19UKVHpsrOzJWtra2n37t0m7U2bNpWioqJUSlWyou8ThYWFUrVq1aR58+YZ23JyciQXFxdpxYoVKiQ0Vdr7WkJCggRAOnnyZIVmKosl78W//PKLBEC6fv16xYQqhSV509PTJQDSvn37FM/DM6tlyMvLw4kTJ9C1a1eT9q5du+Lw4cMqpXqypaenAwDc3NxUTlI2g8GAzZs3IysrCyEhIWrHKdXYsWPRrVs3dO7cWe0oZbp06RK8vb3h7++Pfv364erVq2pHKtXOnTvRvHlz9O7dGx4eHggMDMSqVavUjmWRvLw8bNq0CcOHD4dOp1M7jllt27bF/v37cfHiRQDA6dOnERcXh+eee07lZOYVFBTAYDDA3t7epN3BwQFxcXEqpbJcQkICkpOTTd739Ho92rVrx/c9BaWnp0On02n2X2T+Ki8vD7GxsXBxcUHTpk0VP56N4kcQXGpqKgwGAzw9PU3aPT09kZycrFKqJ5ckSZg4cSLatm2Lxo0bqx2nRGfOnEFISAhycnLg5OSEL774Ag0bNlQ7Vok2b96M+Ph4TV0zV5JWrVrho48+Qr169XD79m288847CA0NxdmzZ1G1alW145l19epVLF++HBMnTsSMGTPwyy+/YNy4cdDr9Rg8eLDa8Uq1Y8cO3L9/H0OHDlU7SommTp2K9PR01K9fH9bW1jAYDJgzZw769++vdjSzKleujJCQEMyePRsNGjSAp6cnPv30U/z888+oW7eu2vHK9Oi9zdz73vXr19WI9MTLycnBtGnTMGDAADg7O6sdp0S7d+9Gv379kJ2dDS8vL+zduxfu7u6KH5fFqoWKnnGQJEmzZyFE9uqrr+LXX3/V/NmHp59+GqdOncL9+/exbds2DBkyBD/88IMmC9YbN25g/Pjx+O6774qd6dGi8PBw438HBAQgJCQEtWvXxoYNGzBx4kQVk5WssLAQzZs3x9y5cwEAgYGBOHv2LJYvX675YnXNmjUIDw+Ht7e32lFKtGXLFmzatAmffPIJGjVqhFOnTiEyMhLe3t4YMmSI2vHM2rhxI4YPH47q1avD2toaQUFBGDBgAOLj49WOZjG+71WM/Px89OvXD4WFhVi2bJnacUrVoUMHnDp1CqmpqVi1ahX69OmDn3/+GR4eHooel5cBlMHd3R3W1tbFzqKmpKQU+9RJf89rr72GnTt34uDBg6hRo4bacUplZ2eHOnXqoHnz5oiJiUHTpk3x/vvvqx3LrBMnTiAlJQXBwcGwsbGBjY0NfvjhByxZsgQ2NjYwGAxqRyyVo6MjAgICcOnSJbWjlMjLy6vYB5UGDRpo9kuYj1y/fh379u3DyJEj1Y5SqsmTJ2PatGno168fAgICMGjQIEyYMAExMTFqRytR7dq18cMPPyAzMxM3btzAL7/8gvz8fPj7+6sdrUyPVt/g+57y8vPz0adPHyQkJGDv3r2aPqsK/Pl6XKdOHbRu3Rpr1qyBjY0N1qxZo/hxWayWwc7ODsHBwcZvyz6yd+9ehIaGqpTqySJJEl599VVs374dBw4cEOLFvChJkpCbm6t2DLM6deqEM2fO4NSpU8Zb8+bNMXDgQJw6dQrW1tZqRyxVbm4uzp8/Dy8vL7WjlKhNmzbFllu7ePEi/Pz8VEpkmXXr1sHDwwPdunVTO0qpsrOzYWVl+nZlbW2t6aWrHnF0dISXlxfu3buHb7/9Fj179lQ7Upn8/f1RrVo1k/e9vLw8/PDDD3zfk9GjQvXSpUvYt2+fZi9zKk1FvffxMgALTJw4EYMGDULz5s0REhKC2NhYJCYmYsyYMWpHMyszMxOXL1823k9ISMCpU6fg5uYGX19fFZOZN3bsWHzyySf48ssvUblyZeOneRcXFzg4OKicrrgZM2YgPDwcPj4+ePDgATZv3ozvv/8e33zzjdrRzKpcuXKx638dHR1RtWpVTV4XPGnSJERERMDX1xcpKSl45513kJGRodl/7gWACRMmIDQ0FHPnzkWfPn3wyy+/IDY2FrGxsWpHK1FhYSHWrVuHIUOGwMZG228FERERmDNnDnx9fdGoUSOcPHkSCxcuxPDhw9WOVqJvv/0WkiTh6aefxuXLlzF58mQ8/fTTGDZsmNrRAJT9PhEZGYm5c+eibt26qFu3LubOnYtKlSphwIABmsx79+5dJCYmGtcpffThsVq1aqqt01xaZm9vb7zwwguIj4/H7t27YTAYjO99bm5usLOz01TeqlWrYs6cOejRowe8vLyQlpaGZcuW4Y8//qiYJe8UX2/gCbF06VLJz89PsrOzk4KCgjS9rNLBgwclAMVuQ4YMUTuaWeayApDWrVundjSzhg8fbpwLTz31lNSpUyfpu+++UztWuWh56aq+fftKXl5ekq2treTt7S09//zz0tmzZ9WOVaZdu3ZJjRs3lvR6vVS/fn0pNjZW7Uil+vbbbyUA0oULF9SOUqaMjAxp/Pjxkq+vr2Rvby/VqlVLioqKknJzc9WOVqItW7ZItWrVkuzs7KRq1apJY8eOle7fv692LKOy3icKCwul6OhoqVq1apJer5eeeeYZ6cyZM5rNu27dOrPbo6OjNZn50RJb5m4HDx7UXN6HDx9K//73vyVvb2/Jzs5O8vLyknr06CH98ssvFZJNJ0mSpFAdTERERET0t/CaVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFpFotVIqK/6a233kKzZs2M94cOHYpevXpVeI5r165Bp9Ph1KlTih2j6N/6OCoiJxE9OVisEtETaejQodDpdNDpdLC1tUWtWrUwadIkZGVlKX7s999/H+vXr7do34ou3Nq3b4/IyMgKORYRkRxs1A5ARKSUf/3rX1i3bh3y8/Nx6NAhjBw5EllZWVi+fHmxffPz82FrayvLcV1cXGTph4iIeGaViJ5ger0e1apVg4+PDwYMGICBAwdix44dAP73z9lr165FrVq1oNfrIUkS0tPTMXr0aHh4eMDZ2RkdO3bE6dOnTfqdN28ePD09UblyZYwYMQI5OTkm24teBlBYWIj58+ejTp060Ov18PX1xZw5cwAA/v7+AIDAwEDodDq0b9/e+Lh169ahQYMGsLe3R/369bFs2TKT4/zyyy8IDAyEvb09mjdvjpMnT/7tMZs6dSrq1auHSpUqoVatWnjjjTeQn59fbL+VK1fCx8cHlSpVQu/evXH//n2T7WVlJyKyFM+sEtE/hoODg0nhdfnyZWzduhXbtm2DtbU1AKBbt25wc3PD119/DRcXF6xcuRKdOnXCxYsX4ebmhq1btyI6OhpLly5FWFgYNm7ciCVLlqBWrVolHnf69OlYtWoVFi1ahLZt2yIpKQm///47gD8LzpYtW2Lfvn1o1KgR7OzsAACrVq1CdHQ0PvzwQwQGBuLkyZMYNWoUHB0dMWTIEGRlZaF79+7o2LEjNm3ahISEBIwfP/5vj1HlypWxfv16eHt748yZMxg1ahQqV66MKVOmFBu3Xbt2ISMjAyNGjMDYsWPx8ccfW5SdiKhcJCKiJ9CQIUOknj17Gu///PPPUtWqVaU+ffpIkiRJ0dHRkq2trZSSkmLcZ//+/ZKzs7OUk5Nj0lft2rWllStXSpIkSSEhIdKYMWNMtrdq1Upq2rSp2WNnZGRIer1eWrVqldmcCQkJEgDp5MmTJu0+Pj7SJ598YtI2e/ZsKSQkRJIkSVq5cqXk5uYmZWVlGbcvX77cbF9/1a5dO2n8+PElbi9qwYIFUnBwsPF+dHS0ZG1tLd24ccPYtmfPHsnKykpKSkqyKHtJfzMRkTk8s0pET6zdu3fDyckJBQUFyM/PR8+ePfHBBx8Yt/v5+eGpp54y3j9x4gQyMzNRtWpVk34ePnyIK1euAADOnz+PMWPGmGwPCQnBwYMHzWY4f/48cnNz0alTJ4tz37lzBzdu3MCIESMwatQoY3tBQYHxetjz58+jadOmqFSpkkmOv+vzzz/H4sWLcfnyZWRmZqKgoADOzs4m+/j6+qJGjRomxy0sLMSFCxdgbW1dZnYiovJgsUpET6wOHTpg+fLlsLW1hbe3d7EvUDk6OprcLywshJeXF77//vtifVWpUuWxMjg4OJT7MYWFhQD+/Of0Vq1amWx7dLmCJEmPlac0R48eRb9+/fD222/j2WefhYuLCzZv3oz33nuv1MfpdDrj/1qSnYioPFisEtETy9HREXXq1LF4/6CgICQnJ8PGxgY1a9Y0u0+DBg1w9OhRDB482Nh29OjREvusW7cuHBwcsH//fowcObLY9kfXqBoMBmObp6cnqlevjqtXr2LgwIFm+23YsCE2btyIhw8fGgvi0nJY4qeffoKfnx+ioqKMbdevXy+2X2JiIm7dugVvb28AwJEjR2BlZYV69epZlJ2IqDxYrBIR/Vfnzp0REhKCXr16Yf78+Xj66adx69YtfP311+jVqxeaN2+O8ePHY8iQIWjevDnatm2Ljz/+GGfPni3xC1b29vaYOnUqpkyZAjs7O7Rp0wZ37tzB2bNnMWLECHh4eMDBwQHffPMNatSoAXt7e7i4uOCtt97CuHHj4OzsjPDwcOTm5uL48eO4d+8eJk6ciAEDBiAqKgojRozAzJkzce3aNbz77rsW/Z137twptq5rtWrVUKdOHSQmJmLz5s1o0aIFvvrqK3zxxRdm/6YhQ4bg3XffRUZGBsaNG4c+ffqgWrVqAFBmdiKiclH7olkiIiUU/YJVUdHR0SZfinokIyNDeu211yRvb2/J1tZW8vHxkQYOHCglJiYa95kzZ47k7u4uOTk5SUOGDJGmTJlS4hesJEmSDAaD9M4770h+fn6Sra2t5OvrK82dO9e4fdWqVZKPj49kZWUltWvXztj+8ccfS82aNZPs7OwkV1dX6ZlnnpG2b99u3H7kyBGpadOmkp2dndSsWTNp27ZtFn3BCkCxW3R0tCRJkjR58mSpatWqkpOTk9S3b19p0aJFkouLS7FxW7ZsmeTt7S3Z29tLzz//vHT37l2T45SWnV+wIqLy0EmSAhc+ERERERHJgD8KQERERESaxWKViIiIiDSLxSoRERERaRaLVSIiIiLSLBarRERERKRZLFaJiIiISLNYrBIRERGRZrFYJSIiIiLNYrFKRERERJrFYpWIiIiINIvFKhERERFp1v8DdWyiAqVla6MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        19\n",
      "           1       0.76      0.93      0.84        14\n",
      "           2       0.96      1.00      0.98        22\n",
      "           3       0.71      0.50      0.59        24\n",
      "           4       0.87      1.00      0.93        20\n",
      "           5       0.88      0.71      0.79        21\n",
      "           6       1.00      0.91      0.95        22\n",
      "           7       0.76      0.90      0.83        21\n",
      "           8       0.88      0.71      0.79        21\n",
      "           9       0.76      0.76      0.76        21\n",
      "          10       0.86      0.90      0.88        20\n",
      "          11       0.93      0.87      0.90        15\n",
      "          12       0.72      0.87      0.79        15\n",
      "          13       0.87      0.95      0.91        21\n",
      "\n",
      "    accuracy                           0.83       276\n",
      "   macro avg       0.83      0.84      0.83       276\n",
      "weighted avg       0.84      0.83      0.83       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_list = set(y_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_pred, y_test)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_list, yticklabels=class_list)\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix[0])):\n",
    "        if i == j:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='white')\n",
    "        else:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='black')\n",
    "            \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d440e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions.csv', np.hstack((y_test.reshape(-1, 1), y_pred.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ada0d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Mapping:\n",
      "{'bacterial_leaf_blight': 0, 'bacterial_leaf_streak': 1, 'bakanae': 2, 'brown_spot': 3, 'grassy_stunt_virus': 4, 'healthy_rice_plant': 5, 'narrow_brown_spot': 6, 'ragged_stunt_virus': 7, 'rice_blast': 8, 'rice_false_smut': 9, 'sheath_blight': 10, 'sheath_rot': 11, 'stem_rot': 12, 'tungro_virus': 13}\n"
     ]
    }
   ],
   "source": [
    "# Display the mapping between class names and encoded numbers\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\nClass Mapping:\")\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3359008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
