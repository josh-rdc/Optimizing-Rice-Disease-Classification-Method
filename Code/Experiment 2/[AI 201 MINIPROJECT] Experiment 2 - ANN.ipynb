{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64653a26-b164-4036-93b5-be0f7358a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auxiliaries (Importing Datafile, Checking Time)\n",
    "import os \n",
    "import time\n",
    "\n",
    "# Calculations\n",
    "import numpy as np\n",
    "\n",
    "# For Importing Data Files\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from skimage import color\n",
    "\n",
    "# For Image Pre-Processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979b03d-2172-4465-999b-1e65d282be22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create dataframe\n",
    "\n",
    "3 columns\n",
    "1. Disease Classification\n",
    "2. Image Name\n",
    "3. Image RGB Values (RGB Converted from BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce4c625-de79-4861-b12a-56db5eb4203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def create_dataframe_from_folders(root_folder):\n",
    "    # Initialize empty lists to store data for each column\n",
    "    folder_names = []\n",
    "    photo_names = []\n",
    "    photos = []\n",
    "\n",
    "    # Traverse through the root folder and its subfolders\n",
    "    for folder_name in sorted(os.listdir(root_folder)):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "\n",
    "        # Check if the entry in the root folder is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for photo_name in sorted(os.listdir(folder_path), key=natural_sort_key):\n",
    "                # Assuming photos are in common image formats (e.g., jpg, png)\n",
    "                if photo_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    photo_path = os.path.join(folder_path, photo_name)\n",
    "\n",
    "                    # Read image data using cv2\n",
    "                    image_data = cv2.imread(photo_path)\n",
    "\n",
    "                    # Convert BGR to RGB\n",
    "                    image_data_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Append data to the lists\n",
    "                    folder_names.append(folder_name)\n",
    "                    photo_names.append(photo_name)\n",
    "                    photos.append(image_data_rgb)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'class': folder_names,\n",
    "        'img_name': photo_names,\n",
    "        'rgb': photos\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af7bde-ac77-45fa-8c61-7a53363109b4",
   "metadata": {},
   "source": [
    "Get data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f698915-bb74-4ec7-8ff1-606c6471d686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   class            img_name  \\\n",
      "0  bacterial_leaf_blight  BLB_single (1).jpg   \n",
      "1  bacterial_leaf_blight  BLB_single (2).jpg   \n",
      "2  bacterial_leaf_blight  BLB_single (3).jpg   \n",
      "3  bacterial_leaf_blight  BLB_single (4).jpg   \n",
      "4  bacterial_leaf_blight  BLB_single (5).jpg   \n",
      "\n",
      "                                                 rgb  \n",
      "0  [[[161, 125, 67], [163, 128, 70], [166, 132, 7...  \n",
      "1  [[[238, 229, 222], [238, 229, 222], [238, 229,...  \n",
      "2  [[[236, 225, 219], [237, 226, 220], [238, 227,...  \n",
      "3  [[[236, 223, 217], [236, 223, 217], [237, 224,...  \n",
      "4  [[[236, 225, 221], [236, 225, 221], [236, 225,...  \n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "extra_resized_folder_path = r\"C:\\Users\\Josh\\000 Files\\003 Mengg AI\\01a 201 (AI)\\03 Mini-Project\\resized_raw_images (3 Classes - Zoomed)\"\n",
    "extra_resized = create_dataframe_from_folders(extra_resized_folder_path)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(extra_resized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5426b9d-5fe5-470e-95cd-b9bd72e1875a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Class Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be65000-1849-48e3-b646-93efd2758afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "brown_spot               54\n",
      "rice_blast               50\n",
      "bacterial_leaf_blight    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = extra_resized['class'].value_counts()\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac8225-3fe7-4259-a715-381055cfb61f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d99ab4-0a06-495a-8af2-2d2ca69d19a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Texture Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef73441b-106f-4a76-af4a-30d0192a58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mahotas\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def compute_glcm_features(df):\n",
    "    df['gray'] = df['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2GRAY))\n",
    "    def calculate_glcm(gray_image):\n",
    "        # Compute GLCM using mahotas\n",
    "        glcm = mahotas.features.haralick(gray_image.astype(np.uint8), ignore_zeros=True)\n",
    "        return glcm.mean(axis=0)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        gray_image = row['gray']\n",
    "        glcm_features = calculate_glcm(gray_image)\n",
    "        features.append(glcm_features)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Define meaningful column names for GLCM features\n",
    "    glcm_columns = [\n",
    "        'Angular Second Moment',\n",
    "        'Contrast',\n",
    "        'Correlation',\n",
    "        'Sum of Squares: Variance',\n",
    "        'Inverse Difference Moment',\n",
    "        'Sum Average',\n",
    "        'Sum Variance',\n",
    "        'Sum Entropy',\n",
    "        'Entropy',\n",
    "        'Difference Variance',\n",
    "        'Difference Entropy',\n",
    "        'Informational Measure of Correlation 1',\n",
    "        'Informational Measure of Correlation 2'\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with the new GLCM features and meaningful column names\n",
    "    glcm_df = pd.DataFrame(features, columns=[f'GLCM_{col}' for col in glcm_columns])\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, glcm_df], axis=1)\n",
    "\n",
    "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2b059a-fa17-4742-a4e9-61286361606a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 2.50 seconds\n"
     ]
    }
   ],
   "source": [
    "glcm = compute_glcm_features(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564a00a9-a6ed-4d71-b79b-82ded4744d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the first n columns\n",
    "f_glcm = glcm.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3555e8-efe3-4a70-8258-9bf9d11a2d14",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_Angular Second Moment</th>\n",
       "      <th>GLCM_Contrast</th>\n",
       "      <th>GLCM_Correlation</th>\n",
       "      <th>GLCM_Sum of Squares: Variance</th>\n",
       "      <th>GLCM_Inverse Difference Moment</th>\n",
       "      <th>GLCM_Sum Average</th>\n",
       "      <th>GLCM_Sum Variance</th>\n",
       "      <th>GLCM_Sum Entropy</th>\n",
       "      <th>GLCM_Entropy</th>\n",
       "      <th>GLCM_Difference Variance</th>\n",
       "      <th>GLCM_Difference Entropy</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 1</th>\n",
       "      <th>GLCM_Informational Measure of Correlation 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000358</td>\n",
       "      <td>266.001841</td>\n",
       "      <td>0.964868</td>\n",
       "      <td>3785.238579</td>\n",
       "      <td>0.239492</td>\n",
       "      <td>180.814209</td>\n",
       "      <td>14874.952473</td>\n",
       "      <td>8.629918</td>\n",
       "      <td>12.466566</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>4.343470</td>\n",
       "      <td>-0.369462</td>\n",
       "      <td>0.997668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018832</td>\n",
       "      <td>29.540256</td>\n",
       "      <td>0.994057</td>\n",
       "      <td>2484.910874</td>\n",
       "      <td>0.515623</td>\n",
       "      <td>370.827844</td>\n",
       "      <td>9910.103241</td>\n",
       "      <td>6.141836</td>\n",
       "      <td>8.088455</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>2.749243</td>\n",
       "      <td>-0.444118</td>\n",
       "      <td>0.993843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012217</td>\n",
       "      <td>47.934937</td>\n",
       "      <td>0.991704</td>\n",
       "      <td>2888.983700</td>\n",
       "      <td>0.439836</td>\n",
       "      <td>355.884272</td>\n",
       "      <td>11507.999864</td>\n",
       "      <td>6.346219</td>\n",
       "      <td>8.658163</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>3.050238</td>\n",
       "      <td>-0.405166</td>\n",
       "      <td>0.991940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019039</td>\n",
       "      <td>56.672401</td>\n",
       "      <td>0.992339</td>\n",
       "      <td>3697.472233</td>\n",
       "      <td>0.519511</td>\n",
       "      <td>348.227408</td>\n",
       "      <td>14733.216531</td>\n",
       "      <td>6.472970</td>\n",
       "      <td>8.465276</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>2.890223</td>\n",
       "      <td>-0.465543</td>\n",
       "      <td>0.996049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025665</td>\n",
       "      <td>45.344059</td>\n",
       "      <td>0.993331</td>\n",
       "      <td>3397.524613</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>379.393294</td>\n",
       "      <td>13544.754392</td>\n",
       "      <td>5.682043</td>\n",
       "      <td>7.201895</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>2.390516</td>\n",
       "      <td>-0.478429</td>\n",
       "      <td>0.993598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_Angular Second Moment  GLCM_Contrast  GLCM_Correlation  \\\n",
       "0                    0.000358     266.001841          0.964868   \n",
       "1                    0.018832      29.540256          0.994057   \n",
       "2                    0.012217      47.934937          0.991704   \n",
       "3                    0.019039      56.672401          0.992339   \n",
       "4                    0.025665      45.344059          0.993331   \n",
       "\n",
       "   GLCM_Sum of Squares: Variance  GLCM_Inverse Difference Moment  \\\n",
       "0                    3785.238579                        0.239492   \n",
       "1                    2484.910874                        0.515623   \n",
       "2                    2888.983700                        0.439836   \n",
       "3                    3697.472233                        0.519511   \n",
       "4                    3397.524613                        0.590942   \n",
       "\n",
       "   GLCM_Sum Average  GLCM_Sum Variance  GLCM_Sum Entropy  GLCM_Entropy  \\\n",
       "0        180.814209       14874.952473          8.629918     12.466566   \n",
       "1        370.827844        9910.103241          6.141836      8.088455   \n",
       "2        355.884272       11507.999864          6.346219      8.658163   \n",
       "3        348.227408       14733.216531          6.472970      8.465276   \n",
       "4        379.393294       13544.754392          5.682043      7.201895   \n",
       "\n",
       "   GLCM_Difference Variance  GLCM_Difference Entropy  \\\n",
       "0                  0.000331                 4.343470   \n",
       "1                  0.000993                 2.749243   \n",
       "2                  0.000813                 3.050238   \n",
       "3                  0.000997                 2.890223   \n",
       "4                  0.001234                 2.390516   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 1  \\\n",
       "0                                    -0.369462   \n",
       "1                                    -0.444118   \n",
       "2                                    -0.405166   \n",
       "3                                    -0.465543   \n",
       "4                                    -0.478429   \n",
       "\n",
       "   GLCM_Informational Measure of Correlation 2  \n",
       "0                                     0.997668  \n",
       "1                                     0.993843  \n",
       "2                                     0.991940  \n",
       "3                                     0.996049  \n",
       "4                                     0.993598  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_glcm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21ad4b-7eb0-4110-bcb4-6e592e28d837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94ca35f-9437-4b01-8009-1a0eed2ae870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354c8451-629c-447d-beef-076db3311418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def values(dataframe):\n",
    "    # Ensure the 'rgb' column exists in the dataframe\n",
    "    dataframe['hsv'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2HSV))\n",
    "    #dataframe['hsi'] = dataframe['rgb'].apply(lambda x: color.rgb2hsi(np.uint8(x)))\n",
    "    dataframe['lab'] = dataframe['rgb'].apply(lambda x: cv2.cvtColor(np.uint8(x), cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    dataframe['red'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,0])\n",
    "    dataframe['green'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,1])\n",
    "    dataframe['blue'] = dataframe['rgb'].apply(lambda rgb: rgb[:,:,2])\n",
    "    \n",
    "    dataframe['hue_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,0])\n",
    "    dataframe['saturation_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,1])\n",
    "    dataframe['value_v'] = dataframe['hsv'].apply(lambda hsv: hsv[:,:,2])\n",
    "    \n",
    "    #dataframe['hue_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,0])\n",
    "    #dataframe['saturation_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,1])\n",
    "    #dataframe['intensity_i'] = dataframe['hsv'].apply(lambda hsi: hsi[:,:,2])\n",
    "    \n",
    "    dataframe['lightness'] = dataframe['lab'].apply(lambda lab: lab[:, :, 0])\n",
    "    dataframe['a'] = dataframe['lab'].apply(lambda lab: lab[:, :, 1])\n",
    "    dataframe['b'] = dataframe['lab'].apply(lambda lab: lab[:, :, 2])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5082c1-48a7-4a77-ae63-d276523f8173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_bins_to_dataframe(dataframe, column_name, num_bins):\n",
    "    # Extract the specified column\n",
    "    original_column = dataframe[column_name]\n",
    "\n",
    "    # Define bin edges based on the min and max values in the matrices\n",
    "    min_value = np.min([np.min(matrix) for matrix in original_column])\n",
    "    max_value = np.max([np.max(matrix) for matrix in original_column])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "    # Create column names for the bins\n",
    "    bin_column_names = [f'{column_name}_{i}' for i in range(num_bins)]\n",
    "\n",
    "    # Iterate through each matrix in the original column\n",
    "    for i, matrix in enumerate(original_column):\n",
    "        # Digitize each element in the matrix into the corresponding bin\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "\n",
    "        # Count the occurrences of each bin index\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        # Add new columns to the DataFrame for each bin\n",
    "        for j, bin_column_name in enumerate(bin_column_names):\n",
    "            dataframe.loc[i, bin_column_name] = bin_counts[j]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb1fba-0704-4f4b-b34a-2e2ef1cbd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = values(extra_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ab83c9-fc0e-4cff-9869-3fa8c12e4469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_bins_dataframe(dataframe, col, num_bins):\n",
    "    bins_dataframe = pd.DataFrame()\n",
    "\n",
    "    #print(col)\n",
    "    min_value = np.min([np.min(matrix) for matrix in dataframe[col]])\n",
    "    max_value = np.max([np.max(matrix) for matrix in dataframe[col]])\n",
    "\n",
    "    bin_edges = np.linspace(min_value, max_value, num_bins + 1)\n",
    "    bin_column_names = [f'{col}_{i}' for i in range(1, num_bins + 1)]\n",
    "\n",
    "    for matrix in dataframe[col]:\n",
    "        bin_indices = np.digitize(matrix.flatten(), bin_edges, right=True)\n",
    "        bin_counts = np.bincount(bin_indices, minlength=num_bins + 1)[1:]\n",
    "\n",
    "        bins_dataframe = pd.concat([bins_dataframe, pd.DataFrame(bin_counts).transpose()], axis=0, ignore_index=True)\n",
    "\n",
    "    bins_dataframe.columns = bin_column_names\n",
    "        \n",
    "    return bins_dataframe\n",
    "\n",
    "def hist_features(df, cols, bins):\n",
    "    complete_bins = pd.DataFrame()\n",
    "\n",
    "    for col in cols:\n",
    "        col_bins = create_bins_dataframe(df, col, bins)\n",
    "        complete_bins = pd.concat([complete_bins, col_bins], axis=1)\n",
    "\n",
    "    return complete_bins\n",
    "\n",
    "cols = ['red', 'green', 'blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef1f4f2-7b29-4783-80bb-942502c3f276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'channels' is your DataFrame\n",
    "f_histogram = hist_features(channels, cols, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200b7499-7dd8-4545-a930-7e28dd715d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>red_10</th>\n",
       "      <th>...</th>\n",
       "      <th>b_73</th>\n",
       "      <th>b_74</th>\n",
       "      <th>b_75</th>\n",
       "      <th>b_76</th>\n",
       "      <th>b_77</th>\n",
       "      <th>b_78</th>\n",
       "      <th>b_79</th>\n",
       "      <th>b_80</th>\n",
       "      <th>b_81</th>\n",
       "      <th>b_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>373</td>\n",
       "      <td>484</td>\n",
       "      <td>879</td>\n",
       "      <td>1088</td>\n",
       "      <td>1006</td>\n",
       "      <td>1012</td>\n",
       "      <td>832</td>\n",
       "      <td>1121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   red_1  red_2  red_3  red_4  red_5  red_6  red_7  red_8  red_9  red_10  ...  \\\n",
       "0    175    390    373    484    879   1088   1006   1012    832    1121  ...   \n",
       "1      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "2      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0       0  ...   \n",
       "\n",
       "   b_73  b_74  b_75  b_76  b_77  b_78  b_79  b_80  b_81  b_82  \n",
       "0     0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 738 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_histogram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58cb8f-65ac-44fc-99e6-58e42abfabfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Color Moments Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8b0823e-3e5b-4f1c-95a6-8b8b4cc97e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import cv2\n",
    "\n",
    "def color_moments(dataframe, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        mean_values = []\n",
    "        variance_values = []\n",
    "        kurtosis_values = []\n",
    "        skewness_values = []\n",
    "\n",
    "        for img in dataframe[col]:\n",
    "            # Assuming 'img' is a 3D numpy array representing an RGB image\n",
    "            # Calculate statistics for each image\n",
    "            mean_channel = np.mean(img, axis=(0, 1))\n",
    "            variance_channel = np.var(img, axis=(0, 1))\n",
    "            kurtosis_channel = kurtosis(img, axis=(0, 1))\n",
    "            skewness_channel = skew(img, axis=(0, 1))\n",
    "\n",
    "            # Append values to respective lists\n",
    "            mean_values.append(mean_channel)\n",
    "            variance_values.append(variance_channel)\n",
    "            kurtosis_values.append(kurtosis_channel)\n",
    "            skewness_values.append(skewness_channel)\n",
    "\n",
    "        # Add the new columns to the DataFrame with channel names\n",
    "        for i in range(img.shape[2]):  # Assuming 'img' has shape (height, width, channels)\n",
    "            dataframe[f'{col}_channel_{i}_mean'] = [x[i] for x in mean_values]\n",
    "            dataframe[f'{col}_channel_{i}_variance'] = [x[i] for x in variance_values]\n",
    "            dataframe[f'{col}_channel_{i}_kurtosis'] = [x[i] for x in kurtosis_values]\n",
    "            dataframe[f'{col}_channel_{i}_skewness'] = [x[i] for x in skewness_values]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2cc9e6e-ddcb-41fe-aa4b-72e3f44afc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb\n",
      "hsv\n",
      "lab\n"
     ]
    }
   ],
   "source": [
    "color_df = color_moments(extra_resized, ['rgb','hsv','lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c245d80-93b2-4cc8-82a3-77f40ab9b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_color = color_df.drop(columns=['class','img_name','rgb','gray','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b52a436e-88b8-43bc-b1d7-b17b428f0ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "      <th>rgb_channel_0_variance</th>\n",
       "      <th>rgb_channel_0_kurtosis</th>\n",
       "      <th>rgb_channel_0_skewness</th>\n",
       "      <th>rgb_channel_1_mean</th>\n",
       "      <th>rgb_channel_1_variance</th>\n",
       "      <th>rgb_channel_1_kurtosis</th>\n",
       "      <th>rgb_channel_1_skewness</th>\n",
       "      <th>rgb_channel_2_mean</th>\n",
       "      <th>rgb_channel_2_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_channel_0_kurtosis</th>\n",
       "      <th>lab_channel_0_skewness</th>\n",
       "      <th>lab_channel_1_mean</th>\n",
       "      <th>lab_channel_1_variance</th>\n",
       "      <th>lab_channel_1_kurtosis</th>\n",
       "      <th>lab_channel_1_skewness</th>\n",
       "      <th>lab_channel_2_mean</th>\n",
       "      <th>lab_channel_2_variance</th>\n",
       "      <th>lab_channel_2_kurtosis</th>\n",
       "      <th>lab_channel_2_skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.270089</td>\n",
       "      <td>3990.031165</td>\n",
       "      <td>-0.411904</td>\n",
       "      <td>0.744936</td>\n",
       "      <td>91.700953</td>\n",
       "      <td>3810.139266</td>\n",
       "      <td>-0.052213</td>\n",
       "      <td>0.715675</td>\n",
       "      <td>66.826531</td>\n",
       "      <td>4130.342437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306373</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>125.893136</td>\n",
       "      <td>75.606086</td>\n",
       "      <td>1.887396</td>\n",
       "      <td>0.218237</td>\n",
       "      <td>142.877770</td>\n",
       "      <td>139.253973</td>\n",
       "      <td>-0.707640</td>\n",
       "      <td>0.418429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199.242566</td>\n",
       "      <td>2069.785490</td>\n",
       "      <td>-1.514378</td>\n",
       "      <td>-0.515288</td>\n",
       "      <td>187.317861</td>\n",
       "      <td>2008.205226</td>\n",
       "      <td>-1.781474</td>\n",
       "      <td>-0.309983</td>\n",
       "      <td>139.516861</td>\n",
       "      <td>7895.016537</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728330</td>\n",
       "      <td>-0.350443</td>\n",
       "      <td>126.572007</td>\n",
       "      <td>37.250356</td>\n",
       "      <td>-0.824629</td>\n",
       "      <td>-0.589908</td>\n",
       "      <td>153.407805</td>\n",
       "      <td>516.292401</td>\n",
       "      <td>-1.853678</td>\n",
       "      <td>0.254570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186.096600</td>\n",
       "      <td>3007.509502</td>\n",
       "      <td>-1.814930</td>\n",
       "      <td>-0.218978</td>\n",
       "      <td>182.329321</td>\n",
       "      <td>2194.281216</td>\n",
       "      <td>-1.800756</td>\n",
       "      <td>-0.187194</td>\n",
       "      <td>135.049247</td>\n",
       "      <td>7673.218019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.818788</td>\n",
       "      <td>-0.189757</td>\n",
       "      <td>122.807617</td>\n",
       "      <td>76.436941</td>\n",
       "      <td>-1.666075</td>\n",
       "      <td>-0.225414</td>\n",
       "      <td>152.541653</td>\n",
       "      <td>431.494438</td>\n",
       "      <td>-1.912749</td>\n",
       "      <td>0.151626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.299904</td>\n",
       "      <td>3966.247111</td>\n",
       "      <td>-1.576733</td>\n",
       "      <td>-0.496616</td>\n",
       "      <td>176.301718</td>\n",
       "      <td>3005.669150</td>\n",
       "      <td>-1.622519</td>\n",
       "      <td>-0.438570</td>\n",
       "      <td>139.876574</td>\n",
       "      <td>7783.860065</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.594524</td>\n",
       "      <td>-0.460021</td>\n",
       "      <td>125.340880</td>\n",
       "      <td>60.401777</td>\n",
       "      <td>-0.872360</td>\n",
       "      <td>-0.856840</td>\n",
       "      <td>147.570592</td>\n",
       "      <td>328.878308</td>\n",
       "      <td>-1.485259</td>\n",
       "      <td>0.609684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195.866789</td>\n",
       "      <td>3836.636711</td>\n",
       "      <td>-1.119386</td>\n",
       "      <td>-0.906572</td>\n",
       "      <td>191.531848</td>\n",
       "      <td>2688.568262</td>\n",
       "      <td>-1.122789</td>\n",
       "      <td>-0.898519</td>\n",
       "      <td>164.997409</td>\n",
       "      <td>6832.874435</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.123964</td>\n",
       "      <td>-0.901373</td>\n",
       "      <td>125.377272</td>\n",
       "      <td>71.134292</td>\n",
       "      <td>-0.437482</td>\n",
       "      <td>-1.166782</td>\n",
       "      <td>142.234515</td>\n",
       "      <td>262.144242</td>\n",
       "      <td>-0.463300</td>\n",
       "      <td>1.184542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgb_channel_0_mean  rgb_channel_0_variance  rgb_channel_0_kurtosis  \\\n",
       "0           96.270089             3990.031165               -0.411904   \n",
       "1          199.242566             2069.785490               -1.514378   \n",
       "2          186.096600             3007.509502               -1.814930   \n",
       "3          183.299904             3966.247111               -1.576733   \n",
       "4          195.866789             3836.636711               -1.119386   \n",
       "\n",
       "   rgb_channel_0_skewness  rgb_channel_1_mean  rgb_channel_1_variance  \\\n",
       "0                0.744936           91.700953             3810.139266   \n",
       "1               -0.515288          187.317861             2008.205226   \n",
       "2               -0.218978          182.329321             2194.281216   \n",
       "3               -0.496616          176.301718             3005.669150   \n",
       "4               -0.906572          191.531848             2688.568262   \n",
       "\n",
       "   rgb_channel_1_kurtosis  rgb_channel_1_skewness  rgb_channel_2_mean  \\\n",
       "0               -0.052213                0.715675           66.826531   \n",
       "1               -1.781474               -0.309983          139.516861   \n",
       "2               -1.800756               -0.187194          135.049247   \n",
       "3               -1.622519               -0.438570          139.876574   \n",
       "4               -1.122789               -0.898519          164.997409   \n",
       "\n",
       "   rgb_channel_2_variance  ...  lab_channel_0_kurtosis  \\\n",
       "0             4130.342437  ...               -0.306373   \n",
       "1             7895.016537  ...               -1.728330   \n",
       "2             7673.218019  ...               -1.818788   \n",
       "3             7783.860065  ...               -1.594524   \n",
       "4             6832.874435  ...               -1.123964   \n",
       "\n",
       "   lab_channel_0_skewness  lab_channel_1_mean  lab_channel_1_variance  \\\n",
       "0                0.581436          125.893136               75.606086   \n",
       "1               -0.350443          126.572007               37.250356   \n",
       "2               -0.189757          122.807617               76.436941   \n",
       "3               -0.460021          125.340880               60.401777   \n",
       "4               -0.901373          125.377272               71.134292   \n",
       "\n",
       "   lab_channel_1_kurtosis  lab_channel_1_skewness  lab_channel_2_mean  \\\n",
       "0                1.887396                0.218237          142.877770   \n",
       "1               -0.824629               -0.589908          153.407805   \n",
       "2               -1.666075               -0.225414          152.541653   \n",
       "3               -0.872360               -0.856840          147.570592   \n",
       "4               -0.437482               -1.166782          142.234515   \n",
       "\n",
       "   lab_channel_2_variance  lab_channel_2_kurtosis  lab_channel_2_skewness  \n",
       "0              139.253973               -0.707640                0.418429  \n",
       "1              516.292401               -1.853678                0.254570  \n",
       "2              431.494438               -1.912749                0.151626  \n",
       "3              328.878308               -1.485259                0.609684  \n",
       "4              262.144242               -0.463300                1.184542  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_color.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374ff69-1bee-49c9-a127-38bf7b2154fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Zernike Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2e3d8b-9bcb-4314-8271-fbda88d99c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas.features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def zernike(df, zernike_order):\n",
    "    features_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        gray_img = row['gray']\n",
    "\n",
    "        # Check if the image is grayscale\n",
    "        if len(gray_img.shape) == 2:\n",
    "            # If grayscale, compute Zernike moments directly\n",
    "            moments = mahotas.features.zernike_moments(gray_img, radius=zernike_order)\n",
    "        else:\n",
    "            raise ValueError(\"Input image must be grayscale.\")\n",
    "\n",
    "        features_list.append(moments)\n",
    "\n",
    "    # Determine the number of features per image\n",
    "    num_features_per_image = len(features_list[0])\n",
    "\n",
    "    # Add features to the DataFrame\n",
    "    feature_columns = [f'feature_{i}' for i in range(num_features_per_image)]\n",
    "    df_features = pd.DataFrame(features_list, columns=feature_columns)\n",
    "    df_result = pd.concat([df, df_features], axis=1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2839e315-3874-4df5-9d76-5f159e11d6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.014889</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.019124</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.013850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.024526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.013213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.063308</td>\n",
       "      <td>0.051655</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.036561</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>0.023167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31831</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    0.31831   0.015994   0.005830   0.004560   0.010091   0.015493   \n",
       "1    0.31831   0.001594   0.004247   0.003555   0.011316   0.010798   \n",
       "2    0.31831   0.005007   0.008705   0.006788   0.019123   0.016181   \n",
       "3    0.31831   0.015932   0.063308   0.051655   0.003087   0.017435   \n",
       "4    0.31831   0.003166   0.010777   0.007619   0.004912   0.010917   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_15  feature_16  \\\n",
       "0   0.014889   0.002006   0.005715   0.019349  ...    0.002224    0.019971   \n",
       "1   0.020522   0.017677   0.027740   0.014565  ...    0.024135    0.019143   \n",
       "2   0.003956   0.002548   0.003154   0.013875  ...    0.007416    0.025023   \n",
       "3   0.015274   0.036561   0.007757   0.015761  ...    0.001233    0.033839   \n",
       "4   0.014197   0.007375   0.009341   0.004156  ...    0.002502    0.008668   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.032080    0.029382    0.009788    0.019124    0.006777    0.016389   \n",
       "1    0.020336    0.016388    0.015845    0.003558    0.002029    0.007313   \n",
       "2    0.029394    0.028356    0.004316    0.020854    0.006702    0.015855   \n",
       "3    0.026412    0.008598    0.007508    0.004111    0.003043    0.041183   \n",
       "4    0.026115    0.033828    0.006642    0.002440    0.006141    0.001619   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.011934    0.013850  \n",
       "1    0.008196    0.024526  \n",
       "2    0.013115    0.013213  \n",
       "3    0.010187    0.023167  \n",
       "4    0.005364    0.005747  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zernike_df = zernike(extra_resized, 10)\n",
    "f_zernike = zernike_df.iloc[:, 51:]\n",
    "f_zernike.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f9f14-f5c1-49e8-bc81-0ff472678dd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Legendre Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c31faf-4303-4c2c-9116-db4207ca5f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extra_resized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11c6966-8fce-4fe6-b283-0ae5a249459b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_input = extra_resized.drop(columns=['class','hsv','lab','red','green','blue', 'hue_v', 'saturation_v', 'value_v', 'lightness', 'a', 'b'])\n",
    "l_input = l_input.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797a48fb-2cbb-4377-a2c7-c851bf96b9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>rgb</th>\n",
       "      <th>gray</th>\n",
       "      <th>rgb_channel_0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLB_single (1).jpg</td>\n",
       "      <td>[[[161, 125, 67], [163, 128, 70], [166, 132, 7...</td>\n",
       "      <td>[[129, 132, 135, 136, 136, 138, 139, 139, 137,...</td>\n",
       "      <td>96.270089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLB_single (2).jpg</td>\n",
       "      <td>[[[238, 229, 222], [238, 229, 222], [238, 229,...</td>\n",
       "      <td>[[231, 231, 231, 231, 230, 229, 230, 230, 229,...</td>\n",
       "      <td>199.242566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLB_single (3).jpg</td>\n",
       "      <td>[[[236, 225, 219], [237, 226, 220], [238, 227,...</td>\n",
       "      <td>[[228, 229, 230, 231, 231, 231, 230, 229, 230,...</td>\n",
       "      <td>186.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLB_single (4).jpg</td>\n",
       "      <td>[[[236, 223, 217], [236, 223, 217], [237, 224,...</td>\n",
       "      <td>[[226, 226, 227, 227, 227, 227, 227, 227, 227,...</td>\n",
       "      <td>183.299904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLB_single (5).jpg</td>\n",
       "      <td>[[[236, 225, 221], [236, 225, 221], [236, 225,...</td>\n",
       "      <td>[[228, 228, 228, 228, 228, 228, 228, 228, 228,...</td>\n",
       "      <td>195.866789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img_name                                                rgb  \\\n",
       "0  BLB_single (1).jpg  [[[161, 125, 67], [163, 128, 70], [166, 132, 7...   \n",
       "1  BLB_single (2).jpg  [[[238, 229, 222], [238, 229, 222], [238, 229,...   \n",
       "2  BLB_single (3).jpg  [[[236, 225, 219], [237, 226, 220], [238, 227,...   \n",
       "3  BLB_single (4).jpg  [[[236, 223, 217], [236, 223, 217], [237, 224,...   \n",
       "4  BLB_single (5).jpg  [[[236, 225, 221], [236, 225, 221], [236, 225,...   \n",
       "\n",
       "                                                gray  rgb_channel_0_mean  \n",
       "0  [[129, 132, 135, 136, 136, 138, 139, 139, 137,...           96.270089  \n",
       "1  [[231, 231, 231, 231, 230, 229, 230, 230, 229,...          199.242566  \n",
       "2  [[228, 229, 230, 231, 231, 231, 230, 229, 230,...          186.096600  \n",
       "3  [[226, 226, 227, 227, 227, 227, 227, 227, 227,...          183.299904  \n",
       "4  [[228, 228, 228, 228, 228, 228, 228, 228, 228,...          195.866789  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac178d0-3ed3-4c52-a778-5ae124e3d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.special import legendre\n",
    "\n",
    "def compute_legendre_features(rgb_image, degree):\n",
    "    # Get V channel from RGB image\n",
    "    v_channel = rgb_image[:, :, 2]\n",
    "\n",
    "    # Define x and y coordinates\n",
    "    x_size, y_size = v_channel.shape\n",
    "    x = np.linspace(-1, 1, x_size)\n",
    "    y = np.linspace(-1, 1, y_size)\n",
    "\n",
    "    # Compute Legendre features for the V channel\n",
    "    legendre_features = np.zeros((degree + 1, degree + 1))\n",
    "\n",
    "    for j in range(degree + 1):\n",
    "        for k in range(degree + 1):\n",
    "            legendre_features[j, k] = np.sum(v_channel * legendre(j)(x) * legendre(k)(y))\n",
    "\n",
    "    return legendre_features.flatten()\n",
    "\n",
    "def add_legendre(df, degree):\n",
    "    # Create a new DataFrame for Legendre features\n",
    "    legendre_columns = [f'v_legendre_{i}_{j}' for i in range(degree + 1) for j in range(degree + 1)]\n",
    "    legendre_df = pd.DataFrame(df['rgb'].apply(lambda rgb: compute_legendre_features(rgb, degree)).values.tolist(), columns=legendre_columns)\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, legendre_df], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43846dc1-14e3-448d-adc4-a22e38c851ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "legendre_df = add_legendre(l_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74b7ce3-9c49-42a7-95d2-ea2df961247b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_legendre_0_0</th>\n",
       "      <th>v_legendre_0_1</th>\n",
       "      <th>v_legendre_0_2</th>\n",
       "      <th>v_legendre_0_3</th>\n",
       "      <th>v_legendre_0_4</th>\n",
       "      <th>v_legendre_0_5</th>\n",
       "      <th>v_legendre_0_6</th>\n",
       "      <th>v_legendre_0_7</th>\n",
       "      <th>v_legendre_0_8</th>\n",
       "      <th>v_legendre_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>v_legendre_10_1</th>\n",
       "      <th>v_legendre_10_2</th>\n",
       "      <th>v_legendre_10_3</th>\n",
       "      <th>v_legendre_10_4</th>\n",
       "      <th>v_legendre_10_5</th>\n",
       "      <th>v_legendre_10_6</th>\n",
       "      <th>v_legendre_10_7</th>\n",
       "      <th>v_legendre_10_8</th>\n",
       "      <th>v_legendre_10_9</th>\n",
       "      <th>v_legendre_10_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3353088.0</td>\n",
       "      <td>-1.087238e+06</td>\n",
       "      <td>235099.508778</td>\n",
       "      <td>138969.614640</td>\n",
       "      <td>-213880.081800</td>\n",
       "      <td>32868.044026</td>\n",
       "      <td>41100.147021</td>\n",
       "      <td>-22057.604276</td>\n",
       "      <td>4093.363361</td>\n",
       "      <td>4959.005446</td>\n",
       "      <td>...</td>\n",
       "      <td>-6311.718764</td>\n",
       "      <td>17134.386705</td>\n",
       "      <td>-4354.325125</td>\n",
       "      <td>21434.136965</td>\n",
       "      <td>-4999.513654</td>\n",
       "      <td>-16770.059701</td>\n",
       "      <td>9646.856903</td>\n",
       "      <td>18634.297732</td>\n",
       "      <td>-77270.510962</td>\n",
       "      <td>171556.758187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000398.0</td>\n",
       "      <td>-1.647153e+05</td>\n",
       "      <td>16993.528324</td>\n",
       "      <td>1784.367334</td>\n",
       "      <td>35445.715279</td>\n",
       "      <td>-2965.453418</td>\n",
       "      <td>31875.111977</td>\n",
       "      <td>-940.235712</td>\n",
       "      <td>29365.092505</td>\n",
       "      <td>-4259.342104</td>\n",
       "      <td>...</td>\n",
       "      <td>-3207.796386</td>\n",
       "      <td>32476.086937</td>\n",
       "      <td>-2489.962161</td>\n",
       "      <td>33577.290543</td>\n",
       "      <td>-2410.030008</td>\n",
       "      <td>34908.447337</td>\n",
       "      <td>-1957.168143</td>\n",
       "      <td>33858.993532</td>\n",
       "      <td>-14522.080791</td>\n",
       "      <td>367208.435549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6776231.0</td>\n",
       "      <td>-4.040194e+04</td>\n",
       "      <td>94178.452151</td>\n",
       "      <td>-28337.376132</td>\n",
       "      <td>38294.200615</td>\n",
       "      <td>2442.323361</td>\n",
       "      <td>29519.886739</td>\n",
       "      <td>573.809983</td>\n",
       "      <td>32319.438140</td>\n",
       "      <td>-2597.708766</td>\n",
       "      <td>...</td>\n",
       "      <td>-2207.567426</td>\n",
       "      <td>34574.201478</td>\n",
       "      <td>-962.117115</td>\n",
       "      <td>34265.410875</td>\n",
       "      <td>-840.786748</td>\n",
       "      <td>35865.336257</td>\n",
       "      <td>-4235.821516</td>\n",
       "      <td>42533.736921</td>\n",
       "      <td>-5801.509097</td>\n",
       "      <td>361853.335579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7018447.0</td>\n",
       "      <td>9.445593e+04</td>\n",
       "      <td>6862.907016</td>\n",
       "      <td>4972.047285</td>\n",
       "      <td>39488.004341</td>\n",
       "      <td>2049.562175</td>\n",
       "      <td>27225.615815</td>\n",
       "      <td>-3893.297024</td>\n",
       "      <td>36188.794809</td>\n",
       "      <td>4373.071135</td>\n",
       "      <td>...</td>\n",
       "      <td>3169.501812</td>\n",
       "      <td>34547.292349</td>\n",
       "      <td>401.307337</td>\n",
       "      <td>33508.846870</td>\n",
       "      <td>1111.812538</td>\n",
       "      <td>35333.013038</td>\n",
       "      <td>1912.006198</td>\n",
       "      <td>33394.064995</td>\n",
       "      <td>8572.133821</td>\n",
       "      <td>367697.941762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8278910.0</td>\n",
       "      <td>-7.859323e+04</td>\n",
       "      <td>13974.904824</td>\n",
       "      <td>924.369355</td>\n",
       "      <td>43248.444176</td>\n",
       "      <td>-1325.024786</td>\n",
       "      <td>36822.544836</td>\n",
       "      <td>-309.008812</td>\n",
       "      <td>39155.165133</td>\n",
       "      <td>-2002.215996</td>\n",
       "      <td>...</td>\n",
       "      <td>-1352.400608</td>\n",
       "      <td>40153.183075</td>\n",
       "      <td>-1015.441145</td>\n",
       "      <td>40220.085810</td>\n",
       "      <td>-1162.845594</td>\n",
       "      <td>41754.143653</td>\n",
       "      <td>-913.967013</td>\n",
       "      <td>39824.164348</td>\n",
       "      <td>-6934.850970</td>\n",
       "      <td>434175.385973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v_legendre_0_0  v_legendre_0_1  v_legendre_0_2  v_legendre_0_3  \\\n",
       "0       3353088.0   -1.087238e+06   235099.508778   138969.614640   \n",
       "1       7000398.0   -1.647153e+05    16993.528324     1784.367334   \n",
       "2       6776231.0   -4.040194e+04    94178.452151   -28337.376132   \n",
       "3       7018447.0    9.445593e+04     6862.907016     4972.047285   \n",
       "4       8278910.0   -7.859323e+04    13974.904824      924.369355   \n",
       "\n",
       "   v_legendre_0_4  v_legendre_0_5  v_legendre_0_6  v_legendre_0_7  \\\n",
       "0  -213880.081800    32868.044026    41100.147021   -22057.604276   \n",
       "1    35445.715279    -2965.453418    31875.111977     -940.235712   \n",
       "2    38294.200615     2442.323361    29519.886739      573.809983   \n",
       "3    39488.004341     2049.562175    27225.615815    -3893.297024   \n",
       "4    43248.444176    -1325.024786    36822.544836     -309.008812   \n",
       "\n",
       "   v_legendre_0_8  v_legendre_0_9  ...  v_legendre_10_1  v_legendre_10_2  \\\n",
       "0     4093.363361     4959.005446  ...     -6311.718764     17134.386705   \n",
       "1    29365.092505    -4259.342104  ...     -3207.796386     32476.086937   \n",
       "2    32319.438140    -2597.708766  ...     -2207.567426     34574.201478   \n",
       "3    36188.794809     4373.071135  ...      3169.501812     34547.292349   \n",
       "4    39155.165133    -2002.215996  ...     -1352.400608     40153.183075   \n",
       "\n",
       "   v_legendre_10_3  v_legendre_10_4  v_legendre_10_5  v_legendre_10_6  \\\n",
       "0     -4354.325125     21434.136965     -4999.513654    -16770.059701   \n",
       "1     -2489.962161     33577.290543     -2410.030008     34908.447337   \n",
       "2      -962.117115     34265.410875      -840.786748     35865.336257   \n",
       "3       401.307337     33508.846870      1111.812538     35333.013038   \n",
       "4     -1015.441145     40220.085810     -1162.845594     41754.143653   \n",
       "\n",
       "   v_legendre_10_7  v_legendre_10_8  v_legendre_10_9  v_legendre_10_10  \n",
       "0      9646.856903     18634.297732    -77270.510962     171556.758187  \n",
       "1     -1957.168143     33858.993532    -14522.080791     367208.435549  \n",
       "2     -4235.821516     42533.736921     -5801.509097     361853.335579  \n",
       "3      1912.006198     33394.064995      8572.133821     367697.941762  \n",
       "4      -913.967013     39824.164348     -6934.850970     434175.385973  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_legendre = legendre_df.iloc[:, 4:]\n",
    "f_legendre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bb6a4-6f30-4f3c-8b50-0bad0e8b6c75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Complete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db5931a6-4d94-44df-8c1a-82076732f0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with just the selected column\n",
    "classes = pd.DataFrame(extra_resized['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5002378-98b0-4b70-ba29-a07ba57764f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#complete_features = pd.concat([classes,f_color,f_histogram, f_glcm], axis=1)\n",
    "complete_features = pd.concat([classes,f_histogram, f_glcm, f_color, f_legendre, f_zernike], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "060e531f-0a6e-455b-8dbf-07ca777d8c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>373</td>\n",
       "      <td>484</td>\n",
       "      <td>879</td>\n",
       "      <td>1088</td>\n",
       "      <td>1006</td>\n",
       "      <td>1012</td>\n",
       "      <td>832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.019124</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.013850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.024526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.013213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>0.023167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  red_1  red_2  red_3  red_4  red_5  red_6  red_7  \\\n",
       "0  bacterial_leaf_blight    175    390    373    484    879   1088   1006   \n",
       "1  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "2  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "3  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "4  bacterial_leaf_blight      0      0      0      0      0      0      0   \n",
       "\n",
       "   red_8  red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0   1012    832  ...    0.002224    0.019971    0.032080    0.029382   \n",
       "1      0      0  ...    0.024135    0.019143    0.020336    0.016388   \n",
       "2      0      0  ...    0.007416    0.025023    0.029394    0.028356   \n",
       "3      0      0  ...    0.001233    0.033839    0.026412    0.008598   \n",
       "4      0      0  ...    0.002502    0.008668    0.026115    0.033828   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.009788    0.019124    0.006777    0.016389    0.011934    0.013850  \n",
       "1    0.015845    0.003558    0.002029    0.007313    0.008196    0.024526  \n",
       "2    0.004316    0.020854    0.006702    0.015855    0.013115    0.013213  \n",
       "3    0.007508    0.004111    0.003043    0.041183    0.010187    0.023167  \n",
       "4    0.006642    0.002440    0.006141    0.001619    0.005364    0.005747  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93653fd4-c7c1-4763-ab89-2102d2f29c4c",
   "metadata": {},
   "source": [
    "# Data Normalization and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80096471-c274-4870-bea1-05b14edc651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe(df):\n",
    "    # Create a MinMaxScaler instance\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Extract numerical columns (assuming only numerical columns need normalization)\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply normalization to each numerical column\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b235b92a-228e-4021-975a-b860cafec988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.11175</td>\n",
       "      <td>0.038097</td>\n",
       "      <td>0.03783</td>\n",
       "      <td>0.044257</td>\n",
       "      <td>0.166037</td>\n",
       "      <td>0.372475</td>\n",
       "      <td>0.433621</td>\n",
       "      <td>0.477358</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>0.435652</td>\n",
       "      <td>0.736849</td>\n",
       "      <td>0.448686</td>\n",
       "      <td>0.176895</td>\n",
       "      <td>0.406590</td>\n",
       "      <td>0.151475</td>\n",
       "      <td>0.387336</td>\n",
       "      <td>0.291973</td>\n",
       "      <td>0.304112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>0.414348</td>\n",
       "      <td>0.453257</td>\n",
       "      <td>0.228580</td>\n",
       "      <td>0.287274</td>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.163068</td>\n",
       "      <td>0.187743</td>\n",
       "      <td>0.556240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152945</td>\n",
       "      <td>0.565631</td>\n",
       "      <td>0.671990</td>\n",
       "      <td>0.431314</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.443532</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.374158</td>\n",
       "      <td>0.324891</td>\n",
       "      <td>0.289075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792448</td>\n",
       "      <td>0.599977</td>\n",
       "      <td>0.096634</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>0.085832</td>\n",
       "      <td>0.048247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.524141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>0.144837</td>\n",
       "      <td>0.592811</td>\n",
       "      <td>0.523997</td>\n",
       "      <td>0.119559</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.133901</td>\n",
       "      <td>0.022382</td>\n",
       "      <td>0.108778</td>\n",
       "      <td>0.112775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class    red_1     red_2    red_3     red_4     red_5  \\\n",
       "0  bacterial_leaf_blight  0.11175  0.038097  0.03783  0.044257  0.166037   \n",
       "1  bacterial_leaf_blight  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "2  bacterial_leaf_blight  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "3  bacterial_leaf_blight  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "4  bacterial_leaf_blight  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "\n",
       "      red_6     red_7     red_8     red_9  ...  feature_15  feature_16  \\\n",
       "0  0.372475  0.433621  0.477358  0.365714  ...    0.024523    0.435652   \n",
       "1  0.000000  0.000000  0.000000  0.000000  ...    0.566500    0.414348   \n",
       "2  0.000000  0.000000  0.000000  0.000000  ...    0.152945    0.565631   \n",
       "3  0.000000  0.000000  0.000000  0.000000  ...    0.000000    0.792448   \n",
       "4  0.000000  0.000000  0.000000  0.000000  ...    0.031393    0.144837   \n",
       "\n",
       "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
       "0    0.736849    0.448686    0.176895    0.406590    0.151475    0.387336   \n",
       "1    0.453257    0.228580    0.287274    0.074008    0.020200    0.163068   \n",
       "2    0.671990    0.431314    0.077160    0.443532    0.149414    0.374158   \n",
       "3    0.599977    0.096634    0.135329    0.085832    0.048247    1.000000   \n",
       "4    0.592811    0.523997    0.119559    0.050127    0.133901    0.022382   \n",
       "\n",
       "   feature_23  feature_24  \n",
       "0    0.291973    0.304112  \n",
       "1    0.187743    0.556240  \n",
       "2    0.324891    0.289075  \n",
       "3    0.243243    0.524141  \n",
       "4    0.108778    0.112775  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features = normalize_dataframe(complete_features)\n",
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b339da2-35a0-455d-8db7-266f056dd5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "normalized_features['class'] = label_encoder.fit_transform(normalized_features['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "097defd8-e917-45e2-a877-dfe178bfe066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_1</th>\n",
       "      <th>red_2</th>\n",
       "      <th>red_3</th>\n",
       "      <th>red_4</th>\n",
       "      <th>red_5</th>\n",
       "      <th>red_6</th>\n",
       "      <th>red_7</th>\n",
       "      <th>red_8</th>\n",
       "      <th>red_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.11175</td>\n",
       "      <td>0.038097</td>\n",
       "      <td>0.03783</td>\n",
       "      <td>0.044257</td>\n",
       "      <td>0.166037</td>\n",
       "      <td>0.372475</td>\n",
       "      <td>0.433621</td>\n",
       "      <td>0.477358</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>0.435652</td>\n",
       "      <td>0.736849</td>\n",
       "      <td>0.448686</td>\n",
       "      <td>0.176895</td>\n",
       "      <td>0.406590</td>\n",
       "      <td>0.151475</td>\n",
       "      <td>0.387336</td>\n",
       "      <td>0.291973</td>\n",
       "      <td>0.304112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>0.414348</td>\n",
       "      <td>0.453257</td>\n",
       "      <td>0.228580</td>\n",
       "      <td>0.287274</td>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.163068</td>\n",
       "      <td>0.187743</td>\n",
       "      <td>0.556240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152945</td>\n",
       "      <td>0.565631</td>\n",
       "      <td>0.671990</td>\n",
       "      <td>0.431314</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.443532</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.374158</td>\n",
       "      <td>0.324891</td>\n",
       "      <td>0.289075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792448</td>\n",
       "      <td>0.599977</td>\n",
       "      <td>0.096634</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>0.085832</td>\n",
       "      <td>0.048247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.524141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>0.144837</td>\n",
       "      <td>0.592811</td>\n",
       "      <td>0.523997</td>\n",
       "      <td>0.119559</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.133901</td>\n",
       "      <td>0.022382</td>\n",
       "      <td>0.108778</td>\n",
       "      <td>0.112775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class    red_1     red_2    red_3     red_4     red_5     red_6     red_7  \\\n",
       "0      0  0.11175  0.038097  0.03783  0.044257  0.166037  0.372475  0.433621   \n",
       "1      0  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      red_8     red_9  ...  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0  0.477358  0.365714  ...    0.024523    0.435652    0.736849    0.448686   \n",
       "1  0.000000  0.000000  ...    0.566500    0.414348    0.453257    0.228580   \n",
       "2  0.000000  0.000000  ...    0.152945    0.565631    0.671990    0.431314   \n",
       "3  0.000000  0.000000  ...    0.000000    0.792448    0.599977    0.096634   \n",
       "4  0.000000  0.000000  ...    0.031393    0.144837    0.592811    0.523997   \n",
       "\n",
       "   feature_19  feature_20  feature_21  feature_22  feature_23  feature_24  \n",
       "0    0.176895    0.406590    0.151475    0.387336    0.291973    0.304112  \n",
       "1    0.287274    0.074008    0.020200    0.163068    0.187743    0.556240  \n",
       "2    0.077160    0.443532    0.149414    0.374158    0.324891    0.289075  \n",
       "3    0.135329    0.085832    0.048247    1.000000    0.243243    0.524141  \n",
       "4    0.119559    0.050127    0.133901    0.022382    0.108778    0.112775  \n",
       "\n",
       "[5 rows x 934 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77638c94-04af-43fb-a1db-0548a9c497cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acc8851d-dc36-4634-8d2f-8a3016c14ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def custom_train_test_split(dataframe, target_column, test_size=0.2, random_state=None):\n",
    "    # Separate features and labels\n",
    "    X = dataframe.drop(target_column, axis=1)  # Features\n",
    "    y = dataframe[target_column]  # Labels\n",
    "\n",
    "    # Perform the train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53594f6d-e920-4b66-91d8-7ba1ad60e4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = custom_train_test_split(normalized_features, 'class', test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "165bd148-e43b-401d-94a1-24f08ca4ef46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract features (all columns except the first)\n",
    "x_d = normalized_features.iloc[:, 1:].values\n",
    "\n",
    "# Extract target variable (first column)\n",
    "y_d = normalized_features.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b4890-0ac4-4c6d-b3c1-9acf0c770916",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "705fec05-d73e-470c-9a2b-d71b16d96f36",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 1s 97ms/step - loss: 1.1668 - accuracy: 0.4298 - val_loss: 0.4906 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6429 - accuracy: 0.7982 - val_loss: 0.2916 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4184 - accuracy: 0.8772 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.9298 - val_loss: 0.1575 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2398 - accuracy: 0.9649 - val_loss: 0.1444 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1925 - accuracy: 0.9737 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1561 - accuracy: 0.9737 - val_loss: 0.1738 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1243 - accuracy: 0.9737 - val_loss: 0.2114 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0991 - accuracy: 0.9825 - val_loss: 0.2629 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5408 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5975 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6144 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6166 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.7787e-04 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.5312e-04 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.2899e-04 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.0624e-04 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.8325e-04 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.6316e-04 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.4213e-04 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.2193e-04 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.0460e-04 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.8533e-04 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.6702e-04 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.4940e-04 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.3351e-04 - accuracy: 1.0000 - val_loss: 0.7407 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.1806e-04 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.0149e-04 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.8713e-04 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.7281e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.5874e-04 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.4531e-04 - accuracy: 1.0000 - val_loss: 0.7538 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.3153e-04 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.1903e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.0710e-04 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.9451e-04 - accuracy: 1.0000 - val_loss: 0.7621 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.8246e-04 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.7121e-04 - accuracy: 1.0000 - val_loss: 0.7657 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.6063e-04 - accuracy: 1.0000 - val_loss: 0.7675 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.4988e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.3903e-04 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.2959e-04 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have your data in x_d and y_d\n",
    "X = x_d\n",
    "y = y_d\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')  # 14 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c715fbb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_predictions = model.predict(X_test_scaled)\n",
    "# predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "# np.savetxt('test_predictions.csv', np.hstack((predicted_labels.reshape(-1, 1), y_test.reshape(-1,1))), delimiter=',', fmt='%d')\n",
    "# # np.savetxt('actual labels.csv', y_test.reshape(-1,1), delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601026b",
   "metadata": {},
   "source": [
    "## Feature Selection PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05c4b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 0.99\n",
      "(152, 102)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 72ms/step - loss: 1.1653 - accuracy: 0.4123 - val_loss: 0.6835 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6363 - accuracy: 0.7895 - val_loss: 0.4118 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4116 - accuracy: 0.9211 - val_loss: 0.3456 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3084 - accuracy: 0.9386 - val_loss: 0.3120 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2428 - accuracy: 0.9561 - val_loss: 0.2808 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1962 - accuracy: 0.9737 - val_loss: 0.2594 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1578 - accuracy: 0.9825 - val_loss: 0.2539 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1281 - accuracy: 0.9825 - val_loss: 0.2359 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 0.9825 - val_loss: 0.2491 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0858 - accuracy: 0.9825 - val_loss: 0.2718 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0711 - accuracy: 0.9825 - val_loss: 0.2933 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5625 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5990 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6256 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6271 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.8335e-04 - accuracy: 1.0000 - val_loss: 0.6516 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.6187e-04 - accuracy: 1.0000 - val_loss: 0.6541 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.4025e-04 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.1803e-04 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.9813e-04 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8.7817e-04 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8.5896e-04 - accuracy: 1.0000 - val_loss: 0.6656 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.3921e-04 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.2275e-04 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.0523e-04 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.8690e-04 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.6924e-04 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.5384e-04 - accuracy: 1.0000 - val_loss: 0.6806 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.3881e-04 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.2445e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.0932e-04 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0834 - accuracy: 0.9677\n",
      "\n",
      "Test accuracy: 0.9677419066429138\n",
      "var: 0.991\n",
      "(152, 104)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 64ms/step - loss: 1.1673 - accuracy: 0.4649 - val_loss: 0.4267 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6701 - accuracy: 0.7018 - val_loss: 0.2444 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4832 - accuracy: 0.8421 - val_loss: 0.1642 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3526 - accuracy: 0.9211 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2654 - accuracy: 0.9649 - val_loss: 0.0725 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2048 - accuracy: 0.9737 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1615 - accuracy: 0.9737 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1298 - accuracy: 0.9825 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1032 - accuracy: 0.9825 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0837 - accuracy: 0.9825 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0694 - accuracy: 0.9825 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0595 - accuracy: 0.9825 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0445 - accuracy: 0.9825 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9825 - val_loss: 0.0748 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0341 - accuracy: 0.9825 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.8160e-04 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5521e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.2723e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.0597e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.8049e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.5518e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.3650e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.1751e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.9656e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.7389e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.5659e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.3942e-04 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.2174e-04 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.0732e-04 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.9058e-04 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 6.7318e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.5822e-04 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.4324e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.3380e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.1706e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.0447e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1046 - accuracy: 0.9355\n",
      "\n",
      "Test accuracy: 0.9354838728904724\n",
      "var: 0.992\n",
      "(152, 107)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 1.3504 - accuracy: 0.4035 - val_loss: 0.7930 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6448 - accuracy: 0.7544 - val_loss: 0.4197 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4267 - accuracy: 0.8947 - val_loss: 0.2925 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.9298 - val_loss: 0.2791 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2269 - accuracy: 0.9737 - val_loss: 0.3580 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1715 - accuracy: 0.9737 - val_loss: 0.4695 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1333 - accuracy: 0.9737 - val_loss: 0.5966 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1062 - accuracy: 0.9737 - val_loss: 0.6900 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.9825 - val_loss: 0.7617 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0691 - accuracy: 0.9825 - val_loss: 0.8168 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0562 - accuracy: 0.9825 - val_loss: 0.8808 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9912 - val_loss: 0.9413 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0384 - accuracy: 0.9912 - val_loss: 0.9909 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.1366 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.1751 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2100 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.2694 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.2914 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3576 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.3713 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.3840 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4078 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.4178 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4257 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.4341 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4432 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4509 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4602 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4679 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4758 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4845 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4935 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5135 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5302 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5373 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5535 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5615 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5682 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5741 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5887 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6024 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6086 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6144 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6211 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6279 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6337 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6395 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6506 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6553 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6597 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.6639 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6680 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6720 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6764 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6807 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6846 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.8997e-04 - accuracy: 1.0000 - val_loss: 1.6889 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.6010e-04 - accuracy: 1.0000 - val_loss: 1.6938 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 9.3541e-04 - accuracy: 1.0000 - val_loss: 1.6984 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.1111e-04 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.8905e-04 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.6642e-04 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.4592e-04 - accuracy: 1.0000 - val_loss: 1.7176 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.2562e-04 - accuracy: 1.0000 - val_loss: 1.7222 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.0470e-04 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.8627e-04 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.6808e-04 - accuracy: 1.0000 - val_loss: 1.7357 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.5113e-04 - accuracy: 1.0000 - val_loss: 1.7398 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.3346e-04 - accuracy: 1.0000 - val_loss: 1.7440 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.1705e-04 - accuracy: 1.0000 - val_loss: 1.7486 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.0124e-04 - accuracy: 1.0000 - val_loss: 1.7529 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.8652e-04 - accuracy: 1.0000 - val_loss: 1.7565 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.7059e-04 - accuracy: 1.0000 - val_loss: 1.7601 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.5753e-04 - accuracy: 1.0000 - val_loss: 1.7645 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.4423e-04 - accuracy: 1.0000 - val_loss: 1.7685 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.3056e-04 - accuracy: 1.0000 - val_loss: 1.7728 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.1709e-04 - accuracy: 1.0000 - val_loss: 1.7768 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.0606e-04 - accuracy: 1.0000 - val_loss: 1.7810 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.9351e-04 - accuracy: 1.0000 - val_loss: 1.7847 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8209e-04 - accuracy: 1.0000 - val_loss: 1.7882 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.7100e-04 - accuracy: 1.0000 - val_loss: 1.7919 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.5851e-04 - accuracy: 1.0000 - val_loss: 1.7956 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.4821e-04 - accuracy: 1.0000 - val_loss: 1.7993 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.3791e-04 - accuracy: 1.0000 - val_loss: 1.8025 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.2801e-04 - accuracy: 1.0000 - val_loss: 1.8060 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.1760e-04 - accuracy: 1.0000 - val_loss: 1.8090 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.0735e-04 - accuracy: 1.0000 - val_loss: 1.8126 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1025 - accuracy: 0.9355\n",
      "\n",
      "Test accuracy: 0.9354838728904724\n",
      "var: 0.993\n",
      "(152, 109)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 62ms/step - loss: 1.2572 - accuracy: 0.4825 - val_loss: 0.3089 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6037 - accuracy: 0.7982 - val_loss: 0.1372 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8596 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2696 - accuracy: 0.9211 - val_loss: 0.1610 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2003 - accuracy: 0.9649 - val_loss: 0.2096 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1497 - accuracy: 0.9737 - val_loss: 0.2596 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1166 - accuracy: 0.9737 - val_loss: 0.3277 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0896 - accuracy: 0.9825 - val_loss: 0.4040 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0692 - accuracy: 0.9912 - val_loss: 0.4640 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7842 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.8453 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8688 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9805 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0372 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1230 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1305 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1424 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1490 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1576 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1726 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1964 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2049 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2211 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2334 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2389 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2439 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.8312e-04 - accuracy: 1.0000 - val_loss: 1.2625 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.5581e-04 - accuracy: 1.0000 - val_loss: 1.2668 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.3062e-04 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.0495e-04 - accuracy: 1.0000 - val_loss: 1.2775 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.8061e-04 - accuracy: 1.0000 - val_loss: 1.2836 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.5699e-04 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.3368e-04 - accuracy: 1.0000 - val_loss: 1.2940 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1255e-04 - accuracy: 1.0000 - val_loss: 1.2977 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.9074e-04 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.7106e-04 - accuracy: 1.0000 - val_loss: 1.3048 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.5231e-04 - accuracy: 1.0000 - val_loss: 1.3087 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.3203e-04 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.1495e-04 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9605e-04 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.8073e-04 - accuracy: 1.0000 - val_loss: 1.3233 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.6411e-04 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.4833e-04 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.3361e-04 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.1920e-04 - accuracy: 1.0000 - val_loss: 1.3380 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.0532e-04 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.9151e-04 - accuracy: 1.0000 - val_loss: 1.3455 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7832e-04 - accuracy: 1.0000 - val_loss: 1.3493 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.6552e-04 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.5458e-04 - accuracy: 1.0000 - val_loss: 1.3553 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.4236e-04 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.3066e-04 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.1921e-04 - accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.0869e-04 - accuracy: 1.0000 - val_loss: 1.3687 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.9814e-04 - accuracy: 1.0000 - val_loss: 1.3722 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.8870e-04 - accuracy: 1.0000 - val_loss: 1.3753 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.7903e-04 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.6950e-04 - accuracy: 1.0000 - val_loss: 1.3825 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.6054e-04 - accuracy: 1.0000 - val_loss: 1.3859 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.5242e-04 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.4342e-04 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.3508e-04 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.2706e-04 - accuracy: 1.0000 - val_loss: 1.4026 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.1915e-04 - accuracy: 1.0000 - val_loss: 1.4075 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.1191e-04 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.0372e-04 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "\n",
      "Test accuracy: 1.0\n",
      "var: 0.994\n",
      "(152, 112)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 67ms/step - loss: 1.1244 - accuracy: 0.4561 - val_loss: 0.6566 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6227 - accuracy: 0.8333 - val_loss: 0.3459 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.9211 - val_loss: 0.2154 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3079 - accuracy: 0.9649 - val_loss: 0.1441 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2341 - accuracy: 0.9737 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9737 - val_loss: 0.1149 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1464 - accuracy: 0.9737 - val_loss: 0.1476 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1137 - accuracy: 0.9825 - val_loss: 0.1860 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0950 - accuracy: 0.9825 - val_loss: 0.2450 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0758 - accuracy: 0.9825 - val_loss: 0.3223 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0636 - accuracy: 0.9825 - val_loss: 0.3910 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0524 - accuracy: 0.9912 - val_loss: 0.4444 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0446 - accuracy: 0.9912 - val_loss: 0.4827 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.5037 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.5333 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.5611 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6189 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6418 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7432 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7854 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8231 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8460 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8508 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8646 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8862 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8896 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9009 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9109 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.8643e-04 - accuracy: 1.0000 - val_loss: 0.9144 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.5850e-04 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.3119e-04 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.1002e-04 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.8588e-04 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.6441e-04 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.4089e-04 - accuracy: 1.0000 - val_loss: 0.9329 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.1949e-04 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.0040e-04 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.8062e-04 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.6380e-04 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.4487e-04 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.2722e-04 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.1186e-04 - accuracy: 1.0000 - val_loss: 0.9503 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.9482e-04 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.8074e-04 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.6486e-04 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.5031e-04 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.3787e-04 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.2317e-04 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.1109e-04 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.9761e-04 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8508e-04 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7374e-04 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.6092e-04 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.5166e-04 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.3905e-04 - accuracy: 1.0000 - val_loss: 0.9824 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.2885e-04 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.1911e-04 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.0791e-04 - accuracy: 1.0000 - val_loss: 0.9878 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.9945e-04 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.8922e-04 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0540 - accuracy: 0.9677\n",
      "\n",
      "Test accuracy: 0.9677419066429138\n",
      "var: 0.995\n",
      "(152, 114)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 86ms/step - loss: 1.0231 - accuracy: 0.4825 - val_loss: 0.4371 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4975 - accuracy: 0.8860 - val_loss: 0.2902 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3324 - accuracy: 0.9035 - val_loss: 0.2918 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2383 - accuracy: 0.9386 - val_loss: 0.3116 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1770 - accuracy: 0.9649 - val_loss: 0.3742 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1332 - accuracy: 0.9737 - val_loss: 0.4607 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0974 - accuracy: 0.9825 - val_loss: 0.5348 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0739 - accuracy: 0.9912 - val_loss: 0.5899 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0565 - accuracy: 0.9912 - val_loss: 0.6310 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.7213 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.7423 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.7706 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.7901 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7967 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8451 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8536 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8616 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9173 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9225 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9278 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9847 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0141 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.8364e-04 - accuracy: 1.0000 - val_loss: 1.0211 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.5764e-04 - accuracy: 1.0000 - val_loss: 1.0246 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.3316e-04 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9.0678e-04 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.8334e-04 - accuracy: 1.0000 - val_loss: 1.0334 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.6125e-04 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.4081e-04 - accuracy: 1.0000 - val_loss: 1.0384 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.1919e-04 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.0040e-04 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.8007e-04 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.6100e-04 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.4408e-04 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.2659e-04 - accuracy: 1.0000 - val_loss: 1.0527 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.1009e-04 - accuracy: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.9457e-04 - accuracy: 1.0000 - val_loss: 1.0580 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.7860e-04 - accuracy: 1.0000 - val_loss: 1.0604 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.6312e-04 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.4873e-04 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.3562e-04 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.2103e-04 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.0872e-04 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.9516e-04 - accuracy: 1.0000 - val_loss: 1.0749 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8330e-04 - accuracy: 1.0000 - val_loss: 1.0770 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7219e-04 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.5981e-04 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.4765e-04 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.3736e-04 - accuracy: 1.0000 - val_loss: 1.0871 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.2627e-04 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.1660e-04 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.0683e-04 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.9645e-04 - accuracy: 1.0000 - val_loss: 1.0954 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.8739e-04 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.7755e-04 - accuracy: 1.0000 - val_loss: 1.0991 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.6905e-04 - accuracy: 1.0000 - val_loss: 1.1012 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.6029e-04 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.5193e-04 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.4382e-04 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0487 - accuracy: 1.0000\n",
      "\n",
      "Test accuracy: 1.0\n",
      "var: 0.996\n",
      "(152, 118)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 78ms/step - loss: 1.2085 - accuracy: 0.4649 - val_loss: 0.3884 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6317 - accuracy: 0.7544 - val_loss: 0.2877 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4054 - accuracy: 0.9123 - val_loss: 0.2810 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2946 - accuracy: 0.9298 - val_loss: 0.2991 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2205 - accuracy: 0.9561 - val_loss: 0.3395 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1725 - accuracy: 0.9737 - val_loss: 0.3889 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1314 - accuracy: 0.9737 - val_loss: 0.4355 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1037 - accuracy: 0.9825 - val_loss: 0.4769 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0828 - accuracy: 0.9912 - val_loss: 0.5108 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0649 - accuracy: 0.9912 - val_loss: 0.5370 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.5978 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.6888 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.7483 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7834 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8179 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8259 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8369 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8445 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8531 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8670 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.7847e-04 - accuracy: 1.0000 - val_loss: 0.8842 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.5285e-04 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.2902e-04 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.0654e-04 - accuracy: 1.0000 - val_loss: 0.8923 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.8578e-04 - accuracy: 1.0000 - val_loss: 0.8948 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8.6355e-04 - accuracy: 1.0000 - val_loss: 0.8972 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.4307e-04 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8.2192e-04 - accuracy: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8.0262e-04 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.8491e-04 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.6641e-04 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.4911e-04 - accuracy: 1.0000 - val_loss: 0.9091 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.3085e-04 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.1481e-04 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.9985e-04 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.8398e-04 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.6865e-04 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.5430e-04 - accuracy: 1.0000 - val_loss: 0.9200 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.3958e-04 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.2605e-04 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.1252e-04 - accuracy: 1.0000 - val_loss: 0.9233 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.0088e-04 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.8780e-04 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.7607e-04 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.6444e-04 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.5335e-04 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.4273e-04 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.3240e-04 - accuracy: 1.0000 - val_loss: 0.9329 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.2220e-04 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0822 - accuracy: 0.9355\n",
      "\n",
      "Test accuracy: 0.9354838728904724\n",
      "var: 0.997\n",
      "(152, 122)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 81ms/step - loss: 1.2435 - accuracy: 0.3947 - val_loss: 0.8180 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5807 - accuracy: 0.7544 - val_loss: 0.4966 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3982 - accuracy: 0.8947 - val_loss: 0.4273 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3021 - accuracy: 0.9298 - val_loss: 0.5041 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2298 - accuracy: 0.9561 - val_loss: 0.5897 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1709 - accuracy: 0.9737 - val_loss: 0.6714 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1297 - accuracy: 0.9737 - val_loss: 0.7474 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0908 - accuracy: 0.9825 - val_loss: 0.8082 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.8691 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.0333 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.0483 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0696 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0792 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.0861 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.0930 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1210 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1263 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1307 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1398 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1525 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1717 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1735 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1778 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1818 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1917 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1942 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1983 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2041 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2071 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2129 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2160 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2185 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2225 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2362 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2402 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2437 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2524 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.8768e-04 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.5935e-04 - accuracy: 1.0000 - val_loss: 1.2573 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.3384e-04 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.0901e-04 - accuracy: 1.0000 - val_loss: 1.2617 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.8469e-04 - accuracy: 1.0000 - val_loss: 1.2652 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.6181e-04 - accuracy: 1.0000 - val_loss: 1.2682 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.3848e-04 - accuracy: 1.0000 - val_loss: 1.2705 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1794e-04 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.9681e-04 - accuracy: 1.0000 - val_loss: 1.2748 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.7777e-04 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.5808e-04 - accuracy: 1.0000 - val_loss: 1.2805 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.3951e-04 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.2248e-04 - accuracy: 1.0000 - val_loss: 1.2844 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.0443e-04 - accuracy: 1.0000 - val_loss: 1.2851 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.8827e-04 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.7141e-04 - accuracy: 1.0000 - val_loss: 1.2875 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.5757e-04 - accuracy: 1.0000 - val_loss: 1.2890 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.4201e-04 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.2726e-04 - accuracy: 1.0000 - val_loss: 1.2924 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.1380e-04 - accuracy: 1.0000 - val_loss: 1.2943 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.0089e-04 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.8734e-04 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.7497e-04 - accuracy: 1.0000 - val_loss: 1.3009 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.6315e-04 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.5150e-04 - accuracy: 1.0000 - val_loss: 1.3050 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.4055e-04 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.2963e-04 - accuracy: 1.0000 - val_loss: 1.3108 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.1857e-04 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.0906e-04 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.9928e-04 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.8930e-04 - accuracy: 1.0000 - val_loss: 1.3208 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.8044e-04 - accuracy: 1.0000 - val_loss: 1.3222 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.7129e-04 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.6265e-04 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.5375e-04 - accuracy: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.4566e-04 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1367 - accuracy: 0.9355\n",
      "\n",
      "Test accuracy: 0.9354838728904724\n",
      "var: 0.998\n",
      "(152, 127)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 73ms/step - loss: 1.1736 - accuracy: 0.3509 - val_loss: 0.5371 - val_accuracy: 0.8571\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7206 - accuracy: 0.6842 - val_loss: 0.3923 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5250 - accuracy: 0.8421 - val_loss: 0.3220 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.8772 - val_loss: 0.3011 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3170 - accuracy: 0.9123 - val_loss: 0.3119 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2529 - accuracy: 0.9386 - val_loss: 0.3124 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2062 - accuracy: 0.9649 - val_loss: 0.2991 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1677 - accuracy: 0.9737 - val_loss: 0.2857 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1393 - accuracy: 0.9737 - val_loss: 0.2889 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1140 - accuracy: 0.9737 - val_loss: 0.2774 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0945 - accuracy: 0.9737 - val_loss: 0.2721 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0766 - accuracy: 0.9912 - val_loss: 0.2833 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6303 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6774 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7703 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7764 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7819 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.9171e-04 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.6680e-04 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.4215e-04 - accuracy: 1.0000 - val_loss: 0.8327 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.1963e-04 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.9701e-04 - accuracy: 1.0000 - val_loss: 0.8398 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.7616e-04 - accuracy: 1.0000 - val_loss: 0.8434 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.5621e-04 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.3575e-04 - accuracy: 1.0000 - val_loss: 0.8505 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.1666e-04 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.9719e-04 - accuracy: 1.0000 - val_loss: 0.8583 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.7895e-04 - accuracy: 1.0000 - val_loss: 0.8620 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.6132e-04 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4370e-04 - accuracy: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.2704e-04 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.1054e-04 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.9521e-04 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.7977e-04 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.6505e-04 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.5266e-04 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.3770e-04 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.2424e-04 - accuracy: 1.0000 - val_loss: 0.9010 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.1148e-04 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.9883e-04 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.8847e-04 - accuracy: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.7484e-04 - accuracy: 1.0000 - val_loss: 0.9162 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.6410e-04 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.5240e-04 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1350 - accuracy: 0.9677\n",
      "\n",
      "Test accuracy: 0.9677419066429138\n",
      "var: 0.999\n",
      "(152, 133)\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 68ms/step - loss: 1.1096 - accuracy: 0.4298 - val_loss: 1.0227 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6556 - accuracy: 0.7018 - val_loss: 0.6700 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4815 - accuracy: 0.8860 - val_loss: 0.4804 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3720 - accuracy: 0.9211 - val_loss: 0.4000 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2877 - accuracy: 0.9386 - val_loss: 0.3635 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2272 - accuracy: 0.9649 - val_loss: 0.4017 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1808 - accuracy: 0.9649 - val_loss: 0.4851 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1414 - accuracy: 0.9737 - val_loss: 0.6071 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1105 - accuracy: 0.9737 - val_loss: 0.7332 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0867 - accuracy: 0.9912 - val_loss: 0.8770 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0685 - accuracy: 0.9912 - val_loss: 1.0053 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0540 - accuracy: 0.9912 - val_loss: 1.1126 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 1.2063 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 1.2839 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 1.3392 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 1.3790 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 1.4088 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 1.4361 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.4639 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.4916 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.5123 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5181 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5213 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5336 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.5381 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5391 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5558 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5668 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5758 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5872 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5932 - val_accuracy: 0.8571\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6004 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6085 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6170 - val_accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6248 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6378 - val_accuracy: 0.8571\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6538 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6601 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6652 - val_accuracy: 0.8571\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6759 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6872 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6920 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6955 - val_accuracy: 0.8571\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6982 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7077 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7121 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7172 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7218 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7264 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7349 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.8229e-04 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.5575e-04 - accuracy: 1.0000 - val_loss: 1.7442 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.2660e-04 - accuracy: 1.0000 - val_loss: 1.7490 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 9.0093e-04 - accuracy: 1.0000 - val_loss: 1.7533 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.7854e-04 - accuracy: 1.0000 - val_loss: 1.7570 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.5537e-04 - accuracy: 1.0000 - val_loss: 1.7596 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 8.3322e-04 - accuracy: 1.0000 - val_loss: 1.7641 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.1248e-04 - accuracy: 1.0000 - val_loss: 1.7692 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.9132e-04 - accuracy: 1.0000 - val_loss: 1.7733 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.7291e-04 - accuracy: 1.0000 - val_loss: 1.7783 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.5470e-04 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.8571\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.3603e-04 - accuracy: 1.0000 - val_loss: 1.7880 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.1986e-04 - accuracy: 1.0000 - val_loss: 1.7925 - val_accuracy: 0.8571\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.0119e-04 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.8662e-04 - accuracy: 1.0000 - val_loss: 1.8006 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.7055e-04 - accuracy: 1.0000 - val_loss: 1.8037 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.5604e-04 - accuracy: 1.0000 - val_loss: 1.8071 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.4103e-04 - accuracy: 1.0000 - val_loss: 1.8125 - val_accuracy: 0.8571\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.2750e-04 - accuracy: 1.0000 - val_loss: 1.8172 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.1369e-04 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.0132e-04 - accuracy: 1.0000 - val_loss: 1.8251 - val_accuracy: 0.8571\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.8814e-04 - accuracy: 1.0000 - val_loss: 1.8284 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7685e-04 - accuracy: 1.0000 - val_loss: 1.8319 - val_accuracy: 0.8571\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.6449e-04 - accuracy: 1.0000 - val_loss: 1.8351 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.5336e-04 - accuracy: 1.0000 - val_loss: 1.8386 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.4225e-04 - accuracy: 1.0000 - val_loss: 1.8420 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.3145e-04 - accuracy: 1.0000 - val_loss: 1.8456 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.2070e-04 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.8571\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.1136e-04 - accuracy: 1.0000 - val_loss: 1.8535 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.0083e-04 - accuracy: 1.0000 - val_loss: 1.8561 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.9161e-04 - accuracy: 1.0000 - val_loss: 1.8586 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.8196e-04 - accuracy: 1.0000 - val_loss: 1.8617 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.7303e-04 - accuracy: 1.0000 - val_loss: 1.8653 - val_accuracy: 0.8571\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.6422e-04 - accuracy: 1.0000 - val_loss: 1.8684 - val_accuracy: 0.8571\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.5608e-04 - accuracy: 1.0000 - val_loss: 1.8720 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0592 - accuracy: 0.9677\n",
      "\n",
      "Test accuracy: 0.9677419066429138\n",
      "Best Accuracy: 1.0\n",
      "Trimmed x_d with Best Selected Features:\n",
      "(152, 109)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_pca_for_feature_selection(X, desired_variance_ratio):\n",
    "    pca = PCA(n_components=desired_variance_ratio)\n",
    "    reduced_features = pca.fit_transform(X)\n",
    "    return reduced_features, pca\n",
    "\n",
    "def pca(X, y, test_size=0.2, random_state=42):\n",
    "\n",
    "    variance_ratios = [i / 1000 for i in range(990, 1000)]\n",
    "    max_accuracy = 0.0\n",
    "    best_selected_features = None\n",
    "    best_pca_model = None\n",
    "\n",
    "    for desired_variance_ratio in variance_ratios:\n",
    "        reduced_features, pca_model = apply_pca_for_feature_selection(X, desired_variance_ratio)\n",
    "        print(f\"var: {desired_variance_ratio}\")\n",
    "        print(np.shape(reduced_features))\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Build the ANN model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            keras.layers.Dense(32, activation='relu'),\n",
    "            keras.layers.Dense(3, activation='softmax')  # 14 output classes\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.05)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Update max accuracy and store corresponding features\n",
    "        if test_acc > max_accuracy:\n",
    "            max_accuracy = test_acc\n",
    "            best_selected_features = reduced_features.copy()\n",
    "            best_pca_model = pca_model\n",
    "\n",
    "    # Apply inverse_transform to the full dataset with the best selected features\n",
    "    trimmed_x_d = best_pca_model.inverse_transform(best_selected_features)\n",
    "\n",
    "    return best_selected_features, max_accuracy\n",
    "\n",
    "# Example usage:\n",
    "reduced_x_d, max_accuracy = pca(x_d, y_d)\n",
    "print(f\"Best Accuracy: {max_accuracy}\")\n",
    "print(\"Trimmed x_d with Best Selected Features:\")\n",
    "print(np.shape(reduced_x_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bcf09",
   "metadata": {},
   "source": [
    "## ANN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca19135c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01, 0.1, 0.3, 0.5], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X = reduced_x_d\n",
    "y = y_d\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # Tune the number of layers.\n",
    "        for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "            model.add(\n",
    "                layers.Dense(\n",
    "                    # Tune number of units separately.\n",
    "                    units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                    activation=hp.Choice(f\"activation_{i}\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model.add(layers.Dense(3, activation=\"softmax\")) # Output Classes\n",
    "\n",
    "        learning_rate = hp.Choice(\"learning_rate\", [0.001, 0.01, 0.1, 0.3, 0.5])\n",
    "#         alpha = hp.Choice(\"alpha\", [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate), #, momentum=alpha\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32, 64, 128]),\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create an instance of HyperParameters\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "# Build the model with default hyperparameters\n",
    "my_hypermodel = MyHyperModel()\n",
    "my_model = my_hypermodel.build(hp)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel=my_hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    factor=2,\n",
    "    directory=\"Parameter Tuning\",\n",
    "    project_name=\"Neural Network - 14 zoomed\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23c23c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 Complete [00h 00m 03s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 06m 30s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.05, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6d24a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Parameter Tuning\\Neural Network - 14 zoomed\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0025 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 320\n",
      "activation_0: relu\n",
      "learning_rate: 0.01\n",
      "units_1: 64\n",
      "activation_1: sigmoid\n",
      "batch_size: 64\n",
      "units_2: 32\n",
      "activation_2: relu\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0027 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 384\n",
      "activation_0: relu\n",
      "learning_rate: 0.3\n",
      "units_1: 480\n",
      "activation_1: sigmoid\n",
      "batch_size: 16\n",
      "units_2: 288\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 5\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0052 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 96\n",
      "activation_0: relu\n",
      "learning_rate: 0.3\n",
      "units_1: 384\n",
      "activation_1: sigmoid\n",
      "batch_size: 16\n",
      "units_2: 160\n",
      "activation_2: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 5\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0031\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0077 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 96\n",
      "activation_0: relu\n",
      "learning_rate: 0.001\n",
      "units_1: 352\n",
      "activation_1: relu\n",
      "batch_size: 64\n",
      "units_2: 384\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0130 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 416\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "batch_size: 16\n",
      "units_2: 192\n",
      "activation_2: relu\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0131 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 32\n",
      "activation_0: relu\n",
      "learning_rate: 0.001\n",
      "units_1: 160\n",
      "activation_1: tanh\n",
      "batch_size: 64\n",
      "units_2: 192\n",
      "activation_2: relu\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0132 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 256\n",
      "activation_0: relu\n",
      "learning_rate: 0.3\n",
      "units_1: 416\n",
      "activation_1: sigmoid\n",
      "batch_size: 16\n",
      "units_2: 480\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0133 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 96\n",
      "activation_0: tanh\n",
      "learning_rate: 0.001\n",
      "units_1: 32\n",
      "activation_1: tanh\n",
      "batch_size: 64\n",
      "units_2: 160\n",
      "activation_2: sigmoid\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0137 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 416\n",
      "activation_0: relu\n",
      "learning_rate: 0.1\n",
      "units_1: 320\n",
      "activation_1: relu\n",
      "batch_size: 16\n",
      "units_2: 192\n",
      "activation_2: relu\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0130\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0138 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 32\n",
      "activation_0: relu\n",
      "learning_rate: 0.001\n",
      "units_1: 160\n",
      "activation_1: tanh\n",
      "batch_size: 64\n",
      "units_2: 192\n",
      "activation_2: relu\n",
      "tuner/epochs: 13\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0131\n",
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fcd0d17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 68ms/step - loss: 1.1085 - accuracy: 0.3590 - val_loss: 0.7352 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5634 - accuracy: 0.8718 - val_loss: 0.6551 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2132 - accuracy: 0.9829 - val_loss: 0.3445 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2311 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.6105e-04 - accuracy: 1.0000 - val_loss: 1.5954 - val_accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.5951e-04 - accuracy: 1.0000 - val_loss: 1.8533 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2525e-04 - accuracy: 1.0000 - val_loss: 2.0369 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.4396e-05 - accuracy: 1.0000 - val_loss: 2.1659 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.1363e-05 - accuracy: 1.0000 - val_loss: 2.2552 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.9023e-05 - accuracy: 1.0000 - val_loss: 2.3168 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1433e-05 - accuracy: 1.0000 - val_loss: 2.3599 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6983e-05 - accuracy: 1.0000 - val_loss: 2.3897 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3198e-05 - accuracy: 1.0000 - val_loss: 2.4109 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.0524e-05 - accuracy: 1.0000 - val_loss: 2.4256 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.8841e-05 - accuracy: 1.0000 - val_loss: 2.4364 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.7330e-05 - accuracy: 1.0000 - val_loss: 2.4471 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.6389e-05 - accuracy: 1.0000 - val_loss: 2.4546 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5753e-05 - accuracy: 1.0000 - val_loss: 2.4609 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5243e-05 - accuracy: 1.0000 - val_loss: 2.4664 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4845e-05 - accuracy: 1.0000 - val_loss: 2.4714 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4514e-05 - accuracy: 1.0000 - val_loss: 2.4760 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4244e-05 - accuracy: 1.0000 - val_loss: 2.4804 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3973e-05 - accuracy: 1.0000 - val_loss: 2.4845 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3758e-05 - accuracy: 1.0000 - val_loss: 2.4885 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3515e-05 - accuracy: 1.0000 - val_loss: 2.4922 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3303e-05 - accuracy: 1.0000 - val_loss: 2.4959 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3117e-05 - accuracy: 1.0000 - val_loss: 2.4992 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2920e-05 - accuracy: 1.0000 - val_loss: 2.5027 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2734e-05 - accuracy: 1.0000 - val_loss: 2.5059 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2551e-05 - accuracy: 1.0000 - val_loss: 2.5092 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2378e-05 - accuracy: 1.0000 - val_loss: 2.5124 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.2181e-05 - accuracy: 1.0000 - val_loss: 2.5155 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2017e-05 - accuracy: 1.0000 - val_loss: 2.5185 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1833e-05 - accuracy: 1.0000 - val_loss: 2.5216 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1671e-05 - accuracy: 1.0000 - val_loss: 2.5245 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1504e-05 - accuracy: 1.0000 - val_loss: 2.5273 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1325e-05 - accuracy: 1.0000 - val_loss: 2.5301 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1165e-05 - accuracy: 1.0000 - val_loss: 2.5329 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1011e-05 - accuracy: 1.0000 - val_loss: 2.5357 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0848e-05 - accuracy: 1.0000 - val_loss: 2.5385 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0683e-05 - accuracy: 1.0000 - val_loss: 2.5413 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0518e-05 - accuracy: 1.0000 - val_loss: 2.5440 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0370e-05 - accuracy: 1.0000 - val_loss: 2.5468 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0218e-05 - accuracy: 1.0000 - val_loss: 2.5495 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0064e-05 - accuracy: 1.0000 - val_loss: 2.5523 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.9034e-06 - accuracy: 1.0000 - val_loss: 2.5551 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.7445e-06 - accuracy: 1.0000 - val_loss: 2.5577 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.6131e-06 - accuracy: 1.0000 - val_loss: 2.5606 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.4613e-06 - accuracy: 1.0000 - val_loss: 2.5635 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.3064e-06 - accuracy: 1.0000 - val_loss: 2.5662 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 9.1658e-06 - accuracy: 1.0000 - val_loss: 2.5690 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.0282e-06 - accuracy: 1.0000 - val_loss: 2.5719 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.8938e-06 - accuracy: 1.0000 - val_loss: 2.5748 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.7481e-06 - accuracy: 1.0000 - val_loss: 2.5777 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.6166e-06 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.4709e-06 - accuracy: 1.0000 - val_loss: 2.5834 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.3252e-06 - accuracy: 1.0000 - val_loss: 2.5863 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.1907e-06 - accuracy: 1.0000 - val_loss: 2.5891 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.0542e-06 - accuracy: 1.0000 - val_loss: 2.5920 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.9238e-06 - accuracy: 1.0000 - val_loss: 2.5947 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.7883e-06 - accuracy: 1.0000 - val_loss: 2.5978 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.6599e-06 - accuracy: 1.0000 - val_loss: 2.6007 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.5295e-06 - accuracy: 1.0000 - val_loss: 2.6037 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.4072e-06 - accuracy: 1.0000 - val_loss: 2.6069 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.2778e-06 - accuracy: 1.0000 - val_loss: 2.6100 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.1515e-06 - accuracy: 1.0000 - val_loss: 2.6131 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7.0343e-06 - accuracy: 1.0000 - val_loss: 2.6161 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.9070e-06 - accuracy: 1.0000 - val_loss: 2.6192 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.8071e-06 - accuracy: 1.0000 - val_loss: 2.6225 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.6767e-06 - accuracy: 1.0000 - val_loss: 2.6257 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.5677e-06 - accuracy: 1.0000 - val_loss: 2.6289 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.4627e-06 - accuracy: 1.0000 - val_loss: 2.6322 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.3354e-06 - accuracy: 1.0000 - val_loss: 2.6357 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 6.2376e-06 - accuracy: 1.0000 - val_loss: 2.6391 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.1306e-06 - accuracy: 1.0000 - val_loss: 2.6426 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.0205e-06 - accuracy: 1.0000 - val_loss: 2.6461 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.9187e-06 - accuracy: 1.0000 - val_loss: 2.6496 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.8137e-06 - accuracy: 1.0000 - val_loss: 2.6532 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.7179e-06 - accuracy: 1.0000 - val_loss: 2.6568 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.6161e-06 - accuracy: 1.0000 - val_loss: 2.6604 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.5111e-06 - accuracy: 1.0000 - val_loss: 2.6641 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.4214e-06 - accuracy: 1.0000 - val_loss: 2.6675 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.3277e-06 - accuracy: 1.0000 - val_loss: 2.6712 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.2350e-06 - accuracy: 1.0000 - val_loss: 2.6748 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 5.1423e-06 - accuracy: 1.0000 - val_loss: 2.6786 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.0506e-06 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.9589e-06 - accuracy: 1.0000 - val_loss: 2.6860 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.8692e-06 - accuracy: 1.0000 - val_loss: 2.6896 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.7887e-06 - accuracy: 1.0000 - val_loss: 2.6932 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.7052e-06 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.6277e-06 - accuracy: 1.0000 - val_loss: 2.7007 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.5422e-06 - accuracy: 1.0000 - val_loss: 2.7044 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.4586e-06 - accuracy: 1.0000 - val_loss: 2.7083 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.3791e-06 - accuracy: 1.0000 - val_loss: 2.7122 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.3109e-06 - accuracy: 1.0000 - val_loss: 2.7161 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.2304e-06 - accuracy: 1.0000 - val_loss: 2.7200 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.1631e-06 - accuracy: 1.0000 - val_loss: 2.7239 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.0847e-06 - accuracy: 1.0000 - val_loss: 2.7278 - val_accuracy: 0.7500\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002DF4A0D6020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "[test loss, test accuracy]: [0.00196496257558465, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.03)\n",
    "\n",
    "# Check Result\n",
    "y_pred_a = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_a, axis=1)\n",
    "\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d191152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        31\n",
      "   macro avg       1.00      1.00      1.00        31\n",
      "weighted avg       1.00      1.00      1.00        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_list = set(y_test)\n",
    "\n",
    "# # Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_list, yticklabels=class_list)\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix[0])):\n",
    "        if i == j:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='white')\n",
    "        else:\n",
    "            plt.text(j + 0.5, i + 0.5, str(conf_matrix[i, j]), ha='center', va='center', color='black')\n",
    "            \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4ed7e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Mapping:\n",
      "{'bacterial_leaf_blight': 0, 'brown_spot': 1, 'rice_blast': 2}\n"
     ]
    }
   ],
   "source": [
    "# Display the mapping between class names and encoded numbers\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\nClass Mapping:\")\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cf8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
